{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cPickle\n",
    "import collections\n",
    "import Image, ImageDraw\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_concatenate():\n",
    "    \n",
    "    img = np.zeros([50000,3072])\n",
    "    lbl = np.zeros([50000])\n",
    "    for i in range(5):\n",
    "        with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/data_batch_'+str(i+1),'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "        for j in range(10000):\n",
    "            img[j+10000*i] = data['data'][j]\n",
    "            lbl[j+10000*i] = data['labels'][j]\n",
    "        \n",
    "        #print(lbl)\n",
    "        #print(\"//////////////////////////////////////////////\")\n",
    "        \n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/test_batch','rb') as f:\n",
    "    data2 = cPickle.load(f)\n",
    "    test_labels = np.asarray(data2['labels'])\n",
    "    test_data = np.asarray(data2['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = cifar10_concatenate()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_reshape(data):\n",
    "    \n",
    "    size = data.shape[0]\n",
    "    img = np.zeros([size,3072])\n",
    "    \n",
    "    for i in range(size):\n",
    "        imageToUse = data[i]\n",
    "        \n",
    "        image = imageToUse.reshape(3,32,32).transpose(1,2,0)\n",
    "        elmn = image.flatten()\n",
    "        \n",
    "        img[i] = elmn\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalisation(array):\n",
    "    \n",
    "    array = array.astype('float32')\n",
    "    array_nomalized = array / 255.0       \n",
    "    return array_nomalized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_preparation():\n",
    "    \n",
    "    train_reshape = cifar10_reshape(train_data)\n",
    "    test_reshape = cifar10_reshape(test_data)\n",
    "    print(\"reshape done\")\n",
    "    \n",
    "    norm_train_data = normalisation(train_reshape)\n",
    "    norm_test_data = normalisation(test_reshape)\n",
    "    print(\"normalisation done\")\n",
    "    \n",
    "    #flip_train = flip_cifar10(norm_train_data)\n",
    "    #print(\"flip done\")\n",
    "    \n",
    "    #data_train_set = np.concatenate((norm_train_data, flip_train), axis=0)\n",
    "    #label_train_set = np.concatenate((train_labels, train_labels), axis = 0)\n",
    "    \n",
    "    return norm_train_data, norm_test_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape done\n",
      "normalisation done\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a,b = cifar10_preparation()\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batches(batch_size, isTrain):\n",
    "    \n",
    "    while (True):\n",
    "        if isTrain:\n",
    "            for i in xrange(0, len(train_labels), batch_size):\n",
    "                yield(a[i:i+batch_size],train_labels[i:i+batch_size])\n",
    "        else:\n",
    "            for i in xrange(0, len(test_labels), batch_size):\n",
    "                yield(b[i:i+batch_size],test_labels[i:i+batch_size])     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-10-dbc62a118b2c>:165 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-10-dbc62a118b2c>:166 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-10-dbc62a118b2c>:173 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  0\n",
      "j =  0\n",
      "batch_train_accuracy =  0.095\n",
      "j =  50\n",
      "batch_train_accuracy =  0.135\n",
      "j =  100\n",
      "batch_train_accuracy =  0.255\n",
      "j =  150\n",
      "batch_train_accuracy =  0.25\n",
      "j =  200\n",
      "batch_train_accuracy =  0.375\n",
      "lost =  3.75212416315\n",
      "train_cumulative_accuracy :  0.241679990679\n",
      "duree :  86.9259450436\n",
      "lost =  1.89397851706\n",
      "test_cumulative_accuracy :  0.320799991339\n",
      "epoch :  1\n",
      "j =  0\n",
      "batch_train_accuracy =  0.35\n",
      "j =  50\n",
      "batch_train_accuracy =  0.325\n",
      "j =  100\n",
      "batch_train_accuracy =  0.37\n",
      "j =  150\n",
      "batch_train_accuracy =  0.35\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  1.77878388596\n",
      "train_cumulative_accuracy :  0.357539989352\n",
      "duree :  182.367388964\n",
      "lost =  1.72701075077\n",
      "test_cumulative_accuracy :  0.370599990636\n",
      "epoch :  2\n",
      "j =  0\n",
      "batch_train_accuracy =  0.39\n",
      "j =  50\n",
      "batch_train_accuracy =  0.405\n",
      "j =  100\n",
      "batch_train_accuracy =  0.435\n",
      "j =  150\n",
      "batch_train_accuracy =  0.365\n",
      "j =  200\n",
      "batch_train_accuracy =  0.435\n",
      "lost =  1.65843607664\n",
      "train_cumulative_accuracy :  0.402679986477\n",
      "duree :  277.415013075\n",
      "lost =  1.62340831161\n",
      "test_cumulative_accuracy :  0.410299986303\n",
      "epoch :  3\n",
      "j =  0\n",
      "batch_train_accuracy =  0.4\n",
      "j =  50\n",
      "batch_train_accuracy =  0.455\n",
      "j =  100\n",
      "batch_train_accuracy =  0.445\n",
      "j =  150\n",
      "batch_train_accuracy =  0.37\n",
      "j =  200\n",
      "batch_train_accuracy =  0.455\n",
      "lost =  1.58685548306\n",
      "train_cumulative_accuracy :  0.427039984465\n",
      "duree :  372.461635113\n",
      "lost =  1.56677535534\n",
      "test_cumulative_accuracy :  0.432499986589\n",
      "epoch :  4\n",
      "j =  0\n",
      "batch_train_accuracy =  0.435\n",
      "j =  50\n",
      "batch_train_accuracy =  0.51\n",
      "j =  100\n",
      "batch_train_accuracy =  0.45\n",
      "j =  150\n",
      "batch_train_accuracy =  0.41\n",
      "j =  200\n",
      "batch_train_accuracy =  0.465\n",
      "lost =  1.53833989286\n",
      "train_cumulative_accuracy :  0.44547998178\n",
      "duree :  467.508141994\n",
      "lost =  1.53004030466\n",
      "test_cumulative_accuracy :  0.445399982929\n",
      "epoch :  5\n",
      "j =  0\n",
      "batch_train_accuracy =  0.435\n",
      "j =  50\n",
      "batch_train_accuracy =  0.51\n",
      "j =  100\n",
      "batch_train_accuracy =  0.48\n",
      "j =  150\n",
      "batch_train_accuracy =  0.44\n",
      "j =  200\n",
      "batch_train_accuracy =  0.48\n",
      "lost =  1.50210503864\n",
      "train_cumulative_accuracy :  0.458139981389\n",
      "duree :  562.53083396\n",
      "lost =  1.50676009893\n",
      "test_cumulative_accuracy :  0.455999986231\n",
      "epoch :  6\n",
      "j =  0\n",
      "batch_train_accuracy =  0.435\n",
      "j =  50\n",
      "batch_train_accuracy =  0.505\n",
      "j =  100\n",
      "batch_train_accuracy =  0.485\n",
      "j =  150\n",
      "batch_train_accuracy =  0.46\n",
      "j =  200\n",
      "batch_train_accuracy =  0.48\n",
      "lost =  1.47133683157\n",
      "train_cumulative_accuracy :  0.470339981556\n",
      "duree :  657.566277027\n",
      "lost =  1.49273544908\n",
      "test_cumulative_accuracy :  0.459999985695\n",
      "epoch :  7\n",
      "j =  0\n",
      "batch_train_accuracy =  0.44\n",
      "j =  50\n",
      "batch_train_accuracy =  0.525\n",
      "j =  100\n",
      "batch_train_accuracy =  0.505\n",
      "j =  150\n",
      "batch_train_accuracy =  0.475\n",
      "j =  200\n",
      "batch_train_accuracy =  0.515\n",
      "lost =  1.44559972048\n",
      "train_cumulative_accuracy :  0.479799980164\n",
      "duree :  752.639699936\n",
      "lost =  1.46656347156\n",
      "test_cumulative_accuracy :  0.472299982607\n",
      "epoch :  8\n",
      "j =  0\n",
      "batch_train_accuracy =  0.435\n",
      "j =  50\n",
      "batch_train_accuracy =  0.54\n",
      "j =  100\n",
      "batch_train_accuracy =  0.5\n",
      "j =  150\n",
      "batch_train_accuracy =  0.485\n",
      "j =  200\n",
      "batch_train_accuracy =  0.515\n",
      "lost =  1.42258472681\n",
      "train_cumulative_accuracy :  0.488939978361\n",
      "duree :  847.711869001\n",
      "lost =  1.45425108075\n",
      "test_cumulative_accuracy :  0.476299984455\n",
      "epoch :  9\n",
      "j =  0\n",
      "batch_train_accuracy =  0.44\n",
      "j =  50\n",
      "batch_train_accuracy =  0.54\n",
      "j =  100\n",
      "batch_train_accuracy =  0.51\n",
      "j =  150\n",
      "batch_train_accuracy =  0.475\n",
      "j =  200\n",
      "batch_train_accuracy =  0.515\n",
      "lost =  1.40302638245\n",
      "train_cumulative_accuracy :  0.496399976015\n",
      "duree :  942.703567028\n",
      "lost =  1.43250499964\n",
      "test_cumulative_accuracy :  0.486099980474\n",
      "epoch :  10\n",
      "j =  0\n",
      "batch_train_accuracy =  0.475\n",
      "j =  50\n",
      "batch_train_accuracy =  0.525\n",
      "j =  100\n",
      "batch_train_accuracy =  0.535\n",
      "j =  150\n",
      "batch_train_accuracy =  0.495\n",
      "j =  200\n",
      "batch_train_accuracy =  0.515\n",
      "lost =  1.38434583807\n",
      "train_cumulative_accuracy :  0.502899977446\n",
      "duree :  1037.72361493\n",
      "lost =  1.43088314533\n",
      "test_cumulative_accuracy :  0.486399981081\n",
      "epoch :  11\n",
      "j =  0\n",
      "batch_train_accuracy =  0.475\n",
      "j =  50\n",
      "batch_train_accuracy =  0.525\n",
      "j =  100\n",
      "batch_train_accuracy =  0.54\n",
      "j =  150\n",
      "batch_train_accuracy =  0.515\n",
      "j =  200\n",
      "batch_train_accuracy =  0.54\n",
      "lost =  1.3688658886\n",
      "train_cumulative_accuracy :  0.508999977231\n",
      "duree :  1132.73257613\n",
      "lost =  1.41510072708\n",
      "test_cumulative_accuracy :  0.489299978912\n",
      "epoch :  12\n",
      "j =  0\n",
      "batch_train_accuracy =  0.48\n",
      "j =  50\n",
      "batch_train_accuracy =  0.545\n",
      "j =  100\n",
      "batch_train_accuracy =  0.52\n",
      "j =  150\n",
      "batch_train_accuracy =  0.52\n",
      "j =  200\n",
      "batch_train_accuracy =  0.56\n",
      "lost =  1.35310699177\n",
      "train_cumulative_accuracy :  0.514519978404\n",
      "duree :  1227.7695241\n",
      "lost =  1.40938952804\n",
      "test_cumulative_accuracy :  0.493599978685\n",
      "epoch :  13\n",
      "j =  0\n",
      "batch_train_accuracy =  0.47\n",
      "j =  50\n",
      "batch_train_accuracy =  0.535\n",
      "j =  100\n",
      "batch_train_accuracy =  0.53\n",
      "j =  150\n",
      "batch_train_accuracy =  0.545\n",
      "j =  200\n",
      "batch_train_accuracy =  0.58\n",
      "lost =  1.33809776926\n",
      "train_cumulative_accuracy :  0.520879975677\n",
      "duree :  1322.76721597\n",
      "lost =  1.39476971507\n",
      "test_cumulative_accuracy :  0.498999979496\n",
      "epoch :  14\n",
      "j =  0\n",
      "batch_train_accuracy =  0.495\n",
      "j =  50\n",
      "batch_train_accuracy =  0.535\n",
      "j =  100\n",
      "batch_train_accuracy =  0.53\n",
      "j =  150\n",
      "batch_train_accuracy =  0.545\n",
      "j =  200\n",
      "batch_train_accuracy =  0.59\n",
      "lost =  1.32476266432\n",
      "train_cumulative_accuracy :  0.525499975204\n",
      "duree :  1417.73500514\n",
      "lost =  1.38263632894\n",
      "test_cumulative_accuracy :  0.503199979365\n",
      "epoch :  15\n",
      "j =  0\n",
      "batch_train_accuracy =  0.51\n",
      "j =  50\n",
      "batch_train_accuracy =  0.535\n",
      "j =  100\n",
      "batch_train_accuracy =  0.54\n",
      "j =  150\n",
      "batch_train_accuracy =  0.54\n",
      "j =  200\n",
      "batch_train_accuracy =  0.59\n",
      "lost =  1.31112197924\n",
      "train_cumulative_accuracy :  0.530839974165\n",
      "duree :  1512.76700902\n",
      "lost =  1.37274071693\n",
      "test_cumulative_accuracy :  0.508599976897\n",
      "epoch :  16\n",
      "j =  0\n",
      "batch_train_accuracy =  0.525\n",
      "j =  50\n",
      "batch_train_accuracy =  0.535\n",
      "j =  100\n",
      "batch_train_accuracy =  0.55\n",
      "j =  150\n",
      "batch_train_accuracy =  0.535\n",
      "j =  200\n",
      "batch_train_accuracy =  0.595\n",
      "lost =  1.29906557941\n",
      "train_cumulative_accuracy :  0.536019976854\n",
      "duree :  1607.78600812\n",
      "lost =  1.36542128801\n",
      "test_cumulative_accuracy :  0.513499977291\n",
      "epoch :  17\n",
      "j =  0\n",
      "batch_train_accuracy =  0.525\n",
      "j =  50\n",
      "batch_train_accuracy =  0.555\n",
      "j =  100\n",
      "batch_train_accuracy =  0.555\n",
      "j =  150\n",
      "batch_train_accuracy =  0.555\n",
      "j =  200\n",
      "batch_train_accuracy =  0.605\n",
      "lost =  1.28824246931\n",
      "train_cumulative_accuracy :  0.54007997942\n",
      "duree :  1702.79346108\n",
      "lost =  1.35266092658\n",
      "test_cumulative_accuracy :  0.516899975836\n",
      "epoch :  18\n",
      "j =  0\n",
      "batch_train_accuracy =  0.535\n",
      "j =  50\n",
      "batch_train_accuracy =  0.55\n",
      "j =  100\n",
      "batch_train_accuracy =  0.53\n",
      "j =  150\n",
      "batch_train_accuracy =  0.56\n",
      "j =  200\n",
      "batch_train_accuracy =  0.605\n",
      "lost =  1.27607467461\n",
      "train_cumulative_accuracy :  0.544519974709\n",
      "duree :  1797.79925203\n",
      "lost =  1.34238777757\n",
      "test_cumulative_accuracy :  0.519899971485\n",
      "epoch :  19\n",
      "j =  0\n",
      "batch_train_accuracy =  0.54\n",
      "j =  50\n",
      "batch_train_accuracy =  0.565\n",
      "j =  100\n",
      "batch_train_accuracy =  0.53\n",
      "j =  150\n",
      "batch_train_accuracy =  0.56\n",
      "j =  200\n",
      "batch_train_accuracy =  0.62\n",
      "lost =  1.26463293266\n",
      "train_cumulative_accuracy :  0.54931997776\n",
      "duree :  1892.79034901\n",
      "lost =  1.3305718708\n",
      "test_cumulative_accuracy :  0.525399970114\n",
      "epoch :  20\n",
      "j =  0\n",
      "batch_train_accuracy =  0.545\n",
      "j =  50\n",
      "batch_train_accuracy =  0.56\n",
      "j =  100\n",
      "batch_train_accuracy =  0.53\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.63\n",
      "lost =  1.25364769793\n",
      "train_cumulative_accuracy :  0.553619977355\n",
      "duree :  1987.79696703\n",
      "lost =  1.31737891436\n",
      "test_cumulative_accuracy :  0.527799970806\n",
      "epoch :  21\n",
      "j =  0\n",
      "batch_train_accuracy =  0.55\n",
      "j =  50\n",
      "batch_train_accuracy =  0.57\n",
      "j =  100\n",
      "batch_train_accuracy =  0.53\n",
      "j =  150\n",
      "batch_train_accuracy =  0.565\n",
      "j =  200\n",
      "batch_train_accuracy =  0.62\n",
      "lost =  1.24262869024\n",
      "train_cumulative_accuracy :  0.556919981241\n",
      "duree :  2082.83867598\n",
      "lost =  1.30461820126\n",
      "test_cumulative_accuracy :  0.529399971664\n",
      "epoch :  22\n",
      "j =  0\n",
      "batch_train_accuracy =  0.54\n",
      "j =  50\n",
      "batch_train_accuracy =  0.58\n",
      "j =  100\n",
      "batch_train_accuracy =  0.54\n",
      "j =  150\n",
      "batch_train_accuracy =  0.56\n",
      "j =  200\n",
      "batch_train_accuracy =  0.63\n",
      "lost =  1.23201802349\n",
      "train_cumulative_accuracy :  0.561179979086\n",
      "duree :  2177.84916711\n",
      "lost =  1.29403581977\n",
      "test_cumulative_accuracy :  0.534499968588\n",
      "epoch :  23\n",
      "j =  0\n",
      "batch_train_accuracy =  0.545\n",
      "j =  50\n",
      "batch_train_accuracy =  0.585\n",
      "j =  100\n",
      "batch_train_accuracy =  0.54\n",
      "j =  150\n",
      "batch_train_accuracy =  0.555\n",
      "j =  200\n",
      "batch_train_accuracy =  0.64\n",
      "lost =  1.2217763052\n",
      "train_cumulative_accuracy :  0.565539978743\n",
      "duree :  2272.86068106\n",
      "lost =  1.28160048485\n",
      "test_cumulative_accuracy :  0.536399966478\n",
      "epoch :  24\n",
      "j =  0\n",
      "batch_train_accuracy =  0.54\n",
      "j =  50\n",
      "batch_train_accuracy =  0.59\n",
      "j =  100\n",
      "batch_train_accuracy =  0.565\n",
      "j =  150\n",
      "batch_train_accuracy =  0.55\n",
      "j =  200\n",
      "batch_train_accuracy =  0.63\n",
      "lost =  1.21192875195\n",
      "train_cumulative_accuracy :  0.568919978023\n",
      "duree :  2367.85856891\n",
      "lost =  1.26823086679\n",
      "test_cumulative_accuracy :  0.541699967086\n",
      "epoch :  25\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  50\n",
      "batch_train_accuracy =  0.595\n",
      "j =  100\n",
      "batch_train_accuracy =  0.575\n",
      "j =  150\n",
      "batch_train_accuracy =  0.555\n",
      "j =  200\n",
      "batch_train_accuracy =  0.65\n",
      "lost =  1.20196751833\n",
      "train_cumulative_accuracy :  0.573839978814\n",
      "duree :  2462.86684394\n",
      "lost =  1.25874153137\n",
      "test_cumulative_accuracy :  0.544199967682\n",
      "epoch :  26\n",
      "j =  0\n",
      "batch_train_accuracy =  0.555\n",
      "j =  50\n",
      "batch_train_accuracy =  0.6\n",
      "j =  100\n",
      "batch_train_accuracy =  0.575\n",
      "j =  150\n",
      "batch_train_accuracy =  0.55\n",
      "j =  200\n",
      "batch_train_accuracy =  0.64\n",
      "lost =  1.19167878723\n",
      "train_cumulative_accuracy :  0.57709998095\n",
      "duree :  2557.87827897\n",
      "lost =  1.24654019117\n",
      "test_cumulative_accuracy :  0.550799968839\n",
      "epoch :  27\n",
      "j =  0\n",
      "batch_train_accuracy =  0.58\n",
      "j =  50\n",
      "batch_train_accuracy =  0.615\n",
      "j =  100\n",
      "batch_train_accuracy =  0.57\n",
      "j =  150\n",
      "batch_train_accuracy =  0.57\n",
      "j =  200\n",
      "batch_train_accuracy =  0.665\n",
      "lost =  1.18210731506\n",
      "train_cumulative_accuracy :  0.58137997973\n",
      "duree :  2652.89667201\n",
      "lost =  1.24134131134\n",
      "test_cumulative_accuracy :  0.55389996618\n",
      "epoch :  28\n",
      "j =  0\n",
      "batch_train_accuracy =  0.585\n",
      "j =  50\n",
      "batch_train_accuracy =  0.61\n",
      "j =  100\n",
      "batch_train_accuracy =  0.57\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.665\n",
      "lost =  1.17217687082\n",
      "train_cumulative_accuracy :  0.585779981732\n",
      "duree :  2747.91159391\n",
      "lost =  1.23032916486\n",
      "test_cumulative_accuracy :  0.55689997226\n",
      "epoch :  29\n",
      "j =  0\n",
      "batch_train_accuracy =  0.585\n",
      "j =  50\n",
      "batch_train_accuracy =  0.61\n",
      "j =  100\n",
      "batch_train_accuracy =  0.575\n",
      "j =  150\n",
      "batch_train_accuracy =  0.57\n",
      "j =  200\n",
      "batch_train_accuracy =  0.65\n",
      "lost =  1.16348855424\n",
      "train_cumulative_accuracy :  0.588559984565\n",
      "duree :  2842.87194109\n",
      "lost =  1.2201798588\n",
      "test_cumulative_accuracy :  0.560899970531\n",
      "epoch :  30\n",
      "j =  0\n",
      "batch_train_accuracy =  0.57\n",
      "j =  50\n",
      "batch_train_accuracy =  0.615\n",
      "j =  100\n",
      "batch_train_accuracy =  0.575\n",
      "j =  150\n",
      "batch_train_accuracy =  0.57\n",
      "j =  200\n",
      "batch_train_accuracy =  0.665\n",
      "lost =  1.15413729119\n",
      "train_cumulative_accuracy :  0.592259984016\n",
      "duree :  2937.86705494\n",
      "lost =  1.21327141523\n",
      "test_cumulative_accuracy :  0.563199970126\n",
      "epoch :  31\n",
      "j =  0\n",
      "batch_train_accuracy =  0.585\n",
      "j =  50\n",
      "batch_train_accuracy =  0.625\n",
      "j =  100\n",
      "batch_train_accuracy =  0.565\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.665\n",
      "lost =  1.14569335485\n",
      "train_cumulative_accuracy :  0.595939981461\n",
      "duree :  3032.86062002\n",
      "lost =  1.20681802273\n",
      "test_cumulative_accuracy :  0.565599971712\n",
      "epoch :  32\n",
      "j =  0\n",
      "batch_train_accuracy =  0.59\n",
      "j =  50\n",
      "batch_train_accuracy =  0.635\n",
      "j =  100\n",
      "batch_train_accuracy =  0.575\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.67\n",
      "lost =  1.13721442509\n",
      "train_cumulative_accuracy :  0.597899980187\n",
      "duree :  3127.85680604\n",
      "lost =  1.19875773251\n",
      "test_cumulative_accuracy :  0.567999968529\n",
      "epoch :  33\n",
      "j =  0\n",
      "batch_train_accuracy =  0.58\n",
      "j =  50\n",
      "batch_train_accuracy =  0.63\n",
      "j =  100\n",
      "batch_train_accuracy =  0.57\n",
      "j =  150\n",
      "batch_train_accuracy =  0.58\n",
      "j =  200\n",
      "batch_train_accuracy =  0.685\n",
      "lost =  1.12848734045\n",
      "train_cumulative_accuracy :  0.601899983048\n",
      "duree :  3222.83082104\n",
      "lost =  1.19045031428\n",
      "test_cumulative_accuracy :  0.572499968112\n",
      "epoch :  34\n",
      "j =  0\n",
      "batch_train_accuracy =  0.585\n",
      "j =  50\n",
      "batch_train_accuracy =  0.64\n",
      "j =  100\n",
      "batch_train_accuracy =  0.57\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n",
      "j =  200\n",
      "batch_train_accuracy =  0.69\n",
      "lost =  1.12052569795\n",
      "train_cumulative_accuracy :  0.604439984083\n",
      "duree :  3317.83661509\n",
      "lost =  1.18717505991\n",
      "test_cumulative_accuracy :  0.575099969506\n",
      "epoch :  35\n",
      "j =  0\n",
      "batch_train_accuracy =  0.595\n",
      "j =  50\n",
      "batch_train_accuracy =  0.645\n",
      "j =  100\n",
      "batch_train_accuracy =  0.575\n",
      "j =  150\n",
      "batch_train_accuracy =  0.58\n",
      "j =  200\n",
      "batch_train_accuracy =  0.68\n",
      "lost =  1.11278007102\n",
      "train_cumulative_accuracy :  0.607459983826\n",
      "duree :  3412.83539796\n",
      "lost =  1.18395141721\n",
      "test_cumulative_accuracy :  0.575099969208\n",
      "epoch :  36\n",
      "j =  0\n",
      "batch_train_accuracy =  0.595\n",
      "j =  50\n",
      "batch_train_accuracy =  0.645\n",
      "j =  100\n",
      "batch_train_accuracy =  0.56\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n",
      "j =  200\n",
      "batch_train_accuracy =  0.695\n",
      "lost =  1.10557632399\n",
      "train_cumulative_accuracy :  0.610479982376\n",
      "duree :  3507.82883501\n",
      "lost =  1.17706008315\n",
      "test_cumulative_accuracy :  0.578899967372\n",
      "epoch :  37\n",
      "j =  0\n",
      "batch_train_accuracy =  0.59\n",
      "j =  50\n",
      "batch_train_accuracy =  0.66\n",
      "j =  100\n",
      "batch_train_accuracy =  0.565\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n",
      "j =  200\n",
      "batch_train_accuracy =  0.69\n",
      "lost =  1.09761113095\n",
      "train_cumulative_accuracy :  0.613059984326\n",
      "duree :  3602.87243295\n",
      "lost =  1.1701906085\n",
      "test_cumulative_accuracy :  0.581299973428\n",
      "epoch :  38\n",
      "j =  0\n",
      "batch_train_accuracy =  0.595\n",
      "j =  50\n",
      "batch_train_accuracy =  0.655\n",
      "j =  100\n",
      "batch_train_accuracy =  0.57\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n",
      "j =  200\n",
      "batch_train_accuracy =  0.68\n",
      "lost =  1.09028301549\n",
      "train_cumulative_accuracy :  0.615899985909\n",
      "duree :  3697.85008001\n",
      "lost =  1.16659880877\n",
      "test_cumulative_accuracy :  0.581799973845\n",
      "epoch :  39\n",
      "j =  0\n",
      "batch_train_accuracy =  0.6\n",
      "j =  50\n",
      "batch_train_accuracy =  0.66\n",
      "j =  100\n",
      "batch_train_accuracy =  0.595\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n",
      "j =  200\n",
      "batch_train_accuracy =  0.69\n",
      "lost =  1.08347753906\n",
      "train_cumulative_accuracy :  0.61795998311\n",
      "duree :  3792.87939692\n",
      "lost =  1.1620419383\n",
      "test_cumulative_accuracy :  0.586099971831\n",
      "epoch :  40\n",
      "j =  0\n",
      "batch_train_accuracy =  0.61\n",
      "j =  50\n",
      "batch_train_accuracy =  0.655\n",
      "j =  100\n",
      "batch_train_accuracy =  0.59\n",
      "j =  150\n",
      "batch_train_accuracy =  0.58\n",
      "j =  200\n",
      "batch_train_accuracy =  0.685\n",
      "lost =  1.07676085234\n",
      "train_cumulative_accuracy :  0.619819983125\n",
      "duree :  3887.85958791\n",
      "lost =  1.15621813416\n",
      "test_cumulative_accuracy :  0.586899974644\n",
      "epoch :  41\n",
      "j =  0\n",
      "batch_train_accuracy =  0.605\n",
      "j =  50\n",
      "batch_train_accuracy =  0.67\n",
      "j =  100\n",
      "batch_train_accuracy =  0.59\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n",
      "j =  200\n",
      "batch_train_accuracy =  0.69\n",
      "lost =  1.06933729768\n",
      "train_cumulative_accuracy :  0.622599982858\n",
      "duree :  3982.85532808\n",
      "lost =  1.14995074213\n",
      "test_cumulative_accuracy :  0.590399971306\n",
      "epoch :  42\n",
      "j =  0\n",
      "batch_train_accuracy =  0.62\n",
      "j =  50\n",
      "batch_train_accuracy =  0.66\n",
      "j =  100\n",
      "batch_train_accuracy =  0.595\n",
      "j =  150\n",
      "batch_train_accuracy =  0.58\n",
      "j =  200\n",
      "batch_train_accuracy =  0.69\n",
      "lost =  1.06199166894\n",
      "train_cumulative_accuracy :  0.624419983387\n",
      "duree :  4077.85306811\n",
      "lost =  1.14242606819\n",
      "test_cumulative_accuracy :  0.592399971485\n",
      "epoch :  43\n",
      "j =  0\n",
      "batch_train_accuracy =  0.63\n",
      "j =  50\n",
      "batch_train_accuracy =  0.665\n",
      "j =  100\n",
      "batch_train_accuracy =  0.595\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.68\n",
      "lost =  1.05476568651\n",
      "train_cumulative_accuracy :  0.627539986491\n",
      "duree :  4172.83109999\n",
      "lost =  1.13679069042\n",
      "test_cumulative_accuracy :  0.594399966002\n",
      "epoch :  44\n",
      "j =  0\n",
      "batch_train_accuracy =  0.65\n",
      "j =  50\n",
      "batch_train_accuracy =  0.67\n",
      "j =  100\n",
      "batch_train_accuracy =  0.605\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.685\n",
      "lost =  1.04787280488\n",
      "train_cumulative_accuracy :  0.630039988399\n",
      "duree :  4267.82675004\n",
      "lost =  1.12756666303\n",
      "test_cumulative_accuracy :  0.597399968505\n",
      "epoch :  45\n",
      "j =  0\n",
      "batch_train_accuracy =  0.64\n",
      "j =  50\n",
      "batch_train_accuracy =  0.68\n",
      "j =  100\n",
      "batch_train_accuracy =  0.61\n",
      "j =  150\n",
      "batch_train_accuracy =  0.575\n",
      "j =  200\n",
      "batch_train_accuracy =  0.69\n",
      "lost =  1.04163455319\n",
      "train_cumulative_accuracy :  0.632479984641\n",
      "duree :  4362.83940506\n",
      "lost =  1.12132981896\n",
      "test_cumulative_accuracy :  0.59949996829\n",
      "epoch :  46\n",
      "j =  0\n",
      "batch_train_accuracy =  0.645\n",
      "j =  50\n",
      "batch_train_accuracy =  0.67\n",
      "j =  100\n",
      "batch_train_accuracy =  0.6\n",
      "j =  150\n",
      "batch_train_accuracy =  0.585\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-4\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/chap3/truncated/momentum/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    #keep_prob_input = tf.placeholder(tf.float32)\n",
    "    #keep_prob_layers=tf.placeholder(tf.float32)\n",
    "    #phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "       \n",
    "    'wc1': tf.Variable(tf.truncated_normal([3, 3, 3, 48]), name = \"w1\"),\n",
    "    'wc2': tf.Variable(tf.truncated_normal([3, 3, 48, 48]), name = \"w2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.Variable(tf.truncated_normal([3, 3, 48, 96]), name = \"w3\"),\n",
    "    'wc4': tf.Variable(tf.truncated_normal([3, 3, 96, 96]), name = \"w4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'wc5': tf.Variable(tf.truncated_normal([3, 3, 96, 192]), name = \"w5\"),\n",
    "    'wc6': tf.Variable(tf.truncated_normal([3, 3, 192, 192]), name = \"w6\"),\n",
    "    'wc7': tf.Variable(tf.truncated_normal([1, 1, 192, 192]), name = \"w7\"),\n",
    "    'wc8': tf.Variable(tf.truncated_normal([3072, 512]), name = \"w8\"),\n",
    "    'wc9': tf.Variable(tf.truncated_normal([512, 256]), name = \"w9\"),\n",
    "    'wc10': tf.Variable(tf.truncated_normal([256, 10]), name = \"w10\"),\n",
    "}\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b9\"),\n",
    "    'bc10': tf.Variable(tf.truncated_normal([10], stddev=0.1), name = \"b10\"),\n",
    "}\n",
    "    \n",
    "    # Create model\n",
    "    #x_image = tf.reshape(x,[-1,28,28,1])\n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "#x_bn = batch_norm(x_image, 3, phase_train, convolutional = True)\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_image, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc1']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.relu(hidden_1)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc2']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.relu(hidden_2)\n",
    "#hidden_2_do=tf.nn.dropout(hidden_2_relu, keep_prob=prob_1)\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc3']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.relu(hidden_3)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc4']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.relu(hidden_4)\n",
    "#hidden_4_do=tf.nn.dropout(hidden_4_relu, keep_prob=prob_1)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc5']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.relu(hidden_5)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc6']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.relu(hidden_6)\n",
    "#hidden_6_do=tf.nn.dropout(hidden_6_relu, keep_prob=prob_1)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "pool_3 = tf.nn.max_pool(hidden_6_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "print(pool_3.get_shape())\n",
    "\n",
    "hidden_7 = tf.nn.conv2d(pool_3, weights['wc7'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc7']\n",
    "hidden_7_relu = tf.nn.relu(hidden_7)\n",
    "print(hidden_7_relu.get_shape())\n",
    "\n",
    "hidden_8 = tf.matmul(slim.flatten(hidden_7_relu), weights['wc8']) + biases['bc8']\n",
    "hidden_8_relu = tf.nn.relu(hidden_8)\n",
    "#hidden_8_do = tf.nn.dropout(hidden_8_relu, prob_2)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.matmul(hidden_8_relu, weights['wc9']) + biases['bc9']\n",
    "hidden_9_relu = tf.nn.relu(hidden_9)\n",
    "#hidden_9_do = tf.nn.dropout(hidden_9_relu, prob_2)\n",
    "print(hidden_9_relu.get_shape())\n",
    "    \n",
    "out_y = tf.matmul(hidden_9_relu, weights['wc10']) + biases['bc10']\n",
    "\n",
    "'''\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_relu, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.nn.conv2d(hidden_8_relu, weights['wc9'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc9']\n",
    "hidden_9_relu = tf.nn.elu(hidden_9)\n",
    "print(hidden_9_relu.get_shape())\n",
    "\n",
    "out_x = tf.nn.avg_pool(hidden_9_relu, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding=\"VALID\")\n",
    "print(out_x.get_shape())\n",
    "out_y = tf.reshape(out_x,(-1,10))\n",
    "print(out_y.get_shape())\n",
    "'''\n",
    "\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    while(True):\n",
    "            gen_batch = create_batches(125,True)\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(400):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%80 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], \n",
    "                                                               feed_dict={x: img, y: lbl})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 400 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 400 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/400\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/400\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            gen_batch2 = create_batches(100,False)\n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], \n",
    "                                                         feed_dict={x: img2, y: lbl2})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
