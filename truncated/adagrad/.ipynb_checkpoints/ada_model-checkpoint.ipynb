{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cPickle\n",
    "import collections\n",
    "import Image, ImageDraw\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_concatenate():\n",
    "    \n",
    "    img = np.zeros([50000,3072])\n",
    "    lbl = np.zeros([50000])\n",
    "    for i in range(5):\n",
    "        with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/data_batch_'+str(i+1),'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "        for j in range(10000):\n",
    "            img[j+10000*i] = data['data'][j]\n",
    "            lbl[j+10000*i] = data['labels'][j]\n",
    "        \n",
    "        #print(lbl)\n",
    "        #print(\"//////////////////////////////////////////////\")\n",
    "        \n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/test_batch','rb') as f:\n",
    "    data2 = cPickle.load(f)\n",
    "    test_labels = np.asarray(data2['labels'])\n",
    "    test_data = np.asarray(data2['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = cifar10_concatenate()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_reshape(data):\n",
    "    \n",
    "    size = data.shape[0]\n",
    "    img = np.zeros([size,3072])\n",
    "    \n",
    "    for i in range(size):\n",
    "        imageToUse = data[i]\n",
    "        \n",
    "        image = imageToUse.reshape(3,32,32).transpose(1,2,0)\n",
    "        elmn = image.flatten()\n",
    "        \n",
    "        img[i] = elmn\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalisation(array):\n",
    "    \n",
    "    array = array.astype('float32')\n",
    "    array_nomalized = array / 255.0       \n",
    "    return array_nomalized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_preparation():\n",
    "    \n",
    "    train_reshape = cifar10_reshape(train_data)\n",
    "    test_reshape = cifar10_reshape(test_data)\n",
    "    print(\"reshape done\")\n",
    "    \n",
    "    norm_train_data = normalisation(train_reshape)\n",
    "    norm_test_data = normalisation(test_reshape)\n",
    "    print(\"normalisation done\")\n",
    "    \n",
    "    #flip_train = flip_cifar10(norm_train_data)\n",
    "    #print(\"flip done\")\n",
    "    \n",
    "    #data_train_set = np.concatenate((norm_train_data, flip_train), axis=0)\n",
    "    #label_train_set = np.concatenate((train_labels, train_labels), axis = 0)\n",
    "    \n",
    "    return norm_train_data, norm_test_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape done\n",
      "normalisation done\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a,b = cifar10_preparation()\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batches(batch_size, isTrain):\n",
    "    \n",
    "    while (True):\n",
    "        if isTrain:\n",
    "            for i in xrange(0, len(train_labels), batch_size):\n",
    "                yield(a[i:i+batch_size],train_labels[i:i+batch_size])\n",
    "        else:\n",
    "            for i in xrange(0, len(test_labels), batch_size):\n",
    "                yield(b[i:i+batch_size],test_labels[i:i+batch_size])     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-11-99a9cf2f9b18>:165 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-99a9cf2f9b18>:166 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-99a9cf2f9b18>:173 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  0\n",
      "j =  0\n",
      "batch_train_accuracy =  0.095\n",
      "j =  50\n",
      "batch_train_accuracy =  0.225\n",
      "j =  100\n",
      "batch_train_accuracy =  0.205\n",
      "j =  150\n",
      "batch_train_accuracy =  0.24\n",
      "j =  200\n",
      "batch_train_accuracy =  0.265\n",
      "lost =  9.11343886757\n",
      "train_cumulative_accuracy :  0.209759991705\n",
      "duree :  83.3294689655\n",
      "lost =  6.93074155807\n",
      "test_cumulative_accuracy :  0.229699993581\n",
      "epoch :  1\n",
      "j =  0\n",
      "batch_train_accuracy =  0.255\n",
      "j =  50\n",
      "batch_train_accuracy =  0.25\n",
      "j =  100\n",
      "batch_train_accuracy =  0.24\n",
      "j =  150\n",
      "batch_train_accuracy =  0.23\n",
      "j =  200\n",
      "batch_train_accuracy =  0.31\n",
      "lost =  6.05069617462\n",
      "train_cumulative_accuracy :  0.251619989574\n",
      "duree :  178.316617012\n",
      "lost =  5.82012764931\n",
      "test_cumulative_accuracy :  0.252499991059\n",
      "epoch :  2\n",
      "j =  0\n",
      "batch_train_accuracy =  0.28\n",
      "j =  50\n",
      "batch_train_accuracy =  0.275\n",
      "j =  100\n",
      "batch_train_accuracy =  0.255\n",
      "j =  150\n",
      "batch_train_accuracy =  0.255\n",
      "j =  200\n",
      "batch_train_accuracy =  0.305\n",
      "lost =  5.28978864098\n",
      "train_cumulative_accuracy :  0.267859988451\n",
      "duree :  273.362195015\n",
      "lost =  5.22006268024\n",
      "test_cumulative_accuracy :  0.265199991018\n",
      "epoch :  3\n",
      "j =  0\n",
      "batch_train_accuracy =  0.295\n",
      "j =  50\n",
      "batch_train_accuracy =  0.28\n",
      "j =  100\n",
      "batch_train_accuracy =  0.265\n",
      "j =  150\n",
      "batch_train_accuracy =  0.255\n",
      "j =  200\n",
      "batch_train_accuracy =  0.315\n",
      "lost =  4.83663065815\n",
      "train_cumulative_accuracy :  0.277399987161\n",
      "duree :  368.408015966\n",
      "lost =  4.8359610486\n",
      "test_cumulative_accuracy :  0.273399988562\n",
      "epoch :  4\n",
      "j =  0\n",
      "batch_train_accuracy =  0.28\n",
      "j =  50\n",
      "batch_train_accuracy =  0.285\n",
      "j =  100\n",
      "batch_train_accuracy =  0.28\n",
      "j =  150\n",
      "batch_train_accuracy =  0.265\n",
      "j =  200\n",
      "batch_train_accuracy =  0.315\n",
      "lost =  4.52400094509\n",
      "train_cumulative_accuracy :  0.285339984\n",
      "duree :  463.452134132\n",
      "lost =  4.55496323586\n",
      "test_cumulative_accuracy :  0.27969998911\n",
      "epoch :  5\n",
      "j =  0\n",
      "batch_train_accuracy =  0.305\n",
      "j =  50\n",
      "batch_train_accuracy =  0.275\n",
      "j =  100\n",
      "batch_train_accuracy =  0.285\n",
      "j =  150\n",
      "batch_train_accuracy =  0.28\n",
      "j =  200\n",
      "batch_train_accuracy =  0.31\n",
      "lost =  4.28677745152\n",
      "train_cumulative_accuracy :  0.29161998409\n",
      "duree :  558.48822403\n",
      "lost =  4.33832491875\n",
      "test_cumulative_accuracy :  0.286399989426\n",
      "epoch :  6\n",
      "j =  0\n",
      "batch_train_accuracy =  0.33\n",
      "j =  50\n",
      "batch_train_accuracy =  0.295\n",
      "j =  100\n",
      "batch_train_accuracy =  0.3\n",
      "j =  150\n",
      "batch_train_accuracy =  0.275\n",
      "j =  200\n",
      "batch_train_accuracy =  0.32\n",
      "lost =  4.10178233433\n",
      "train_cumulative_accuracy :  0.297099983931\n",
      "duree :  653.507535934\n",
      "lost =  4.16683360338\n",
      "test_cumulative_accuracy :  0.293599991649\n",
      "epoch :  7\n",
      "j =  0\n",
      "batch_train_accuracy =  0.345\n",
      "j =  50\n",
      "batch_train_accuracy =  0.3\n",
      "j =  100\n",
      "batch_train_accuracy =  0.29\n",
      "j =  150\n",
      "batch_train_accuracy =  0.275\n",
      "j =  200\n",
      "batch_train_accuracy =  0.31\n",
      "lost =  3.94915948009\n",
      "train_cumulative_accuracy :  0.300599985063\n",
      "duree :  748.545810938\n",
      "lost =  4.02387474775\n",
      "test_cumulative_accuracy :  0.299899991453\n",
      "epoch :  8\n",
      "j =  0\n",
      "batch_train_accuracy =  0.335\n",
      "j =  50\n",
      "batch_train_accuracy =  0.315\n",
      "j =  100\n",
      "batch_train_accuracy =  0.295\n",
      "j =  150\n",
      "batch_train_accuracy =  0.29\n",
      "j =  200\n",
      "batch_train_accuracy =  0.315\n",
      "lost =  3.82005523491\n",
      "train_cumulative_accuracy :  0.305999982893\n",
      "duree :  843.569950104\n",
      "lost =  3.90214558125\n",
      "test_cumulative_accuracy :  0.303799991608\n",
      "epoch :  9\n",
      "j =  0\n",
      "batch_train_accuracy =  0.345\n",
      "j =  50\n",
      "batch_train_accuracy =  0.315\n",
      "j =  100\n",
      "batch_train_accuracy =  0.295\n",
      "j =  150\n",
      "batch_train_accuracy =  0.29\n",
      "j =  200\n",
      "batch_train_accuracy =  0.315\n",
      "lost =  3.70921641636\n",
      "train_cumulative_accuracy :  0.309459983885\n",
      "duree :  938.594237089\n",
      "lost =  3.79524576902\n",
      "test_cumulative_accuracy :  0.30719998911\n",
      "epoch :  10\n",
      "j =  0\n",
      "batch_train_accuracy =  0.345\n",
      "j =  50\n",
      "batch_train_accuracy =  0.315\n",
      "j =  100\n",
      "batch_train_accuracy =  0.3\n",
      "j =  150\n",
      "batch_train_accuracy =  0.285\n",
      "j =  200\n",
      "batch_train_accuracy =  0.305\n",
      "lost =  3.61128043461\n",
      "train_cumulative_accuracy :  0.313319984853\n",
      "duree :  1033.62107205\n",
      "lost =  3.69917218447\n",
      "test_cumulative_accuracy :  0.30989999041\n",
      "epoch :  11\n",
      "j =  0\n",
      "batch_train_accuracy =  0.36\n",
      "j =  50\n",
      "batch_train_accuracy =  0.325\n",
      "j =  100\n",
      "batch_train_accuracy =  0.305\n",
      "j =  150\n",
      "batch_train_accuracy =  0.285\n",
      "j =  200\n",
      "batch_train_accuracy =  0.3\n",
      "lost =  3.52345371723\n",
      "train_cumulative_accuracy :  0.317519984305\n",
      "duree :  1128.64642406\n",
      "lost =  3.61439005852\n",
      "test_cumulative_accuracy :  0.313499990404\n",
      "epoch :  12\n",
      "j =  0\n",
      "batch_train_accuracy =  0.37\n",
      "j =  50\n",
      "batch_train_accuracy =  0.315\n",
      "j =  100\n",
      "batch_train_accuracy =  0.3\n",
      "j =  150\n",
      "batch_train_accuracy =  0.285\n",
      "j =  200\n",
      "batch_train_accuracy =  0.315\n",
      "lost =  3.44428682899\n",
      "train_cumulative_accuracy :  0.320779984355\n",
      "duree :  1223.71142602\n",
      "lost =  3.53769079447\n",
      "test_cumulative_accuracy :  0.317199991047\n",
      "epoch :  13\n",
      "j =  0\n",
      "batch_train_accuracy =  0.365\n",
      "j =  50\n",
      "batch_train_accuracy =  0.335\n",
      "j =  100\n",
      "batch_train_accuracy =  0.295\n",
      "j =  150\n",
      "batch_train_accuracy =  0.295\n",
      "j =  200\n",
      "batch_train_accuracy =  0.325\n",
      "lost =  3.37330813789\n",
      "train_cumulative_accuracy :  0.324099982738\n",
      "duree :  1318.73677015\n",
      "lost =  3.46755772114\n",
      "test_cumulative_accuracy :  0.318099992275\n",
      "epoch :  14\n",
      "j =  0\n",
      "batch_train_accuracy =  0.365\n",
      "j =  50\n",
      "batch_train_accuracy =  0.33\n",
      "j =  100\n",
      "batch_train_accuracy =  0.295\n",
      "j =  150\n",
      "batch_train_accuracy =  0.305\n",
      "j =  200\n",
      "batch_train_accuracy =  0.32\n",
      "lost =  3.30887596893\n",
      "train_cumulative_accuracy :  0.327099982023\n",
      "duree :  1413.76209402\n",
      "lost =  3.40321071148\n",
      "test_cumulative_accuracy :  0.320699989051\n",
      "epoch :  15\n",
      "j =  0\n",
      "batch_train_accuracy =  0.365\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.31\n",
      "j =  150\n",
      "batch_train_accuracy =  0.3\n",
      "j =  200\n",
      "batch_train_accuracy =  0.325\n",
      "lost =  3.24947357845\n",
      "train_cumulative_accuracy :  0.330259980798\n",
      "duree :  1508.77679801\n",
      "lost =  3.34378046513\n",
      "test_cumulative_accuracy :  0.32409998998\n",
      "epoch :  16\n",
      "j =  0\n",
      "batch_train_accuracy =  0.355\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.315\n",
      "j =  150\n",
      "batch_train_accuracy =  0.285\n",
      "j =  200\n",
      "batch_train_accuracy =  0.34\n",
      "lost =  3.19421119213\n",
      "train_cumulative_accuracy :  0.332399983287\n",
      "duree :  1603.80300903\n",
      "lost =  3.28901781321\n",
      "test_cumulative_accuracy :  0.325999988765\n",
      "epoch :  17\n",
      "j =  0\n",
      "batch_train_accuracy =  0.355\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.32\n",
      "j =  150\n",
      "batch_train_accuracy =  0.28\n",
      "j =  200\n",
      "batch_train_accuracy =  0.33\n",
      "lost =  3.1433897047\n",
      "train_cumulative_accuracy :  0.334419983864\n",
      "duree :  1698.82803702\n",
      "lost =  3.23922525883\n",
      "test_cumulative_accuracy :  0.329199988246\n",
      "epoch :  18\n",
      "j =  0\n",
      "batch_train_accuracy =  0.36\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.285\n",
      "j =  200\n",
      "batch_train_accuracy =  0.35\n",
      "lost =  3.09639330864\n",
      "train_cumulative_accuracy :  0.337039983273\n",
      "duree :  1793.85660696\n",
      "lost =  3.19312088966\n",
      "test_cumulative_accuracy :  0.33099998787\n",
      "epoch :  19\n",
      "j =  0\n",
      "batch_train_accuracy =  0.37\n",
      "j =  50\n",
      "batch_train_accuracy =  0.355\n",
      "j =  100\n",
      "batch_train_accuracy =  0.335\n",
      "j =  150\n",
      "batch_train_accuracy =  0.29\n",
      "j =  200\n",
      "batch_train_accuracy =  0.355\n",
      "lost =  3.05282761955\n",
      "train_cumulative_accuracy :  0.339279984236\n",
      "duree :  1888.88126493\n",
      "lost =  3.15008309841\n",
      "test_cumulative_accuracy :  0.335399988294\n",
      "epoch :  20\n",
      "j =  0\n",
      "batch_train_accuracy =  0.375\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.295\n",
      "j =  200\n",
      "batch_train_accuracy =  0.35\n",
      "lost =  3.01204659176\n",
      "train_cumulative_accuracy :  0.341539982796\n",
      "duree :  1983.90462708\n",
      "lost =  3.10955758333\n",
      "test_cumulative_accuracy :  0.337199989259\n",
      "epoch :  21\n",
      "j =  0\n",
      "batch_train_accuracy =  0.375\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.305\n",
      "j =  200\n",
      "batch_train_accuracy =  0.345\n",
      "lost =  2.97368583107\n",
      "train_cumulative_accuracy :  0.343439982772\n",
      "duree :  2078.93215299\n",
      "lost =  3.07117641926\n",
      "test_cumulative_accuracy :  0.337899990082\n",
      "epoch :  22\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.35\n",
      "j =  100\n",
      "batch_train_accuracy =  0.33\n",
      "j =  150\n",
      "batch_train_accuracy =  0.32\n",
      "j =  200\n",
      "batch_train_accuracy =  0.345\n",
      "lost =  2.9372880106\n",
      "train_cumulative_accuracy :  0.345799982071\n",
      "duree :  2173.96072698\n",
      "lost =  3.03458541155\n",
      "test_cumulative_accuracy :  0.340399988145\n",
      "epoch :  23\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.355\n",
      "j =  100\n",
      "batch_train_accuracy =  0.335\n",
      "j =  150\n",
      "batch_train_accuracy =  0.33\n",
      "j =  200\n",
      "batch_train_accuracy =  0.355\n",
      "lost =  2.90324328613\n",
      "train_cumulative_accuracy :  0.347839981198\n",
      "duree :  2268.98713708\n",
      "lost =  3.00029140234\n",
      "test_cumulative_accuracy :  0.342799989581\n",
      "epoch :  24\n",
      "j =  0\n",
      "batch_train_accuracy =  0.385\n",
      "j =  50\n",
      "batch_train_accuracy =  0.365\n",
      "j =  100\n",
      "batch_train_accuracy =  0.335\n",
      "j =  150\n",
      "batch_train_accuracy =  0.33\n",
      "j =  200\n",
      "batch_train_accuracy =  0.355\n",
      "lost =  2.87116449928\n",
      "train_cumulative_accuracy :  0.349719982028\n",
      "duree :  2364.01350713\n",
      "lost =  2.96821331263\n",
      "test_cumulative_accuracy :  0.344699989408\n",
      "epoch :  25\n",
      "j =  0\n",
      "batch_train_accuracy =  0.375\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.335\n",
      "j =  150\n",
      "batch_train_accuracy =  0.33\n",
      "j =  200\n",
      "batch_train_accuracy =  0.36\n",
      "lost =  2.84108572102\n",
      "train_cumulative_accuracy :  0.351739982843\n",
      "duree :  2459.03960204\n",
      "lost =  2.93776531458\n",
      "test_cumulative_accuracy :  0.348099989295\n",
      "epoch :  26\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.38\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.33\n",
      "j =  200\n",
      "batch_train_accuracy =  0.36\n",
      "lost =  2.81245332432\n",
      "train_cumulative_accuracy :  0.35345998323\n",
      "duree :  2554.06086493\n",
      "lost =  2.9084109664\n",
      "test_cumulative_accuracy :  0.349399989545\n",
      "epoch :  27\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.35\n",
      "j =  150\n",
      "batch_train_accuracy =  0.335\n",
      "j =  200\n",
      "batch_train_accuracy =  0.36\n",
      "lost =  2.78527809811\n",
      "train_cumulative_accuracy :  0.354819984198\n",
      "duree :  2649.07487392\n",
      "lost =  2.88125489473\n",
      "test_cumulative_accuracy :  0.350599989295\n",
      "epoch :  28\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.345\n",
      "j =  150\n",
      "batch_train_accuracy =  0.34\n",
      "j =  200\n",
      "batch_train_accuracy =  0.365\n",
      "lost =  2.75951377583\n",
      "train_cumulative_accuracy :  0.356499983788\n",
      "duree :  2744.10680699\n",
      "lost =  2.85598296642\n",
      "test_cumulative_accuracy :  0.351399991214\n",
      "epoch :  29\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.34\n",
      "j =  200\n",
      "batch_train_accuracy =  0.365\n",
      "lost =  2.73524006557\n",
      "train_cumulative_accuracy :  0.357999981284\n",
      "duree :  2839.13776994\n",
      "lost =  2.83268159628\n",
      "test_cumulative_accuracy :  0.353299991786\n",
      "epoch :  30\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.345\n",
      "j =  200\n",
      "batch_train_accuracy =  0.37\n",
      "lost =  2.71201428509\n",
      "train_cumulative_accuracy :  0.359639984131\n",
      "duree :  2934.15988803\n",
      "lost =  2.81062992573\n",
      "test_cumulative_accuracy :  0.354099990427\n",
      "epoch :  31\n",
      "j =  0\n",
      "batch_train_accuracy =  0.385\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.335\n",
      "j =  150\n",
      "batch_train_accuracy =  0.35\n",
      "j =  200\n",
      "batch_train_accuracy =  0.375\n",
      "lost =  2.6899227438\n",
      "train_cumulative_accuracy :  0.361019985676\n",
      "duree :  3029.17397404\n",
      "lost =  2.7887930131\n",
      "test_cumulative_accuracy :  0.355199989527\n",
      "epoch :  32\n",
      "j =  0\n",
      "batch_train_accuracy =  0.38\n",
      "j =  50\n",
      "batch_train_accuracy =  0.385\n",
      "j =  100\n",
      "batch_train_accuracy =  0.34\n",
      "j =  150\n",
      "batch_train_accuracy =  0.345\n",
      "j =  200\n",
      "batch_train_accuracy =  0.38\n",
      "lost =  2.6687811079\n",
      "train_cumulative_accuracy :  0.362379984498\n",
      "duree :  3124.19338894\n",
      "lost =  2.76820352793\n",
      "test_cumulative_accuracy :  0.357299990207\n",
      "epoch :  33\n",
      "j =  0\n",
      "batch_train_accuracy =  0.375\n",
      "j =  50\n",
      "batch_train_accuracy =  0.39\n",
      "j =  100\n",
      "batch_train_accuracy =  0.35\n",
      "j =  150\n",
      "batch_train_accuracy =  0.35\n",
      "j =  200\n",
      "batch_train_accuracy =  0.39\n",
      "lost =  2.64863580227\n",
      "train_cumulative_accuracy :  0.36429998529\n",
      "duree :  3219.21086693\n",
      "lost =  2.7479921484\n",
      "test_cumulative_accuracy :  0.357799991667\n",
      "epoch :  34\n",
      "j =  0\n",
      "batch_train_accuracy =  0.375\n",
      "j =  50\n",
      "batch_train_accuracy =  0.395\n",
      "j =  100\n",
      "batch_train_accuracy =  0.35\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.39\n",
      "lost =  2.62918984795\n",
      "train_cumulative_accuracy :  0.365619982243\n",
      "duree :  3314.22122216\n",
      "lost =  2.72823942184\n",
      "test_cumulative_accuracy :  0.358899989873\n",
      "epoch :  35\n",
      "j =  0\n",
      "batch_train_accuracy =  0.39\n",
      "j =  50\n",
      "batch_train_accuracy =  0.395\n",
      "j =  100\n",
      "batch_train_accuracy =  0.355\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.395\n",
      "lost =  2.6104118948\n",
      "train_cumulative_accuracy :  0.366799982548\n",
      "duree :  3409.22708416\n",
      "lost =  2.70936203241\n",
      "test_cumulative_accuracy :  0.359999991059\n",
      "epoch :  36\n",
      "j =  0\n",
      "batch_train_accuracy =  0.39\n",
      "j =  50\n",
      "batch_train_accuracy =  0.4\n",
      "j =  100\n",
      "batch_train_accuracy =  0.355\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.4\n",
      "lost =  2.59233008289\n",
      "train_cumulative_accuracy :  0.367859985232\n",
      "duree :  3504.24444008\n",
      "lost =  2.69148379564\n",
      "test_cumulative_accuracy :  0.360599990785\n",
      "epoch :  37\n",
      "j =  0\n",
      "batch_train_accuracy =  0.39\n",
      "j =  50\n",
      "batch_train_accuracy =  0.4\n",
      "j =  100\n",
      "batch_train_accuracy =  0.37\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.5747773428\n",
      "train_cumulative_accuracy :  0.369139983773\n",
      "duree :  3599.30839109\n",
      "lost =  2.67403217554\n",
      "test_cumulative_accuracy :  0.361699990034\n",
      "epoch :  38\n",
      "j =  0\n",
      "batch_train_accuracy =  0.39\n",
      "j =  50\n",
      "batch_train_accuracy =  0.405\n",
      "j =  100\n",
      "batch_train_accuracy =  0.37\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.55772435951\n",
      "train_cumulative_accuracy :  0.370239983678\n",
      "duree :  3694.33038712\n",
      "lost =  2.65701954842\n",
      "test_cumulative_accuracy :  0.362299988717\n",
      "epoch :  39\n",
      "j =  0\n",
      "batch_train_accuracy =  0.4\n",
      "j =  50\n",
      "batch_train_accuracy =  0.405\n",
      "j =  100\n",
      "batch_train_accuracy =  0.37\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.54124205685\n",
      "train_cumulative_accuracy :  0.37113998282\n",
      "duree :  3789.35082293\n",
      "lost =  2.64065011978\n",
      "test_cumulative_accuracy :  0.364299990088\n",
      "epoch :  40\n",
      "j =  0\n",
      "batch_train_accuracy =  0.4\n",
      "j =  50\n",
      "batch_train_accuracy =  0.41\n",
      "j =  100\n",
      "batch_train_accuracy =  0.38\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.52543676853\n",
      "train_cumulative_accuracy :  0.372599983215\n",
      "duree :  3884.36633301\n",
      "lost =  2.6249691534\n",
      "test_cumulative_accuracy :  0.364599989504\n",
      "epoch :  41\n",
      "j =  0\n",
      "batch_train_accuracy =  0.405\n",
      "j =  50\n",
      "batch_train_accuracy =  0.415\n",
      "j =  100\n",
      "batch_train_accuracy =  0.375\n",
      "j =  150\n",
      "batch_train_accuracy =  0.355\n",
      "j =  200\n",
      "batch_train_accuracy =  0.41\n",
      "lost =  2.51025005722\n",
      "train_cumulative_accuracy :  0.373459984303\n",
      "duree :  3979.39222813\n",
      "lost =  2.60969716549\n",
      "test_cumulative_accuracy :  0.366499990374\n",
      "epoch :  42\n",
      "j =  0\n",
      "batch_train_accuracy =  0.405\n",
      "j =  50\n",
      "batch_train_accuracy =  0.415\n",
      "j =  100\n",
      "batch_train_accuracy =  0.38\n",
      "j =  150\n",
      "batch_train_accuracy =  0.36\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.49557295036\n",
      "train_cumulative_accuracy :  0.374419982195\n",
      "duree :  4074.41378212\n",
      "lost =  2.59483821869\n",
      "test_cumulative_accuracy :  0.367799992561\n",
      "epoch :  43\n",
      "j =  0\n",
      "batch_train_accuracy =  0.405\n",
      "j =  50\n",
      "batch_train_accuracy =  0.415\n",
      "j =  100\n",
      "batch_train_accuracy =  0.37\n",
      "j =  150\n",
      "batch_train_accuracy =  0.36\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.4813296423\n",
      "train_cumulative_accuracy :  0.374899982572\n",
      "duree :  4169.44025993\n",
      "lost =  2.58044477463\n",
      "test_cumulative_accuracy :  0.369299990535\n",
      "epoch :  44\n",
      "j =  0\n",
      "batch_train_accuracy =  0.415\n",
      "j =  50\n",
      "batch_train_accuracy =  0.42\n",
      "j =  100\n",
      "batch_train_accuracy =  0.38\n",
      "j =  150\n",
      "batch_train_accuracy =  0.365\n",
      "j =  200\n",
      "batch_train_accuracy =  0.4\n",
      "lost =  2.46743800354\n",
      "train_cumulative_accuracy :  0.376039983153\n",
      "duree :  4264.48720193\n",
      "lost =  2.56654938459\n",
      "test_cumulative_accuracy :  0.369099988937\n",
      "epoch :  45\n",
      "j =  0\n",
      "batch_train_accuracy =  0.415\n",
      "j =  50\n",
      "batch_train_accuracy =  0.42\n",
      "j =  100\n",
      "batch_train_accuracy =  0.38\n",
      "j =  150\n",
      "batch_train_accuracy =  0.365\n",
      "j =  200\n",
      "batch_train_accuracy =  0.405\n",
      "lost =  2.45380324268\n",
      "train_cumulative_accuracy :  0.3771399827\n",
      "duree :  4359.60642695\n",
      "lost =  2.55300902605\n",
      "test_cumulative_accuracy :  0.369099986553\n",
      "epoch :  46\n",
      "j =  0\n",
      "batch_train_accuracy =  0.415\n",
      "j =  50\n",
      "batch_train_accuracy =  0.415\n",
      "j =  100\n",
      "batch_train_accuracy =  0.39\n",
      "j =  150\n",
      "batch_train_accuracy =  0.365\n",
      "j =  200\n",
      "batch_train_accuracy =  0.41\n",
      "lost =  2.44050878334\n",
      "train_cumulative_accuracy :  0.378099982858\n",
      "duree :  4454.71901703\n",
      "lost =  2.53956851125\n",
      "test_cumulative_accuracy :  0.370899987221\n",
      "epoch :  47\n",
      "j =  0\n",
      "batch_train_accuracy =  0.41\n",
      "j =  50\n",
      "batch_train_accuracy =  0.405\n",
      "j =  100\n",
      "batch_train_accuracy =  0.395\n",
      "j =  150\n",
      "batch_train_accuracy =  0.365\n",
      "j =  200\n",
      "batch_train_accuracy =  0.41\n",
      "lost =  2.42760040283\n",
      "train_cumulative_accuracy :  0.378519982696\n",
      "duree :  4549.83691716\n",
      "lost =  2.52671751499\n",
      "test_cumulative_accuracy :  0.37109998703\n",
      "epoch :  48\n",
      "j =  0\n",
      "batch_train_accuracy =  0.405\n",
      "j =  50\n",
      "batch_train_accuracy =  0.405\n",
      "j =  100\n",
      "batch_train_accuracy =  0.395\n",
      "j =  150\n",
      "batch_train_accuracy =  0.365\n",
      "j =  200\n",
      "batch_train_accuracy =  0.41\n",
      "lost =  2.41499177265\n",
      "train_cumulative_accuracy :  0.379259982467\n",
      "duree :  4644.95181513\n",
      "lost =  2.51413675308\n",
      "test_cumulative_accuracy :  0.372999988794\n",
      "epoch :  49\n",
      "j =  0\n",
      "batch_train_accuracy =  0.405\n",
      "j =  50\n",
      "batch_train_accuracy =  0.405\n",
      "j =  100\n",
      "batch_train_accuracy =  0.39\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-4\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/opt_compare/adagrad/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    #keep_prob_input = tf.placeholder(tf.float32)\n",
    "    #keep_prob_layers=tf.placeholder(tf.float32)\n",
    "    #phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "       \n",
    "    'wc1': tf.Variable(tf.truncated_normal([3, 3, 3, 48], stddev=0.1), name = \"w1\"),\n",
    "    'wc2': tf.Variable(tf.truncated_normal([3, 3, 48, 48], stddev=0.1), name = \"w2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.Variable(tf.truncated_normal([3, 3, 48, 96], stddev=0.1), name = \"w3\"),\n",
    "    'wc4': tf.Variable(tf.truncated_normal([3, 3, 96, 96], stddev=0.1), name = \"w4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'wc5': tf.Variable(tf.truncated_normal([3, 3, 96, 192], stddev=0.1), name = \"w5\"),\n",
    "    'wc6': tf.Variable(tf.truncated_normal([3, 3, 192, 192], stddev=0.1), name = \"w6\"),\n",
    "    'wc7': tf.Variable(tf.truncated_normal([12288, 512], stddev=0.1), name = \"w7\"),\n",
    "    'wc8': tf.Variable(tf.truncated_normal([512, 256], stddev=0.1), name = \"w8\"),\n",
    "    'wc9': tf.Variable(tf.truncated_normal([256, 10], stddev=0.1), name = \"w9\"),\n",
    "}\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.truncated_normal([10], stddev=0.1), name = \"w9\"),\n",
    "}\n",
    "    \n",
    "    # Create model\n",
    "    #x_image = tf.reshape(x,[-1,28,28,1])\n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_image, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc1']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.relu(hidden_1)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc2']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.relu(hidden_2)\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc3']\n",
    "#hidden_3_bn = batch_norm(hidden_3, 32, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.relu(hidden_3)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc4']\n",
    "#hidden_4_bn = batch_norm(hidden_4, 64, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.relu(hidden_4)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME') \n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc5']\n",
    "#hidden_5_bn = batch_norm(hidden_5, 192, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.relu(hidden_5)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc6']\n",
    "#hidden_6_bn = batch_norm(hidden_6, 192, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.relu(hidden_6)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "fc_1 = tf.matmul(slim.flatten(hidden_6_relu), weights['wc7']) + biases['bc7']\n",
    "fc_1_relu = tf.nn.relu(fc_1)\n",
    "print(fc_1_relu.get_shape())\n",
    "\n",
    "fc_2 = tf.matmul(fc_1_relu, weights['wc8']) + biases['bc8']\n",
    "fc_2_relu = tf.nn.relu(fc_2)\n",
    "print(fc_2_relu.get_shape())\n",
    "\n",
    "out_y = tf.matmul(fc_2_relu, weights['wc9']) + biases['bc9']\n",
    "print(out_y.get_shape())\n",
    "\n",
    "'''''\n",
    "hidden_5 = tf.nn.conv2d(hidden_4_relu, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_5_bn = batch_norm(hidden_5, 64, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.elu(hidden_5_bn)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 2, 2, 1], padding='SAME')\n",
    "hidden_6_bn = batch_norm(hidden_6, 64, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.elu(hidden_6_bn)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "hidden_6_do=tf.nn.dropout(hidden_6_relu, keep_prob=keep_prob_layers)\n",
    "\n",
    "hidden_7 = tf.nn.conv2d(hidden_6_do, weights['wc7'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_7_bn = batch_norm(hidden_7, 64, phase_train, convolutional = True)\n",
    "hidden_7_relu = tf.nn.elu(hidden_7_bn)\n",
    "print(hidden_7_relu.get_shape())\n",
    "\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_relu, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc7']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.nn.conv2d(hidden_8_relu, weights['wc9'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_9_relu = tf.nn.elu(hidden_9)\n",
    "print(hidden_9_relu.get_shape())\n",
    "\n",
    "out_x = tf.nn.avg_pool(hidden_9_relu, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding=\"VALID\")\n",
    "print(out_x.get_shape())\n",
    "out_y = tf.reshape(out_x,(-1,10))\n",
    "print(out_y.get_shape())\n",
    "'''\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#tf.scalar_summary(\"cost\", cost)\n",
    "#tf.scalar_summary(\"accuracy\", accuracy)\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "train_cost_array = list()\n",
    "train_acc_array = list()\n",
    "test_cost_array = list()\n",
    "test_acc_array = list()\n",
    "epoch_array = list()\n",
    "\n",
    "gen_batch = create_batches(200,True)\n",
    "gen_batch2 = create_batches(100,False)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    while(True):\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(250):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%50 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], feed_dict={x: img, y: lbl})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 250 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 250 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/250\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/250\n",
    "            \n",
    "            epoch_array.append(epoch)\n",
    "            train_cost_array.append(train_cost)\n",
    "            train_acc_array.append(train_cumulative_accuracy)\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], feed_dict={x: img2, y: lbl2})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            test_cost_array.append(train_cost)\n",
    "            test_acc_array.append(train_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
