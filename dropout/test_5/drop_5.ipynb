{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cPickle\n",
    "import collections\n",
    "import Image, ImageDraw\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_concatenate():\n",
    "    \n",
    "    img = np.zeros([50000,3072])\n",
    "    lbl = np.zeros([50000])\n",
    "    for i in range(5):\n",
    "        with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/data_batch_'+str(i+1),'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "        for j in range(10000):\n",
    "            img[j+10000*i] = data['data'][j]\n",
    "            lbl[j+10000*i] = data['labels'][j]\n",
    "        \n",
    "        #print(lbl)\n",
    "        #print(\"//////////////////////////////////////////////\")\n",
    "        \n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/test_batch','rb') as f:\n",
    "    data2 = cPickle.load(f)\n",
    "    test_labels = np.asarray(data2['labels'])\n",
    "    test_data = np.asarray(data2['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = cifar10_concatenate()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_reshape(data):\n",
    "    \n",
    "    size = data.shape[0]\n",
    "    img = np.zeros([size,3072])\n",
    "    \n",
    "    for i in range(size):\n",
    "        imageToUse = data[i]\n",
    "        \n",
    "        image = imageToUse.reshape(3,32,32).transpose(1,2,0)\n",
    "        elmn = image.flatten()\n",
    "        \n",
    "        img[i] = elmn\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalisation(array):\n",
    "    \n",
    "    array = array.astype('float32')\n",
    "    array_nomalized = array / 255.0       \n",
    "    return array_nomalized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_preparation():\n",
    "    \n",
    "    train_reshape = cifar10_reshape(train_data)\n",
    "    test_reshape = cifar10_reshape(test_data)\n",
    "    print(\"reshape done\")\n",
    "    \n",
    "    norm_train_data = normalisation(train_reshape)\n",
    "    norm_test_data = normalisation(test_reshape)\n",
    "    print(\"normalisation done\")\n",
    "    \n",
    "    #flip_train = flip_cifar10(norm_train_data)\n",
    "    #print(\"flip done\")\n",
    "    \n",
    "    #data_train_set = np.concatenate((norm_train_data, flip_train), axis=0)\n",
    "    #label_train_set = np.concatenate((train_labels, train_labels), axis = 0)\n",
    "    \n",
    "    return norm_train_data, norm_test_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape done\n",
      "normalisation done\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a,b = cifar10_preparation()\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batches(batch_size, isTrain):\n",
    "    \n",
    "    while (True):\n",
    "        if isTrain:\n",
    "            for i in xrange(0, len(train_labels), batch_size):\n",
    "                yield(a[i:i+batch_size],train_labels[i:i+batch_size])\n",
    "        else:\n",
    "            for i in xrange(0, len(test_labels), batch_size):\n",
    "                yield(b[i:i+batch_size],test_labels[i:i+batch_size])     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "48\n",
      "1296\n",
      "(3, 3, 48, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "48\n",
      "20736\n",
      "(3, 3, 48, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "96\n",
      "41472\n",
      "(3, 3, 96, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "96\n",
      "82944\n",
      "(3, 3, 96, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "192\n",
      "165888\n",
      "(3, 3, 192, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "192\n",
      "192\n",
      "331776\n",
      "(1, 1, 192, 192)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "192\n",
      "36864\n",
      "(3072, 512)\n",
      "2\n",
      "3072\n",
      "512\n",
      "1572864\n",
      "(512, 256)\n",
      "2\n",
      "512\n",
      "256\n",
      "131072\n",
      "(256, 10)\n",
      "2\n",
      "256\n",
      "10\n",
      "2560\n",
      "(48,)\n",
      "1\n",
      "48\n",
      "48\n",
      "(48,)\n",
      "1\n",
      "48\n",
      "48\n",
      "(96,)\n",
      "1\n",
      "96\n",
      "96\n",
      "(96,)\n",
      "1\n",
      "96\n",
      "96\n",
      "(192,)\n",
      "1\n",
      "192\n",
      "192\n",
      "(192,)\n",
      "1\n",
      "192\n",
      "192\n",
      "(192,)\n",
      "1\n",
      "192\n",
      "192\n",
      "(512,)\n",
      "1\n",
      "512\n",
      "512\n",
      "(256,)\n",
      "1\n",
      "256\n",
      "256\n",
      "(10,)\n",
      "1\n",
      "10\n",
      "10\n",
      "total_parameters :  2389114\n",
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 512)\n",
      "(?, 256)\n",
      "WARNING:tensorflow:From <ipython-input-10-c52f08e5a747>:177 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-10-c52f08e5a747>:178 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-10-c52f08e5a747>:185 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  0\n",
      "j =  0\n",
      "batch_train_accuracy =  0.136\n",
      "j =  80\n",
      "batch_train_accuracy =  0.08\n",
      "j =  160\n",
      "batch_train_accuracy =  0.216\n",
      "j =  240\n",
      "batch_train_accuracy =  0.264\n",
      "j =  320\n",
      "batch_train_accuracy =  0.352\n",
      "lost =  2.03031208694\n",
      "train_cumulative_accuracy :  0.225980001036\n",
      "duree :  87.6092848778\n",
      "lost =  1.64720170498\n",
      "test_cumulative_accuracy :  0.373599988818\n",
      "epoch :  1\n",
      "j =  0\n",
      "batch_train_accuracy =  0.44\n",
      "j =  80\n",
      "batch_train_accuracy =  0.44\n",
      "j =  160\n",
      "batch_train_accuracy =  0.384\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.48\n",
      "lost =  1.48587973356\n",
      "train_cumulative_accuracy :  0.442380000651\n",
      "duree :  188.506264925\n",
      "lost =  1.4230803597\n",
      "test_cumulative_accuracy :  0.483799980283\n",
      "epoch :  2\n",
      "j =  0\n",
      "batch_train_accuracy =  0.544\n",
      "j =  80\n",
      "batch_train_accuracy =  0.52\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.608\n",
      "lost =  1.224465736\n",
      "train_cumulative_accuracy :  0.551379995123\n",
      "duree :  291.209879875\n",
      "lost =  1.18409795165\n",
      "test_cumulative_accuracy :  0.575299969316\n",
      "epoch :  3\n",
      "j =  0\n",
      "batch_train_accuracy =  0.648\n",
      "j =  80\n",
      "batch_train_accuracy =  0.608\n",
      "j =  160\n",
      "batch_train_accuracy =  0.584\n",
      "j =  240\n",
      "batch_train_accuracy =  0.6\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  1.05974682212\n",
      "train_cumulative_accuracy :  0.616239997074\n",
      "duree :  394.096436977\n",
      "lost =  1.05754092455\n",
      "test_cumulative_accuracy :  0.626599968076\n",
      "epoch :  4\n",
      "j =  0\n",
      "batch_train_accuracy =  0.68\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.704\n",
      "j =  320\n",
      "batch_train_accuracy =  0.656\n",
      "lost =  0.944942945838\n",
      "train_cumulative_accuracy :  0.659299996048\n",
      "duree :  496.955693007\n",
      "lost =  0.952655355334\n",
      "test_cumulative_accuracy :  0.667099967003\n",
      "epoch :  5\n",
      "j =  0\n",
      "batch_train_accuracy =  0.704\n",
      "j =  80\n",
      "batch_train_accuracy =  0.704\n",
      "j =  160\n",
      "batch_train_accuracy =  0.672\n",
      "j =  240\n",
      "batch_train_accuracy =  0.712\n",
      "j =  320\n",
      "batch_train_accuracy =  0.704\n",
      "lost =  0.855512160212\n",
      "train_cumulative_accuracy :  0.693079996407\n",
      "duree :  600.652843952\n",
      "lost =  0.909557788372\n",
      "test_cumulative_accuracy :  0.676899970174\n",
      "epoch :  6\n",
      "j =  0\n",
      "batch_train_accuracy =  0.704\n",
      "j =  80\n",
      "batch_train_accuracy =  0.76\n",
      "j =  160\n",
      "batch_train_accuracy =  0.656\n",
      "j =  240\n",
      "batch_train_accuracy =  0.752\n",
      "j =  320\n",
      "batch_train_accuracy =  0.76\n",
      "lost =  0.785427271724\n",
      "train_cumulative_accuracy :  0.71750000149\n",
      "duree :  706.324841022\n",
      "lost =  0.841608618498\n",
      "test_cumulative_accuracy :  0.703799967766\n",
      "epoch :  7\n",
      "j =  0\n",
      "batch_train_accuracy =  0.808\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.752\n",
      "j =  240\n",
      "batch_train_accuracy =  0.72\n",
      "j =  320\n",
      "batch_train_accuracy =  0.744\n",
      "lost =  0.717087814063\n",
      "train_cumulative_accuracy :  0.743380006403\n",
      "duree :  813.067368031\n",
      "lost =  0.844088740349\n",
      "test_cumulative_accuracy :  0.70639996767\n",
      "epoch :  8\n",
      "j =  0\n",
      "batch_train_accuracy =  0.808\n",
      "j =  80\n",
      "batch_train_accuracy =  0.768\n",
      "j =  160\n",
      "batch_train_accuracy =  0.712\n",
      "j =  240\n",
      "batch_train_accuracy =  0.784\n",
      "j =  320\n",
      "batch_train_accuracy =  0.8\n",
      "lost =  0.665495222956\n",
      "train_cumulative_accuracy :  0.764760006666\n",
      "duree :  918.879216909\n",
      "lost =  0.850496737957\n",
      "test_cumulative_accuracy :  0.70819996655\n",
      "epoch :  9\n",
      "j =  0\n",
      "batch_train_accuracy =  0.752\n",
      "j =  80\n",
      "batch_train_accuracy =  0.824\n",
      "j =  160\n",
      "batch_train_accuracy =  0.744\n",
      "j =  240\n",
      "batch_train_accuracy =  0.808\n",
      "j =  320\n",
      "batch_train_accuracy =  0.76\n",
      "lost =  0.620140943676\n",
      "train_cumulative_accuracy :  0.779560009241\n",
      "duree :  1022.10265183\n",
      "lost =  0.728353444934\n",
      "test_cumulative_accuracy :  0.747699972987\n",
      "epoch :  10\n",
      "j =  0\n",
      "batch_train_accuracy =  0.816\n",
      "j =  80\n",
      "batch_train_accuracy =  0.808\n",
      "j =  160\n",
      "batch_train_accuracy =  0.776\n",
      "j =  240\n",
      "batch_train_accuracy =  0.832\n",
      "j =  320\n",
      "batch_train_accuracy =  0.776\n",
      "lost =  0.584888672009\n",
      "train_cumulative_accuracy :  0.793120010644\n",
      "duree :  1125.47011781\n",
      "lost =  0.797830146551\n",
      "test_cumulative_accuracy :  0.72939997375\n",
      "epoch :  11\n",
      "j =  0\n",
      "batch_train_accuracy =  0.776\n",
      "j =  80\n",
      "batch_train_accuracy =  0.808\n",
      "j =  160\n",
      "batch_train_accuracy =  0.768\n",
      "j =  240\n",
      "batch_train_accuracy =  0.816\n",
      "j =  320\n",
      "batch_train_accuracy =  0.824\n",
      "lost =  0.551382057294\n",
      "train_cumulative_accuracy :  0.804200016111\n",
      "duree :  1230.02837086\n",
      "lost =  0.74777130276\n",
      "test_cumulative_accuracy :  0.746199973822\n",
      "epoch :  12\n",
      "j =  0\n",
      "batch_train_accuracy =  0.864\n",
      "j =  80\n",
      "batch_train_accuracy =  0.856\n",
      "j =  160\n",
      "batch_train_accuracy =  0.776\n",
      "j =  240\n",
      "batch_train_accuracy =  0.84\n",
      "j =  320\n",
      "batch_train_accuracy =  0.872\n",
      "lost =  0.520638735667\n",
      "train_cumulative_accuracy :  0.816400015652\n",
      "duree :  1331.04495788\n",
      "lost =  0.722579625249\n",
      "test_cumulative_accuracy :  0.75619997561\n",
      "epoch :  13\n",
      "j =  0\n",
      "batch_train_accuracy =  0.816\n",
      "j =  80\n",
      "batch_train_accuracy =  0.872\n",
      "j =  160\n",
      "batch_train_accuracy =  0.776\n",
      "j =  240\n",
      "batch_train_accuracy =  0.848\n",
      "j =  320\n",
      "batch_train_accuracy =  0.84\n",
      "lost =  0.493660183847\n",
      "train_cumulative_accuracy :  0.823900015801\n",
      "duree :  1431.79631686\n",
      "lost =  0.722791732252\n",
      "test_cumulative_accuracy :  0.753699973822\n",
      "epoch :  14\n",
      "j =  0\n",
      "batch_train_accuracy =  0.816\n",
      "j =  80\n",
      "batch_train_accuracy =  0.848\n",
      "j =  160\n",
      "batch_train_accuracy =  0.824\n",
      "j =  240\n",
      "batch_train_accuracy =  0.848\n",
      "j =  320\n",
      "batch_train_accuracy =  0.856\n",
      "lost =  0.469285174087\n",
      "train_cumulative_accuracy :  0.83466001749\n",
      "duree :  1532.46261001\n",
      "lost =  0.65303004235\n",
      "test_cumulative_accuracy :  0.778899974227\n",
      "epoch :  15\n",
      "j =  0\n",
      "batch_train_accuracy =  0.872\n",
      "j =  80\n",
      "batch_train_accuracy =  0.848\n",
      "j =  160\n",
      "batch_train_accuracy =  0.776\n",
      "j =  240\n",
      "batch_train_accuracy =  0.84\n",
      "j =  320\n",
      "batch_train_accuracy =  0.848\n",
      "lost =  0.451031455919\n",
      "train_cumulative_accuracy :  0.840540019423\n",
      "duree :  1633.12985897\n",
      "lost =  0.660820126832\n",
      "test_cumulative_accuracy :  0.771999981999\n",
      "epoch :  16\n",
      "j =  0\n",
      "batch_train_accuracy =  0.84\n",
      "j =  80\n",
      "batch_train_accuracy =  0.864\n",
      "j =  160\n",
      "batch_train_accuracy =  0.824\n",
      "j =  240\n",
      "batch_train_accuracy =  0.872\n",
      "j =  320\n",
      "batch_train_accuracy =  0.888\n",
      "lost =  0.429392715245\n",
      "train_cumulative_accuracy :  0.847720020413\n",
      "duree :  1733.7933228\n",
      "lost =  0.651369147301\n",
      "test_cumulative_accuracy :  0.78109998107\n",
      "epoch :  17\n",
      "j =  0\n",
      "batch_train_accuracy =  0.848\n",
      "j =  80\n",
      "batch_train_accuracy =  0.848\n",
      "j =  160\n",
      "batch_train_accuracy =  0.848\n",
      "j =  240\n",
      "batch_train_accuracy =  0.848\n",
      "j =  320\n",
      "batch_train_accuracy =  0.864\n",
      "lost =  0.417250677869\n",
      "train_cumulative_accuracy :  0.852540020645\n",
      "duree :  1834.94012094\n",
      "lost =  0.669177895188\n",
      "test_cumulative_accuracy :  0.769399980307\n",
      "epoch :  18\n",
      "j =  0\n",
      "batch_train_accuracy =  0.848\n",
      "j =  80\n",
      "batch_train_accuracy =  0.88\n",
      "j =  160\n",
      "batch_train_accuracy =  0.816\n",
      "j =  240\n",
      "batch_train_accuracy =  0.864\n",
      "j =  320\n",
      "batch_train_accuracy =  0.896\n",
      "lost =  0.403780959547\n",
      "train_cumulative_accuracy :  0.859300021529\n",
      "duree :  1936.59407592\n",
      "lost =  0.662738045454\n",
      "test_cumulative_accuracy :  0.775399976373\n",
      "epoch :  19\n",
      "j =  0\n",
      "batch_train_accuracy =  0.88\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.84\n",
      "j =  240\n",
      "batch_train_accuracy =  0.864\n",
      "j =  320\n",
      "batch_train_accuracy =  0.824\n",
      "lost =  0.38812928468\n",
      "train_cumulative_accuracy :  0.864220024645\n",
      "duree :  2037.87718582\n",
      "lost =  0.637809483409\n",
      "test_cumulative_accuracy :  0.780399979353\n",
      "epoch :  20\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.88\n",
      "j =  320\n",
      "batch_train_accuracy =  0.888\n",
      "lost =  0.369317689724\n",
      "train_cumulative_accuracy :  0.871200025678\n",
      "duree :  2139.68582892\n",
      "lost =  0.622214131355\n",
      "test_cumulative_accuracy :  0.792399981618\n",
      "epoch :  21\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.848\n",
      "j =  240\n",
      "batch_train_accuracy =  0.88\n",
      "j =  320\n",
      "batch_train_accuracy =  0.872\n",
      "lost =  0.367933811583\n",
      "train_cumulative_accuracy :  0.871040024906\n",
      "duree :  2241.08310294\n",
      "lost =  0.631335451007\n",
      "test_cumulative_accuracy :  0.787799979448\n",
      "epoch :  22\n",
      "j =  0\n",
      "batch_train_accuracy =  0.88\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.848\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.864\n",
      "lost =  0.358368176334\n",
      "train_cumulative_accuracy :  0.87506002605\n",
      "duree :  2343.29752898\n",
      "lost =  0.598190340996\n",
      "test_cumulative_accuracy :  0.797699970603\n",
      "epoch :  23\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.864\n",
      "j =  240\n",
      "batch_train_accuracy =  0.872\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.343804173134\n",
      "train_cumulative_accuracy :  0.88130002737\n",
      "duree :  2444.95114803\n",
      "lost =  0.629923683405\n",
      "test_cumulative_accuracy :  0.793699977398\n",
      "epoch :  24\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.864\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.888\n",
      "lost =  0.343931454271\n",
      "train_cumulative_accuracy :  0.881100023836\n",
      "duree :  2545.98514986\n",
      "lost =  0.600380762815\n",
      "test_cumulative_accuracy :  0.79749997735\n",
      "epoch :  25\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.872\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.330052586421\n",
      "train_cumulative_accuracy :  0.88708002612\n",
      "duree :  2650.45605803\n",
      "lost =  0.635600079298\n",
      "test_cumulative_accuracy :  0.788699977994\n",
      "epoch :  26\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.888\n",
      "j =  320\n",
      "batch_train_accuracy =  0.896\n",
      "lost =  0.317537420504\n",
      "train_cumulative_accuracy :  0.891180026978\n",
      "duree :  2752.41990399\n",
      "lost =  0.602596136332\n",
      "test_cumulative_accuracy :  0.801299979091\n",
      "epoch :  27\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.856\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.864\n",
      "lost =  0.318425785042\n",
      "train_cumulative_accuracy :  0.890000028014\n",
      "duree :  2854.262959\n",
      "lost =  0.60985298574\n",
      "test_cumulative_accuracy :  0.794499981999\n",
      "epoch :  28\n",
      "j =  0\n",
      "batch_train_accuracy =  0.88\n",
      "j =  80\n",
      "batch_train_accuracy =  0.872\n",
      "j =  160\n",
      "batch_train_accuracy =  0.872\n",
      "j =  240\n",
      "batch_train_accuracy =  0.88\n",
      "j =  320\n",
      "batch_train_accuracy =  0.92\n",
      "lost =  0.308434947468\n",
      "train_cumulative_accuracy :  0.894400026947\n",
      "duree :  2956.53103495\n",
      "lost =  0.607548095584\n",
      "test_cumulative_accuracy :  0.799899978042\n",
      "epoch :  29\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.92\n",
      "j =  160\n",
      "batch_train_accuracy =  0.88\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.912\n",
      "lost =  0.297945088744\n",
      "train_cumulative_accuracy :  0.898700025827\n",
      "duree :  3057.12470698\n",
      "lost =  0.606174463332\n",
      "test_cumulative_accuracy :  0.800899974704\n",
      "epoch :  30\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.88\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.293145983815\n",
      "train_cumulative_accuracy :  0.901340027452\n",
      "duree :  3159.8753798\n",
      "lost =  0.576595308483\n",
      "test_cumulative_accuracy :  0.812499975562\n",
      "epoch :  31\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.286757337488\n",
      "train_cumulative_accuracy :  0.90240002647\n",
      "duree :  3260.46145296\n",
      "lost =  0.608210085332\n",
      "test_cumulative_accuracy :  0.799099975228\n",
      "epoch :  32\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.888\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.27603255935\n",
      "train_cumulative_accuracy :  0.907520030886\n",
      "duree :  3361.30446982\n",
      "lost =  0.572076298892\n",
      "test_cumulative_accuracy :  0.807099980116\n",
      "epoch :  33\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.872\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.279450351074\n",
      "train_cumulative_accuracy :  0.905500028431\n",
      "duree :  3463.51538086\n",
      "lost =  0.59483607471\n",
      "test_cumulative_accuracy :  0.806499978304\n",
      "epoch :  34\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.896\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.912\n",
      "lost =  0.26844782725\n",
      "train_cumulative_accuracy :  0.910160026699\n",
      "duree :  3565.87642193\n",
      "lost =  0.609808117747\n",
      "test_cumulative_accuracy :  0.798299974203\n",
      "epoch :  35\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.856\n",
      "lost =  0.267622731254\n",
      "train_cumulative_accuracy :  0.910680031031\n",
      "duree :  3668.06309986\n",
      "lost =  0.585392308533\n",
      "test_cumulative_accuracy :  0.808799981475\n",
      "epoch :  36\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.92\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.268914488591\n",
      "train_cumulative_accuracy :  0.910460030138\n",
      "duree :  3769.93169785\n",
      "lost =  0.577682617009\n",
      "test_cumulative_accuracy :  0.809599977732\n",
      "epoch :  37\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.912\n",
      "lost =  0.261991604231\n",
      "train_cumulative_accuracy :  0.91194002986\n",
      "duree :  3872.32286286\n",
      "lost =  0.597923094034\n",
      "test_cumulative_accuracy :  0.804199978709\n",
      "epoch :  38\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.92\n",
      "j =  160\n",
      "batch_train_accuracy =  0.864\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.912\n",
      "lost =  0.262140885033\n",
      "train_cumulative_accuracy :  0.911480029523\n",
      "duree :  3976.11193395\n",
      "lost =  0.581296924651\n",
      "test_cumulative_accuracy :  0.806899977922\n",
      "epoch :  39\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.872\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.912\n",
      "lost =  0.252845837772\n",
      "train_cumulative_accuracy :  0.91616002962\n",
      "duree :  4077.18853903\n",
      "lost =  0.565120689571\n",
      "test_cumulative_accuracy :  0.812399982214\n",
      "epoch :  40\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.888\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.246385551617\n",
      "train_cumulative_accuracy :  0.91932002902\n",
      "duree :  4178.21060991\n",
      "lost =  0.570778565109\n",
      "test_cumulative_accuracy :  0.812499979734\n",
      "epoch :  41\n",
      "j =  0\n",
      "batch_train_accuracy =  0.896\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.244370027706\n",
      "train_cumulative_accuracy :  0.918540031314\n",
      "duree :  4278.95835996\n",
      "lost =  0.584126843214\n",
      "test_cumulative_accuracy :  0.813099983335\n",
      "epoch :  42\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.241140933037\n",
      "train_cumulative_accuracy :  0.92000002861\n",
      "duree :  4379.88114381\n",
      "lost =  0.608404333591\n",
      "test_cumulative_accuracy :  0.801099982262\n",
      "epoch :  43\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.234562277794\n",
      "train_cumulative_accuracy :  0.922920027822\n",
      "duree :  4482.45165086\n",
      "lost =  0.585431919694\n",
      "test_cumulative_accuracy :  0.810399982333\n",
      "epoch :  44\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.92\n",
      "lost =  0.239100826252\n",
      "train_cumulative_accuracy :  0.923100032061\n",
      "duree :  4584.97489595\n",
      "lost =  0.640131022036\n",
      "test_cumulative_accuracy :  0.795399975181\n",
      "epoch :  45\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.233595758751\n",
      "train_cumulative_accuracy :  0.925160030276\n",
      "duree :  4685.3642199\n",
      "lost =  0.678211400211\n",
      "test_cumulative_accuracy :  0.791199976206\n",
      "epoch :  46\n",
      "j =  0\n",
      "batch_train_accuracy =  0.888\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.228668289576\n",
      "train_cumulative_accuracy :  0.926960029453\n",
      "duree :  4785.73903489\n",
      "lost =  0.604230442345\n",
      "test_cumulative_accuracy :  0.810999977589\n",
      "epoch :  47\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.222026163414\n",
      "train_cumulative_accuracy :  0.928980030566\n",
      "duree :  4886.11952782\n",
      "lost =  0.591898594499\n",
      "test_cumulative_accuracy :  0.805199979544\n",
      "epoch :  48\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.92\n",
      "lost =  0.223690672442\n",
      "train_cumulative_accuracy :  0.9281000337\n",
      "duree :  4986.4961319\n",
      "lost =  0.605637565255\n",
      "test_cumulative_accuracy :  0.81059997797\n",
      "epoch :  49\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.888\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.215077237468\n",
      "train_cumulative_accuracy :  0.931460032016\n",
      "duree :  5086.87048292\n",
      "lost =  0.575113124251\n",
      "test_cumulative_accuracy :  0.817399980426\n",
      "epoch :  50\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.896\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.207851564698\n",
      "train_cumulative_accuracy :  0.933220032305\n",
      "duree :  5187.24740386\n",
      "lost =  0.579896185696\n",
      "test_cumulative_accuracy :  0.808299981952\n",
      "epoch :  51\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.209779735655\n",
      "train_cumulative_accuracy :  0.930780031979\n",
      "duree :  5287.63868093\n",
      "lost =  0.639164409637\n",
      "test_cumulative_accuracy :  0.798199981451\n",
      "epoch :  52\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.92\n",
      "lost =  0.212972741891\n",
      "train_cumulative_accuracy :  0.932260029912\n",
      "duree :  5388.01613688\n",
      "lost =  0.597973999381\n",
      "test_cumulative_accuracy :  0.815399981737\n",
      "epoch :  53\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.211753117163\n",
      "train_cumulative_accuracy :  0.931460033059\n",
      "duree :  5488.45591187\n",
      "lost =  0.589950802326\n",
      "test_cumulative_accuracy :  0.813799980879\n",
      "epoch :  54\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.208947447166\n",
      "train_cumulative_accuracy :  0.932420032471\n",
      "duree :  5588.8403008\n",
      "lost =  0.625228103399\n",
      "test_cumulative_accuracy :  0.807299978733\n",
      "epoch :  55\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.202746222522\n",
      "train_cumulative_accuracy :  0.934440032095\n",
      "duree :  5689.2867918\n",
      "lost =  0.593967148662\n",
      "test_cumulative_accuracy :  0.811299977899\n",
      "epoch :  56\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.200716477986\n",
      "train_cumulative_accuracy :  0.935640035272\n",
      "duree :  5789.67594481\n",
      "lost =  0.632306830883\n",
      "test_cumulative_accuracy :  0.806299975514\n",
      "epoch :  57\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.199489222262\n",
      "train_cumulative_accuracy :  0.935860037953\n",
      "duree :  5890.06759381\n",
      "lost =  0.622856380939\n",
      "test_cumulative_accuracy :  0.810099977851\n",
      "epoch :  58\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.92\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.199600140695\n",
      "train_cumulative_accuracy :  0.937360033989\n",
      "duree :  5990.45455003\n",
      "lost =  0.586961132884\n",
      "test_cumulative_accuracy :  0.820599981546\n",
      "epoch :  59\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.193709408417\n",
      "train_cumulative_accuracy :  0.939680032879\n",
      "duree :  6090.84965181\n",
      "lost =  0.600218427479\n",
      "test_cumulative_accuracy :  0.811299979091\n",
      "epoch :  60\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.197641569134\n",
      "train_cumulative_accuracy :  0.938240033388\n",
      "duree :  6191.25180101\n",
      "lost =  0.601595765352\n",
      "test_cumulative_accuracy :  0.809999978542\n",
      "epoch :  61\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.188337074015\n",
      "train_cumulative_accuracy :  0.942820036262\n",
      "duree :  6291.67543793\n",
      "lost =  0.583958778977\n",
      "test_cumulative_accuracy :  0.813599982262\n",
      "epoch :  62\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.185691633839\n",
      "train_cumulative_accuracy :  0.942440032959\n",
      "duree :  6392.07370687\n",
      "lost =  0.611683898568\n",
      "test_cumulative_accuracy :  0.810499977469\n",
      "epoch :  63\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.191987100225\n",
      "train_cumulative_accuracy :  0.940060031563\n",
      "duree :  6492.46101999\n",
      "lost =  0.569726681113\n",
      "test_cumulative_accuracy :  0.821899982691\n",
      "epoch :  64\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.190397604425\n",
      "train_cumulative_accuracy :  0.940400031656\n",
      "duree :  6595.27804089\n",
      "lost =  0.587420067489\n",
      "test_cumulative_accuracy :  0.818699977994\n",
      "epoch :  65\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.190912081767\n",
      "train_cumulative_accuracy :  0.93942003265\n",
      "duree :  6697.47773385\n",
      "lost =  0.582496975362\n",
      "test_cumulative_accuracy :  0.814599978924\n",
      "epoch :  66\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.185058516525\n",
      "train_cumulative_accuracy :  0.94144003436\n",
      "duree :  6798.36442685\n",
      "lost =  0.582934333384\n",
      "test_cumulative_accuracy :  0.813799984455\n",
      "epoch :  67\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.186910147928\n",
      "train_cumulative_accuracy :  0.941480033845\n",
      "duree :  6898.77499795\n",
      "lost =  0.575602286756\n",
      "test_cumulative_accuracy :  0.81619998455\n",
      "epoch :  68\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.184986384716\n",
      "train_cumulative_accuracy :  0.941220033765\n",
      "duree :  6999.18350387\n",
      "lost =  0.599358285069\n",
      "test_cumulative_accuracy :  0.814399981499\n",
      "epoch :  69\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.178081666511\n",
      "train_cumulative_accuracy :  0.94586003527\n",
      "duree :  7099.78136492\n",
      "lost =  0.57560285151\n",
      "test_cumulative_accuracy :  0.82549998641\n",
      "epoch :  70\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.182008111626\n",
      "train_cumulative_accuracy :  0.943300034553\n",
      "duree :  7200.18811297\n",
      "lost =  0.625362935364\n",
      "test_cumulative_accuracy :  0.811099976301\n",
      "epoch :  71\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.181015511248\n",
      "train_cumulative_accuracy :  0.945160035789\n",
      "duree :  7300.61624599\n",
      "lost =  0.594908063114\n",
      "test_cumulative_accuracy :  0.812799977064\n",
      "epoch :  72\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.174016835522\n",
      "train_cumulative_accuracy :  0.946260033995\n",
      "duree :  7401.03307295\n",
      "lost =  0.596456044316\n",
      "test_cumulative_accuracy :  0.817399979234\n",
      "epoch :  73\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.181451324616\n",
      "train_cumulative_accuracy :  0.944360033721\n",
      "duree :  7501.49972296\n",
      "lost =  0.592594471574\n",
      "test_cumulative_accuracy :  0.812199977636\n",
      "epoch :  74\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.175396608058\n",
      "train_cumulative_accuracy :  0.945960035771\n",
      "duree :  7601.90915489\n",
      "lost =  0.582186776698\n",
      "test_cumulative_accuracy :  0.818699985743\n",
      "epoch :  75\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.179674779978\n",
      "train_cumulative_accuracy :  0.945400032848\n",
      "duree :  7702.32146692\n",
      "lost =  0.589252153933\n",
      "test_cumulative_accuracy :  0.817099983096\n",
      "epoch :  76\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.175654667877\n",
      "train_cumulative_accuracy :  0.948300034255\n",
      "duree :  7802.74037004\n",
      "lost =  0.576651036739\n",
      "test_cumulative_accuracy :  0.820699982643\n",
      "epoch :  77\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.166715015974\n",
      "train_cumulative_accuracy :  0.949540034235\n",
      "duree :  7903.16638494\n",
      "lost =  0.581778783798\n",
      "test_cumulative_accuracy :  0.818499974012\n",
      "epoch :  78\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.177314875145\n",
      "train_cumulative_accuracy :  0.946060033441\n",
      "duree :  8003.59951591\n",
      "lost =  0.572292782068\n",
      "test_cumulative_accuracy :  0.820799981356\n",
      "epoch :  79\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.170040449016\n",
      "train_cumulative_accuracy :  0.947520035356\n",
      "duree :  8104.02866793\n",
      "lost =  0.600522207618\n",
      "test_cumulative_accuracy :  0.814399980903\n",
      "epoch :  80\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.161160555016\n",
      "train_cumulative_accuracy :  0.950840035528\n",
      "duree :  8204.45682192\n",
      "lost =  0.571394677162\n",
      "test_cumulative_accuracy :  0.822499979734\n",
      "epoch :  81\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.167295812014\n",
      "train_cumulative_accuracy :  0.94978003487\n",
      "duree :  8304.86885381\n",
      "lost =  0.569871610701\n",
      "test_cumulative_accuracy :  0.822199979424\n",
      "epoch :  82\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.172554595675\n",
      "train_cumulative_accuracy :  0.949580033571\n",
      "duree :  8405.29025388\n",
      "lost =  0.620531674027\n",
      "test_cumulative_accuracy :  0.806599977612\n",
      "epoch :  83\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c52f08e5a747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m#print(\"j = \",j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                     \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3666\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3668\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/chap3/dropout/test_5/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    prob_1=tf.placeholder(tf.float32)\n",
    "    prob_2=tf.placeholder(tf.float32)\n",
    "    #prob_3=tf.placeholder(tf.float32)\n",
    "    #phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "\n",
    "    'wc1': tf.get_variable(name = \"w1\",shape = [3, 3, 3, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc2': tf.get_variable(name = \"w2\",shape = [3, 3, 48, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.get_variable(name = \"w3\",shape = [3, 3, 48, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc4': tf.get_variable(name = \"w4\",shape = [3, 3, 96, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    'wc5': tf.get_variable(name = \"w5\",shape = [3, 3, 96, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc6': tf.get_variable(name = \"w6\",shape = [3, 3, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc8': tf.Variable(tf.truncated_normal([1, 1, 128, 128], stddev=0.1), name = \"w8\"),\n",
    "    'wc7': tf.get_variable(name = \"w7\",shape = [1, 1, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc8': tf.get_variable(name = \"w8\",shape = [3072, 512], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc9': tf.get_variable(name = \"w9\",shape = [512, 256], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'wc10': tf.get_variable(name = \"w10\",shape = [256, 10], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b9\"),\n",
    "    'bc10': tf.Variable(tf.constant(0.1, shape=[10]), name = \"b10\"),\n",
    "}\n",
    "    \n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parametes = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parametes *= dim.value\n",
    "    print(variable_parametes)\n",
    "    total_parameters += variable_parametes\n",
    "print(\"total_parameters : \",total_parameters)\n",
    "    \n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "#x_bn = batch_norm(x_image, 3, phase_train, convolutional = True)\n",
    "#x_image_do=tf.nn.dropout(x_image, keep_prob=prob_3)\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_image, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc1']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.relu(hidden_1)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc2']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.relu(hidden_2)\n",
    "\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_1_do=tf.nn.dropout(pool_1, keep_prob=prob_1)\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1_do, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc3']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.relu(hidden_3)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc4']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.relu(hidden_4)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_2_do=tf.nn.dropout(pool_2, keep_prob=prob_1)\n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2_do, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc5']\n",
    "#hidden_1_bn = batch_norm(hidden_1, 32, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.relu(hidden_5)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME') + biases['bc6']\n",
    "#hidden_2_bn = batch_norm(hidden_2, 32, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.relu(hidden_6)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "pool_3 = tf.nn.max_pool(hidden_6_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_3_do=tf.nn.dropout(pool_3, keep_prob=prob_1)\n",
    "print(pool_3.get_shape())\n",
    "\n",
    "hidden_7 = tf.nn.conv2d(pool_3_do, weights['wc7'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc7']\n",
    "hidden_7_relu = tf.nn.relu(hidden_7)\n",
    "hidden_7_do=tf.nn.dropout(hidden_7_relu, keep_prob=prob_1)\n",
    "print(hidden_7_relu.get_shape())\n",
    "\n",
    "hidden_8 = tf.matmul(slim.flatten(hidden_7_do), weights['wc8']) + biases['bc8']\n",
    "hidden_8_relu = tf.nn.relu(hidden_8)\n",
    "hidden_8_do = tf.nn.dropout(hidden_8_relu, prob_2)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.matmul(hidden_8_do, weights['wc9']) + biases['bc9']\n",
    "hidden_9_relu = tf.nn.relu(hidden_9)\n",
    "hidden_9_do = tf.nn.dropout(hidden_9_relu, prob_2)\n",
    "print(hidden_9_relu.get_shape())\n",
    "    \n",
    "out_y = tf.matmul(hidden_9_do, weights['wc10']) + biases['bc10']\n",
    "\n",
    "'''\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_relu, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.nn.conv2d(hidden_8_relu, weights['wc9'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc9']\n",
    "hidden_9_relu = tf.nn.elu(hidden_9)\n",
    "print(hidden_9_relu.get_shape())\n",
    "\n",
    "out_x = tf.nn.avg_pool(hidden_9_relu, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding=\"VALID\")\n",
    "print(out_x.get_shape())\n",
    "out_y = tf.reshape(out_x,(-1,10))\n",
    "print(out_y.get_shape())\n",
    "'''\n",
    "\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    while(True):\n",
    "            gen_batch = create_batches(125,True)\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(400):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl, prob_1: 0.75, prob_2:0.5})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl, prob_1: 1., prob_2:1.})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl, prob_1: 1., prob_2:1.})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%80 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], \n",
    "                                                               feed_dict={x: img, y: lbl, prob_1: 1., prob_2:1.})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 400 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 400 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/400\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/400\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            gen_batch2 = create_batches(100,False)\n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2, prob_1: 1., prob_2:1.})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2, prob_1: 1., prob_2:1.})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], \n",
    "                                                         feed_dict={x: img2, y: lbl2, prob_1: 1., prob_2:1.})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
