{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cPickle\n",
    "import collections\n",
    "import Image, ImageDraw\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, convolutional = False, scope='bn'):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        if convolutional:\n",
    "            batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        \n",
    "        else:\n",
    "            batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "        \n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.999)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_concatenate():\n",
    "    \n",
    "    img = np.zeros([50000,3072])\n",
    "    lbl = np.zeros([50000])\n",
    "    for i in range(5):\n",
    "        with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/data_batch_'+str(i+1),'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "        for j in range(10000):\n",
    "            img[j+10000*i] = data['data'][j]\n",
    "            lbl[j+10000*i] = data['labels'][j]\n",
    "        \n",
    "        #print(lbl)\n",
    "        #print(\"//////////////////////////////////////////////\")\n",
    "        \n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/test_batch','rb') as f:\n",
    "    data2 = cPickle.load(f)\n",
    "    test_labels = np.asarray(data2['labels'])\n",
    "    test_data = np.asarray(data2['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = cifar10_concatenate()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_reshape(data):\n",
    "    \n",
    "    size = data.shape[0]\n",
    "    img = np.zeros([size,3072])\n",
    "    \n",
    "    for i in range(size):\n",
    "        imageToUse = data[i]\n",
    "        \n",
    "        image = imageToUse.reshape(3,32,32).transpose(1,2,0)\n",
    "        elmn = image.flatten()\n",
    "        \n",
    "        img[i] = elmn\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalisation(array):\n",
    "    \n",
    "    array = array.astype('float32')\n",
    "    array_nomalized = array / 255.0       \n",
    "    return array_nomalized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_preparation():\n",
    "    \n",
    "    train_reshape = cifar10_reshape(train_data)\n",
    "    test_reshape = cifar10_reshape(test_data)\n",
    "    print(\"reshape done\")\n",
    "    \n",
    "    norm_train_data = normalisation(train_reshape)\n",
    "    norm_test_data = normalisation(test_reshape)\n",
    "    print(\"normalisation done\")\n",
    "    \n",
    "    #flip_train = flip_cifar10(norm_train_data)\n",
    "    #print(\"flip done\")\n",
    "    \n",
    "    #data_train_set = np.concatenate((norm_train_data, flip_train), axis=0)\n",
    "    #label_train_set = np.concatenate((train_labels, train_labels), axis = 0)\n",
    "    \n",
    "    return norm_train_data, norm_test_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape done\n",
      "normalisation done\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a,b = cifar10_preparation()\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batches(batch_size, isTrain):\n",
    "    \n",
    "    while (True):\n",
    "        if isTrain:\n",
    "            for i in xrange(0, len(train_labels), batch_size):\n",
    "                yield(a[i:i+batch_size],train_labels[i:i+batch_size])\n",
    "        else:\n",
    "            for i in xrange(0, len(test_labels), batch_size):\n",
    "                yield(b[i:i+batch_size],test_labels[i:i+batch_size])     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "48\n",
      "1296\n",
      "(3, 3, 48, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "48\n",
      "20736\n",
      "(3, 3, 48, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "96\n",
      "41472\n",
      "(3, 3, 96, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "96\n",
      "82944\n",
      "(3, 3, 96, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "192\n",
      "165888\n",
      "(3, 3, 192, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "192\n",
      "192\n",
      "331776\n",
      "(1, 1, 192, 192)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "192\n",
      "36864\n",
      "(1, 1, 192, 10)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "10\n",
      "1920\n",
      "(192,)\n",
      "1\n",
      "192\n",
      "192\n",
      "(10,)\n",
      "1\n",
      "10\n",
      "10\n",
      "total_parameters :  683098\n",
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 10)\n",
      "(?, 1, 1, 10)\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-11-a0dce8a94073>:159 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-a0dce8a94073>:160 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-a0dce8a94073>:167 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  0\n",
      "j =  0\n",
      "batch_train_accuracy =  0.208\n",
      "j =  80\n",
      "batch_train_accuracy =  0.48\n",
      "j =  160\n",
      "batch_train_accuracy =  0.44\n",
      "j =  240\n",
      "batch_train_accuracy =  0.488\n",
      "j =  320\n",
      "batch_train_accuracy =  0.512\n",
      "lost =  2.07632772774\n",
      "train_cumulative_accuracy :  0.408779997416\n",
      "duree :  108.547029972\n",
      "lost =  2.23689743519\n",
      "test_cumulative_accuracy :  0.446999984682\n",
      "epoch :  1\n",
      "j =  0\n",
      "batch_train_accuracy =  0.472\n",
      "j =  80\n",
      "batch_train_accuracy =  0.488\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.632\n",
      "j =  320\n",
      "batch_train_accuracy =  0.624\n",
      "lost =  1.72961700082\n",
      "train_cumulative_accuracy :  0.52487999402\n",
      "duree :  229.987962961\n",
      "lost =  1.98775458694\n",
      "test_cumulative_accuracy :  0.509299973547\n",
      "epoch :  2\n",
      "j =  0\n",
      "batch_train_accuracy =  0.488\n",
      "j =  80\n",
      "batch_train_accuracy =  0.6\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.64\n",
      "j =  320\n",
      "batch_train_accuracy =  0.696\n",
      "lost =  1.39393748373\n",
      "train_cumulative_accuracy :  0.611059999466\n",
      "duree :  351.241196156\n",
      "lost =  1.1772269547\n",
      "test_cumulative_accuracy :  0.656199965477\n",
      "epoch :  3\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.704\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.696\n",
      "j =  320\n",
      "batch_train_accuracy =  0.744\n",
      "lost =  1.15363332033\n",
      "train_cumulative_accuracy :  0.666399998367\n",
      "duree :  473.109102964\n",
      "lost =  0.969812625647\n",
      "test_cumulative_accuracy :  0.703299971819\n",
      "epoch :  4\n",
      "j =  0\n",
      "batch_train_accuracy =  0.696\n",
      "j =  80\n",
      "batch_train_accuracy =  0.736\n",
      "j =  160\n",
      "batch_train_accuracy =  0.712\n",
      "j =  240\n",
      "batch_train_accuracy =  0.696\n",
      "j =  320\n",
      "batch_train_accuracy =  0.792\n",
      "lost =  1.00187656909\n",
      "train_cumulative_accuracy :  0.705819998682\n",
      "duree :  593.66200614\n",
      "lost =  0.970045183301\n",
      "test_cumulative_accuracy :  0.717499970198\n",
      "epoch :  5\n",
      "j =  0\n",
      "batch_train_accuracy =  0.712\n",
      "j =  80\n",
      "batch_train_accuracy =  0.776\n",
      "j =  160\n",
      "batch_train_accuracy =  0.72\n",
      "j =  240\n",
      "batch_train_accuracy =  0.752\n",
      "j =  320\n",
      "batch_train_accuracy =  0.8\n",
      "lost =  0.822263553292\n",
      "train_cumulative_accuracy :  0.747600004971\n",
      "duree :  714.202803135\n",
      "lost =  0.755171548724\n",
      "test_cumulative_accuracy :  0.760999978185\n",
      "epoch :  6\n",
      "j =  0\n",
      "batch_train_accuracy =  0.792\n",
      "j =  80\n",
      "batch_train_accuracy =  0.792\n",
      "j =  160\n",
      "batch_train_accuracy =  0.792\n",
      "j =  240\n",
      "batch_train_accuracy =  0.712\n",
      "j =  320\n",
      "batch_train_accuracy =  0.784\n",
      "lost =  0.690281612426\n",
      "train_cumulative_accuracy :  0.779840010554\n",
      "duree :  834.669237137\n",
      "lost =  0.677123256922\n",
      "test_cumulative_accuracy :  0.781799979806\n",
      "epoch :  7\n",
      "j =  0\n",
      "batch_train_accuracy =  0.864\n",
      "j =  80\n",
      "batch_train_accuracy =  0.84\n",
      "j =  160\n",
      "batch_train_accuracy =  0.8\n",
      "j =  240\n",
      "batch_train_accuracy =  0.72\n",
      "j =  320\n",
      "batch_train_accuracy =  0.784\n",
      "lost =  0.618446059898\n",
      "train_cumulative_accuracy :  0.801640013754\n",
      "duree :  955.113253117\n",
      "lost =  0.657092555761\n",
      "test_cumulative_accuracy :  0.796399983168\n",
      "epoch :  8\n",
      "j =  0\n",
      "batch_train_accuracy =  0.896\n",
      "j =  80\n",
      "batch_train_accuracy =  0.84\n",
      "j =  160\n",
      "batch_train_accuracy =  0.776\n",
      "j =  240\n",
      "batch_train_accuracy =  0.792\n",
      "j =  320\n",
      "batch_train_accuracy =  0.824\n",
      "lost =  0.581747183688\n",
      "train_cumulative_accuracy :  0.814300015867\n",
      "duree :  1076.31944513\n",
      "lost =  0.693811721504\n",
      "test_cumulative_accuracy :  0.788499978185\n",
      "epoch :  9\n",
      "j =  0\n",
      "batch_train_accuracy =  0.872\n",
      "j =  80\n",
      "batch_train_accuracy =  0.84\n",
      "j =  160\n",
      "batch_train_accuracy =  0.832\n",
      "j =  240\n",
      "batch_train_accuracy =  0.752\n",
      "j =  320\n",
      "batch_train_accuracy =  0.864\n",
      "lost =  0.535227434672\n",
      "train_cumulative_accuracy :  0.826800017506\n",
      "duree :  1197.02342701\n",
      "lost =  0.661381478608\n",
      "test_cumulative_accuracy :  0.795299980044\n",
      "epoch :  10\n",
      "j =  0\n",
      "batch_train_accuracy =  0.848\n",
      "j =  80\n",
      "batch_train_accuracy =  0.872\n",
      "j =  160\n",
      "batch_train_accuracy =  0.808\n",
      "j =  240\n",
      "batch_train_accuracy =  0.792\n",
      "j =  320\n",
      "batch_train_accuracy =  0.84\n",
      "lost =  0.458515269235\n",
      "train_cumulative_accuracy :  0.846200019866\n",
      "duree :  1318.00265098\n",
      "lost =  0.592830839753\n",
      "test_cumulative_accuracy :  0.81119998157\n",
      "epoch :  11\n",
      "j =  0\n",
      "batch_train_accuracy =  0.888\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.856\n",
      "j =  240\n",
      "batch_train_accuracy =  0.832\n",
      "j =  320\n",
      "batch_train_accuracy =  0.88\n",
      "lost =  0.426639670208\n",
      "train_cumulative_accuracy :  0.857460022271\n",
      "duree :  1439.92005205\n",
      "lost =  0.579976379275\n",
      "test_cumulative_accuracy :  0.821499984264\n",
      "epoch :  12\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.872\n",
      "j =  160\n",
      "batch_train_accuracy =  0.872\n",
      "j =  240\n",
      "batch_train_accuracy =  0.84\n",
      "j =  320\n",
      "batch_train_accuracy =  0.872\n",
      "lost =  0.392922374569\n",
      "train_cumulative_accuracy :  0.86944002375\n",
      "duree :  1562.15124297\n",
      "lost =  0.593462229371\n",
      "test_cumulative_accuracy :  0.81839997828\n",
      "epoch :  13\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.872\n",
      "j =  160\n",
      "batch_train_accuracy =  0.88\n",
      "j =  240\n",
      "batch_train_accuracy =  0.848\n",
      "j =  320\n",
      "batch_train_accuracy =  0.864\n",
      "lost =  0.368859583139\n",
      "train_cumulative_accuracy :  0.874520025551\n",
      "duree :  1682.23949313\n",
      "lost =  0.61525177896\n",
      "test_cumulative_accuracy :  0.817799982429\n",
      "epoch :  14\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.872\n",
      "lost =  0.324341939017\n",
      "train_cumulative_accuracy :  0.888280028105\n",
      "duree :  1802.28344107\n",
      "lost =  0.575995900631\n",
      "test_cumulative_accuracy :  0.827399986982\n",
      "epoch :  15\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.88\n",
      "j =  160\n",
      "batch_train_accuracy =  0.896\n",
      "j =  240\n",
      "batch_train_accuracy =  0.864\n",
      "j =  320\n",
      "batch_train_accuracy =  0.864\n",
      "lost =  0.296809845939\n",
      "train_cumulative_accuracy :  0.897360026687\n",
      "duree :  1922.33898211\n",
      "lost =  0.587492839098\n",
      "test_cumulative_accuracy :  0.829599977136\n",
      "epoch :  16\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.92\n",
      "lost =  0.281823768839\n",
      "train_cumulative_accuracy :  0.902440028638\n",
      "duree :  2042.30784297\n",
      "lost =  0.59920407027\n",
      "test_cumulative_accuracy :  0.828999978304\n",
      "epoch :  17\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.896\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.259294899311\n",
      "train_cumulative_accuracy :  0.909380030632\n",
      "duree :  2162.30868411\n",
      "lost =  0.577659646273\n",
      "test_cumulative_accuracy :  0.834999982715\n",
      "epoch :  18\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.912\n",
      "j =  320\n",
      "batch_train_accuracy =  0.88\n",
      "lost =  0.254883909561\n",
      "train_cumulative_accuracy :  0.911100028157\n",
      "duree :  2282.44925404\n",
      "lost =  0.541170508713\n",
      "test_cumulative_accuracy :  0.840499981046\n",
      "epoch :  19\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.904\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.226032132413\n",
      "train_cumulative_accuracy :  0.921120031774\n",
      "duree :  2402.58170509\n",
      "lost =  0.582481183708\n",
      "test_cumulative_accuracy :  0.836799983382\n",
      "epoch :  20\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.904\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.205755624622\n",
      "train_cumulative_accuracy :  0.927620030344\n",
      "duree :  2522.62442303\n",
      "lost =  0.540340449214\n",
      "test_cumulative_accuracy :  0.842399981618\n",
      "epoch :  21\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.19825890094\n",
      "train_cumulative_accuracy :  0.931120033562\n",
      "duree :  2642.72563601\n",
      "lost =  0.504414551258\n",
      "test_cumulative_accuracy :  0.850599990487\n",
      "epoch :  22\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.180377031118\n",
      "train_cumulative_accuracy :  0.936280032247\n",
      "duree :  2763.00743914\n",
      "lost =  0.587800300717\n",
      "test_cumulative_accuracy :  0.843299988508\n",
      "epoch :  23\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.173563570185\n",
      "train_cumulative_accuracy :  0.937980033606\n",
      "duree :  2883.43598604\n",
      "lost =  0.577185076475\n",
      "test_cumulative_accuracy :  0.846599990129\n",
      "epoch :  24\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.153725808589\n",
      "train_cumulative_accuracy :  0.946420034021\n",
      "duree :  3003.83093596\n",
      "lost =  0.536914682388\n",
      "test_cumulative_accuracy :  0.853999984264\n",
      "epoch :  25\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.14423000115\n",
      "train_cumulative_accuracy :  0.948260038942\n",
      "duree :  3124.20681214\n",
      "lost =  0.510580867231\n",
      "test_cumulative_accuracy :  0.857899995446\n",
      "epoch :  26\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.124359047827\n",
      "train_cumulative_accuracy :  0.956940036565\n",
      "duree :  3244.62048411\n",
      "lost =  0.583470306695\n",
      "test_cumulative_accuracy :  0.850899991393\n",
      "epoch :  27\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.122080772584\n",
      "train_cumulative_accuracy :  0.957080035806\n",
      "duree :  3364.99012709\n",
      "lost =  0.498502036631\n",
      "test_cumulative_accuracy :  0.857899993658\n",
      "epoch :  28\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.112079706527\n",
      "train_cumulative_accuracy :  0.961060036868\n",
      "duree :  3485.52639198\n",
      "lost =  0.553317314237\n",
      "test_cumulative_accuracy :  0.851299989223\n",
      "epoch :  29\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.105763106341\n",
      "train_cumulative_accuracy :  0.963380034268\n",
      "duree :  3605.65634799\n",
      "lost =  0.651556746364\n",
      "test_cumulative_accuracy :  0.840599992871\n",
      "epoch :  30\n",
      "j =  0\n",
      "batch_train_accuracy =  0.928\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.123352819863\n",
      "train_cumulative_accuracy :  0.956120035499\n",
      "duree :  3726.76582813\n",
      "lost =  0.587204764485\n",
      "test_cumulative_accuracy :  0.855399997234\n",
      "epoch :  31\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.120214920361\n",
      "train_cumulative_accuracy :  0.956320036948\n",
      "duree :  3847.76393199\n",
      "lost =  0.670600089431\n",
      "test_cumulative_accuracy :  0.838499984145\n",
      "epoch :  32\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0904267636407\n",
      "train_cumulative_accuracy :  0.969080033153\n",
      "duree :  3968.45544195\n",
      "lost =  0.574638244212\n",
      "test_cumulative_accuracy :  0.854199991822\n",
      "epoch :  33\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0853839621227\n",
      "train_cumulative_accuracy :  0.970440034568\n",
      "duree :  4088.39514518\n",
      "lost =  0.530820670277\n",
      "test_cumulative_accuracy :  0.860499996543\n",
      "epoch :  34\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0746842759894\n",
      "train_cumulative_accuracy :  0.973960033655\n",
      "duree :  4209.360955\n",
      "lost =  0.561896347106\n",
      "test_cumulative_accuracy :  0.858999994993\n",
      "epoch :  35\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0705779255973\n",
      "train_cumulative_accuracy :  0.975340029746\n",
      "duree :  4329.17729616\n",
      "lost =  0.741422863305\n",
      "test_cumulative_accuracy :  0.835599987507\n",
      "epoch :  36\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.069607686305\n",
      "train_cumulative_accuracy :  0.975280026346\n",
      "duree :  4449.03953815\n",
      "lost =  0.567814442962\n",
      "test_cumulative_accuracy :  0.857999991179\n",
      "epoch :  37\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0684688279289\n",
      "train_cumulative_accuracy :  0.976160029918\n",
      "duree :  4569.13348603\n",
      "lost =  0.583624221385\n",
      "test_cumulative_accuracy :  0.859199993014\n",
      "epoch :  38\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0584686120076\n",
      "train_cumulative_accuracy :  0.980180025548\n",
      "duree :  4688.92579198\n",
      "lost =  0.64257822901\n",
      "test_cumulative_accuracy :  0.848599995971\n",
      "epoch :  39\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0580313081923\n",
      "train_cumulative_accuracy :  0.980220023096\n",
      "duree :  4808.65630102\n",
      "lost =  0.573259846121\n",
      "test_cumulative_accuracy :  0.858500002027\n",
      "epoch :  40\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0498704402731\n",
      "train_cumulative_accuracy :  0.983440021127\n",
      "duree :  4928.34683418\n",
      "lost =  0.572628302276\n",
      "test_cumulative_accuracy :  0.868000002503\n",
      "epoch :  41\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0486407790938\n",
      "train_cumulative_accuracy :  0.983040018827\n",
      "duree :  5048.20577717\n",
      "lost =  0.581510942727\n",
      "test_cumulative_accuracy :  0.862300002575\n",
      "epoch :  42\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0541955727665\n",
      "train_cumulative_accuracy :  0.980840022415\n",
      "duree :  5167.91277814\n",
      "lost =  0.609365367442\n",
      "test_cumulative_accuracy :  0.860299994946\n",
      "epoch :  43\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0531828293984\n",
      "train_cumulative_accuracy :  0.981880023777\n",
      "duree :  5287.55474615\n",
      "lost =  0.635153499842\n",
      "test_cumulative_accuracy :  0.85619999826\n",
      "epoch :  44\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0513999464712\n",
      "train_cumulative_accuracy :  0.981560021788\n",
      "duree :  5407.323313\n",
      "lost =  0.602548227012\n",
      "test_cumulative_accuracy :  0.861700001955\n",
      "epoch :  45\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0485812154005\n",
      "train_cumulative_accuracy :  0.982940021753\n",
      "duree :  5527.21460295\n",
      "lost =  0.681801082492\n",
      "test_cumulative_accuracy :  0.854199991822\n",
      "epoch :  46\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.0651775777503\n",
      "train_cumulative_accuracy :  0.976440025121\n",
      "duree :  5647.06383514\n",
      "lost =  0.607432188392\n",
      "test_cumulative_accuracy :  0.855699996352\n",
      "epoch :  47\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0469028872298\n",
      "train_cumulative_accuracy :  0.983620021194\n",
      "duree :  5766.80185199\n",
      "lost =  0.696753396988\n",
      "test_cumulative_accuracy :  0.8431999892\n",
      "epoch :  48\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0412522797845\n",
      "train_cumulative_accuracy :  0.985780017525\n",
      "duree :  5886.47637296\n",
      "lost =  0.622923882008\n",
      "test_cumulative_accuracy :  0.864899999499\n",
      "epoch :  49\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0391291262978\n",
      "train_cumulative_accuracy :  0.986800016165\n",
      "duree :  6006.29869795\n",
      "lost =  0.611814543158\n",
      "test_cumulative_accuracy :  0.862599998116\n",
      "epoch :  50\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.0389601373603\n",
      "train_cumulative_accuracy :  0.986980013847\n",
      "duree :  6125.99751902\n",
      "lost =  0.591072511077\n",
      "test_cumulative_accuracy :  0.865099993944\n",
      "epoch :  51\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0406550190679\n",
      "train_cumulative_accuracy :  0.985600016117\n",
      "duree :  6245.71865916\n",
      "lost =  0.56327696234\n",
      "test_cumulative_accuracy :  0.867800002098\n",
      "epoch :  52\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0308964722417\n",
      "train_cumulative_accuracy :  0.989860010147\n",
      "duree :  6365.86420918\n",
      "lost =  0.622714387178\n",
      "test_cumulative_accuracy :  0.863399995565\n",
      "epoch :  53\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0328973908699\n",
      "train_cumulative_accuracy :  0.988560011387\n",
      "duree :  6488.49994206\n",
      "lost =  0.613687842935\n",
      "test_cumulative_accuracy :  0.864499999881\n",
      "epoch :  54\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.035661558857\n",
      "train_cumulative_accuracy :  0.987660012394\n",
      "duree :  6611.38326502\n",
      "lost =  0.613790285289\n",
      "test_cumulative_accuracy :  0.867999998927\n",
      "epoch :  55\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.028795929355\n",
      "train_cumulative_accuracy :  0.990820007026\n",
      "duree :  6734.01180005\n",
      "lost =  0.614260790199\n",
      "test_cumulative_accuracy :  0.866000000238\n",
      "epoch :  56\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0344233257131\n",
      "train_cumulative_accuracy :  0.988120011985\n",
      "duree :  6855.20345306\n",
      "lost =  0.562827873826\n",
      "test_cumulative_accuracy :  0.873299999833\n",
      "epoch :  57\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0347034837876\n",
      "train_cumulative_accuracy :  0.988380011916\n",
      "duree :  6974.8662281\n",
      "lost =  0.612440874726\n",
      "test_cumulative_accuracy :  0.862699994445\n",
      "epoch :  58\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.031097059676\n",
      "train_cumulative_accuracy :  0.98946001038\n",
      "duree :  7094.94369817\n",
      "lost =  0.599103018343\n",
      "test_cumulative_accuracy :  0.865900000334\n",
      "epoch :  59\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0332100520449\n",
      "train_cumulative_accuracy :  0.988120013028\n",
      "duree :  7214.60346818\n",
      "lost =  0.60580771625\n",
      "test_cumulative_accuracy :  0.870700001717\n",
      "epoch :  60\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0254282042803\n",
      "train_cumulative_accuracy :  0.991760006398\n",
      "duree :  7334.44678497\n",
      "lost =  0.680356533229\n",
      "test_cumulative_accuracy :  0.861099994779\n",
      "epoch :  61\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0297416044999\n",
      "train_cumulative_accuracy :  0.989880010039\n",
      "duree :  7454.17800617\n",
      "lost =  0.741254487634\n",
      "test_cumulative_accuracy :  0.847399988174\n",
      "epoch :  62\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0218918515343\n",
      "train_cumulative_accuracy :  0.992740006149\n",
      "duree :  7573.96821404\n",
      "lost =  0.647397794724\n",
      "test_cumulative_accuracy :  0.865000004172\n",
      "epoch :  63\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.019181964806\n",
      "train_cumulative_accuracy :  0.994080005586\n",
      "duree :  7693.63959813\n",
      "lost =  0.667568626106\n",
      "test_cumulative_accuracy :  0.863999998569\n",
      "epoch :  64\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0182841281235\n",
      "train_cumulative_accuracy :  0.99412000522\n",
      "duree :  7813.47059107\n",
      "lost =  0.642994653583\n",
      "test_cumulative_accuracy :  0.872000002265\n",
      "epoch :  65\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0200892753268\n",
      "train_cumulative_accuracy :  0.993520005494\n",
      "duree :  7933.181288\n",
      "lost =  0.72807554394\n",
      "test_cumulative_accuracy :  0.858499997258\n",
      "epoch :  66\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0186205316868\n",
      "train_cumulative_accuracy :  0.994080004245\n",
      "duree :  8052.99296498\n",
      "lost =  0.706851731539\n",
      "test_cumulative_accuracy :  0.857699992061\n",
      "epoch :  67\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0202855016862\n",
      "train_cumulative_accuracy :  0.993500005752\n",
      "duree :  8172.73339605\n",
      "lost =  0.63694533214\n",
      "test_cumulative_accuracy :  0.866499999166\n",
      "epoch :  68\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0245343005043\n",
      "train_cumulative_accuracy :  0.991480006576\n",
      "duree :  8292.53624105\n",
      "lost =  0.68402189672\n",
      "test_cumulative_accuracy :  0.856899998188\n",
      "epoch :  69\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0213731515507\n",
      "train_cumulative_accuracy :  0.992680006325\n",
      "duree :  8412.35214496\n",
      "lost =  0.591934100091\n",
      "test_cumulative_accuracy :  0.873399999738\n",
      "epoch :  70\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.015944195027\n",
      "train_cumulative_accuracy :  0.99510000363\n",
      "duree :  8532.147475\n",
      "lost =  0.621743538082\n",
      "test_cumulative_accuracy :  0.870499997735\n",
      "epoch :  71\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0152394191179\n",
      "train_cumulative_accuracy :  0.995460004359\n",
      "duree :  8651.84507418\n",
      "lost =  0.656703135967\n",
      "test_cumulative_accuracy :  0.869800004363\n",
      "epoch :  72\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0164396999181\n",
      "train_cumulative_accuracy :  0.994820004404\n",
      "duree :  8771.70157003\n",
      "lost =  0.601345975548\n",
      "test_cumulative_accuracy :  0.87470000267\n",
      "epoch :  73\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0235802939875\n",
      "train_cumulative_accuracy :  0.992040007412\n",
      "duree :  8891.41619802\n",
      "lost =  0.655390385091\n",
      "test_cumulative_accuracy :  0.864899999499\n",
      "epoch :  74\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/chap3/gap/test_1/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    prob_1=tf.placeholder(tf.float32)\n",
    "    #prob_2=tf.placeholder(tf.float32)\n",
    "    phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "\n",
    "    'wc1': tf.get_variable(name = \"w1\",shape = [3, 3, 3, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc2': tf.get_variable(name = \"w2\",shape = [3, 3, 48, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.get_variable(name = \"w3\",shape = [3, 3, 48, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc4': tf.get_variable(name = \"w4\",shape = [3, 3, 96, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    'wc5': tf.get_variable(name = \"w5\",shape = [3, 3, 96, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc6': tf.get_variable(name = \"w6\",shape = [3, 3, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc8': tf.Variable(tf.truncated_normal([1, 1, 128, 128], stddev=0.1), name = \"w8\"),\n",
    "    'wc7': tf.get_variable(name = \"w7\",shape = [1, 1, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc8': tf.get_variable(name = \"w8\",shape = [1, 1, 192, 10], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "}\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),   \n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[10]), name = \"b8\"),\n",
    "}\n",
    "\n",
    "'''\n",
    "'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b9\"),\n",
    "'''\n",
    "\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parametes = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parametes *= dim.value\n",
    "    print(variable_parametes)\n",
    "    total_parameters += variable_parametes\n",
    "print(\"total_parameters : \",total_parameters)\n",
    "    \n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "x_bn = batch_norm(x_image, 3, phase_train, convolutional = True)\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_bn, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_1_bn = batch_norm(hidden_1, 48, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.elu(hidden_1_bn)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_2_bn = batch_norm(hidden_2, 48, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.elu(hidden_2_bn)\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_1_do=tf.nn.dropout(pool_1, keep_prob=prob_1)\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1_do, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_3_bn = batch_norm(hidden_3, 96, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.elu(hidden_3_bn)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_4_bn = batch_norm(hidden_4, 96, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.elu(hidden_4_bn)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_2_do=tf.nn.dropout(pool_2, keep_prob=prob_1)\n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2_do, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_5_bn = batch_norm(hidden_5, 192, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.elu(hidden_5_bn)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_6_bn = batch_norm(hidden_6, 192, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.elu(hidden_6_bn)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "pool_3 = tf.nn.max_pool(hidden_6_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_3_do=tf.nn.dropout(pool_3, keep_prob=prob_1)\n",
    "print(pool_3.get_shape())\n",
    "\n",
    "hidden_7 = tf.nn.conv2d(pool_3_do, weights['wc7'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc7']\n",
    "#hidden_7_bn = batch_norm(hidden_7, 192, phase_train, convolutional = True)\n",
    "hidden_7_relu = tf.nn.elu(hidden_7)\n",
    "hidden_7_do=tf.nn.dropout(hidden_7_relu, keep_prob=prob_1)\n",
    "print(hidden_7_relu.get_shape())\n",
    "\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_do, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "gap = tf.nn.avg_pool(hidden_8_relu, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding=\"VALID\")\n",
    "print(gap.get_shape())\n",
    "\n",
    "out_y = tf.reshape(gap, (-1,10))\n",
    "print(out_y.get_shape())\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, {phase_train: True})\n",
    "    while(True):\n",
    "            gen_batch = create_batches(125,True)\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(400):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl, prob_1: 0.75, phase_train: True})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%80 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], \n",
    "                                                               feed_dict={x: img, y: lbl, prob_1:1., phase_train: False})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 400 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 400 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/400\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/400\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            gen_batch2 = create_batches(100,False)\n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], \n",
    "                                                         feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            \n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "48\n",
      "1296\n",
      "(3, 3, 48, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "48\n",
      "20736\n",
      "(3, 3, 48, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "96\n",
      "41472\n",
      "(3, 3, 96, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "96\n",
      "82944\n",
      "(3, 3, 96, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "192\n",
      "165888\n",
      "(3, 3, 192, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "192\n",
      "192\n",
      "331776\n",
      "(1, 1, 192, 192)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "192\n",
      "36864\n",
      "(1, 1, 192, 10)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "10\n",
      "1920\n",
      "(192,)\n",
      "1\n",
      "192\n",
      "192\n",
      "(10,)\n",
      "1\n",
      "10\n",
      "10\n",
      "total_parameters :  683098\n",
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 10)\n",
      "(?, 1, 1, 10)\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-11-26cf6734a02d>:159 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-26cf6734a02d>:160 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-26cf6734a02d>:167 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  74\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0160863239408\n",
      "train_cumulative_accuracy :  0.994760005474\n",
      "duree :  113.162645102\n",
      "lost =  0.589999195486\n",
      "test_cumulative_accuracy :  0.873400005102\n",
      "epoch :  75\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0185214049288\n",
      "train_cumulative_accuracy :  0.994160004705\n",
      "duree :  239.568377972\n",
      "lost =  0.635069662184\n",
      "test_cumulative_accuracy :  0.869600004554\n",
      "epoch :  76\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.016402829217\n",
      "train_cumulative_accuracy :  0.994620004743\n",
      "duree :  363.385945082\n",
      "lost =  0.633991937935\n",
      "test_cumulative_accuracy :  0.874200007319\n",
      "epoch :  77\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0184753888979\n",
      "train_cumulative_accuracy :  0.994400003552\n",
      "duree :  493.484035015\n",
      "lost =  0.618434012681\n",
      "test_cumulative_accuracy :  0.874600009918\n",
      "epoch :  78\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0192627765582\n",
      "train_cumulative_accuracy :  0.993940005749\n",
      "duree :  623.268682003\n",
      "lost =  0.641528251916\n",
      "test_cumulative_accuracy :  0.869800001383\n",
      "epoch :  79\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0238307003456\n",
      "train_cumulative_accuracy :  0.992500005066\n",
      "duree :  746.812373161\n",
      "lost =  0.768505085558\n",
      "test_cumulative_accuracy :  0.854599988461\n",
      "epoch :  80\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/chap3/gap/test_1/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    prob_1=tf.placeholder(tf.float32)\n",
    "    #prob_2=tf.placeholder(tf.float32)\n",
    "    phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "\n",
    "    'wc1': tf.get_variable(name = \"w1\",shape = [3, 3, 3, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc2': tf.get_variable(name = \"w2\",shape = [3, 3, 48, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.get_variable(name = \"w3\",shape = [3, 3, 48, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc4': tf.get_variable(name = \"w4\",shape = [3, 3, 96, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    'wc5': tf.get_variable(name = \"w5\",shape = [3, 3, 96, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc6': tf.get_variable(name = \"w6\",shape = [3, 3, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc8': tf.Variable(tf.truncated_normal([1, 1, 128, 128], stddev=0.1), name = \"w8\"),\n",
    "    'wc7': tf.get_variable(name = \"w7\",shape = [1, 1, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc8': tf.get_variable(name = \"w8\",shape = [1, 1, 192, 10], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "}\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),   \n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[10]), name = \"b8\"),\n",
    "}\n",
    "\n",
    "'''\n",
    "'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b9\"),\n",
    "'''\n",
    "\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parametes = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parametes *= dim.value\n",
    "    print(variable_parametes)\n",
    "    total_parameters += variable_parametes\n",
    "print(\"total_parameters : \",total_parameters)\n",
    "    \n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "x_bn = batch_norm(x_image, 3, phase_train, convolutional = True)\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_bn, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_1_bn = batch_norm(hidden_1, 48, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.elu(hidden_1_bn)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_2_bn = batch_norm(hidden_2, 48, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.elu(hidden_2_bn)\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_1_do=tf.nn.dropout(pool_1, keep_prob=prob_1)\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1_do, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_3_bn = batch_norm(hidden_3, 96, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.elu(hidden_3_bn)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_4_bn = batch_norm(hidden_4, 96, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.elu(hidden_4_bn)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_2_do=tf.nn.dropout(pool_2, keep_prob=prob_1)\n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2_do, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_5_bn = batch_norm(hidden_5, 192, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.elu(hidden_5_bn)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_6_bn = batch_norm(hidden_6, 192, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.elu(hidden_6_bn)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "pool_3 = tf.nn.max_pool(hidden_6_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_3_do=tf.nn.dropout(pool_3, keep_prob=prob_1)\n",
    "print(pool_3.get_shape())\n",
    "\n",
    "hidden_7 = tf.nn.conv2d(pool_3_do, weights['wc7'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc7']\n",
    "#hidden_7_bn = batch_norm(hidden_7, 192, phase_train, convolutional = True)\n",
    "hidden_7_relu = tf.nn.elu(hidden_7)\n",
    "hidden_7_do=tf.nn.dropout(hidden_7_relu, keep_prob=prob_1)\n",
    "print(hidden_7_relu.get_shape())\n",
    "\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_do, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "gap = tf.nn.avg_pool(hidden_8_relu, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding=\"VALID\")\n",
    "print(gap.get_shape())\n",
    "\n",
    "out_y = tf.reshape(gap, (-1,10))\n",
    "print(out_y.get_shape())\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 74\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, {phase_train: True})\n",
    "    saver.restore(sess, \"./73_model.ckpt\")\n",
    "    while(True):\n",
    "            gen_batch = create_batches(125,True)\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(400):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl, prob_1: 0.75, phase_train: True})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%80 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], \n",
    "                                                               feed_dict={x: img, y: lbl, prob_1:1., phase_train: False})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 400 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 400 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/400\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/400\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            gen_batch2 = create_batches(100,False)\n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], \n",
    "                                                         feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            \n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
