{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cPickle\n",
    "import collections\n",
    "import Image, ImageDraw\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, convolutional = False, scope='bn'):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        if convolutional:\n",
    "            batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        \n",
    "        else:\n",
    "            batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "        \n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.999)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_concatenate():\n",
    "    \n",
    "    img = np.zeros([50000,3072])\n",
    "    lbl = np.zeros([50000])\n",
    "    for i in range(5):\n",
    "        with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/data_batch_'+str(i+1),'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "        for j in range(10000):\n",
    "            img[j+10000*i] = data['data'][j]\n",
    "            lbl[j+10000*i] = data['labels'][j]\n",
    "        \n",
    "        #print(lbl)\n",
    "        #print(\"//////////////////////////////////////////////\")\n",
    "        \n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/test_batch','rb') as f:\n",
    "    data2 = cPickle.load(f)\n",
    "    test_labels = np.asarray(data2['labels'])\n",
    "    test_data = np.asarray(data2['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = cifar10_concatenate()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_reshape(data):\n",
    "    \n",
    "    size = data.shape[0]\n",
    "    img = np.zeros([size,3072])\n",
    "    \n",
    "    for i in range(size):\n",
    "        imageToUse = data[i]\n",
    "        \n",
    "        image = imageToUse.reshape(3,32,32).transpose(1,2,0)\n",
    "        elmn = image.flatten()\n",
    "        \n",
    "        img[i] = elmn\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalisation(array):\n",
    "    \n",
    "    array = array.astype('float32')\n",
    "    array_nomalized = array / 255.0       \n",
    "    return array_nomalized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_preparation():\n",
    "    \n",
    "    train_reshape = cifar10_reshape(train_data)\n",
    "    test_reshape = cifar10_reshape(test_data)\n",
    "    print(\"reshape done\")\n",
    "    \n",
    "    norm_train_data = normalisation(train_reshape)\n",
    "    norm_test_data = normalisation(test_reshape)\n",
    "    print(\"normalisation done\")\n",
    "    \n",
    "    #flip_train = flip_cifar10(norm_train_data)\n",
    "    #print(\"flip done\")\n",
    "    \n",
    "    #data_train_set = np.concatenate((norm_train_data, flip_train), axis=0)\n",
    "    #label_train_set = np.concatenate((train_labels, train_labels), axis = 0)\n",
    "    \n",
    "    return norm_train_data, norm_test_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape done\n",
      "normalisation done\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a,b = cifar10_preparation()\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batches(batch_size, isTrain):\n",
    "    \n",
    "    while (True):\n",
    "        if isTrain:\n",
    "            for i in xrange(0, len(train_labels), batch_size):\n",
    "                yield(a[i:i+batch_size],train_labels[i:i+batch_size])\n",
    "        else:\n",
    "            for i in xrange(0, len(test_labels), batch_size):\n",
    "                yield(b[i:i+batch_size],test_labels[i:i+batch_size])     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "48\n",
      "1296\n",
      "(3, 3, 48, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "48\n",
      "20736\n",
      "(3, 3, 48, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "96\n",
      "41472\n",
      "(3, 3, 96, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "96\n",
      "82944\n",
      "(3, 3, 96, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "192\n",
      "165888\n",
      "(3, 3, 192, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "192\n",
      "192\n",
      "331776\n",
      "(1, 1, 192, 192)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "192\n",
      "36864\n",
      "(1, 1, 192, 192)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "192\n",
      "36864\n",
      "(1, 1, 192, 10)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "10\n",
      "1920\n",
      "(10,)\n",
      "1\n",
      "10\n",
      "10\n",
      "total_parameters :  719770\n",
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 10)\n",
      "(?, 1, 1, 10)\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-11-bb24d26def3f>:201 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-bb24d26def3f>:202 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-bb24d26def3f>:209 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  0\n",
      "j =  0\n",
      "batch_train_accuracy =  0.152\n",
      "j =  80\n",
      "batch_train_accuracy =  0.272\n",
      "j =  160\n",
      "batch_train_accuracy =  0.384\n",
      "j =  240\n",
      "batch_train_accuracy =  0.344\n",
      "j =  320\n",
      "batch_train_accuracy =  0.52\n",
      "lost =  2.65027394295\n",
      "train_cumulative_accuracy :  0.366299999058\n",
      "duree :  113.401176929\n",
      "lost =  3.01434479475\n",
      "test_cumulative_accuracy :  0.36229998827\n",
      "epoch :  1\n",
      "j =  0\n",
      "batch_train_accuracy =  0.336\n",
      "j =  80\n",
      "batch_train_accuracy =  0.448\n",
      "j =  160\n",
      "batch_train_accuracy =  0.512\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.38302256972\n",
      "train_cumulative_accuracy :  0.45905999735\n",
      "duree :  244.8666749\n",
      "lost =  1.93279143333\n",
      "test_cumulative_accuracy :  0.542799969316\n",
      "epoch :  2\n",
      "j =  0\n",
      "batch_train_accuracy =  0.528\n",
      "j =  80\n",
      "batch_train_accuracy =  0.464\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  2.27198432803\n",
      "train_cumulative_accuracy :  0.507419996262\n",
      "duree :  378.12635088\n",
      "lost =  1.68724610806\n",
      "test_cumulative_accuracy :  0.589999965131\n",
      "epoch :  3\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.504\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.64\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  1.74437736213\n",
      "train_cumulative_accuracy :  0.58579999581\n",
      "duree :  509.0383358\n",
      "lost =  1.37209836602\n",
      "test_cumulative_accuracy :  0.640399970412\n",
      "epoch :  4\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.6\n",
      "j =  160\n",
      "batch_train_accuracy =  0.664\n",
      "j =  240\n",
      "batch_train_accuracy =  0.64\n",
      "j =  320\n",
      "batch_train_accuracy =  0.68\n",
      "lost =  1.40068932131\n",
      "train_cumulative_accuracy :  0.64307999745\n",
      "duree :  642.333268881\n",
      "lost =  1.0718081224\n",
      "test_cumulative_accuracy :  0.700899968147\n",
      "epoch :  5\n",
      "j =  0\n",
      "batch_train_accuracy =  0.712\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.736\n",
      "j =  240\n",
      "batch_train_accuracy =  0.68\n",
      "j =  320\n",
      "batch_train_accuracy =  0.744\n",
      "lost =  0.993066446409\n",
      "train_cumulative_accuracy :  0.716820000559\n",
      "duree :  776.711097002\n",
      "lost =  0.935351734161\n",
      "test_cumulative_accuracy :  0.732099973559\n",
      "epoch :  6\n",
      "j =  0\n",
      "batch_train_accuracy =  0.792\n",
      "j =  80\n",
      "batch_train_accuracy =  0.736\n",
      "j =  160\n",
      "batch_train_accuracy =  0.696\n",
      "j =  240\n",
      "batch_train_accuracy =  0.752\n",
      "j =  320\n",
      "batch_train_accuracy =  0.76\n",
      "lost =  0.880190833881\n",
      "train_cumulative_accuracy :  0.747780004591\n",
      "duree :  910.418936968\n",
      "lost =  0.835357750058\n",
      "test_cumulative_accuracy :  0.756099983454\n",
      "epoch :  7\n",
      "j =  0\n",
      "batch_train_accuracy =  0.84\n",
      "j =  80\n",
      "batch_train_accuracy =  0.76\n",
      "j =  160\n",
      "batch_train_accuracy =  0.72\n",
      "j =  240\n",
      "batch_train_accuracy =  0.768\n",
      "j =  320\n",
      "batch_train_accuracy =  0.784\n",
      "lost =  0.751268366277\n",
      "train_cumulative_accuracy :  0.775300010592\n",
      "duree :  1042.33874702\n",
      "lost =  0.857049591839\n",
      "test_cumulative_accuracy :  0.760599977374\n",
      "epoch :  8\n",
      "j =  0\n",
      "batch_train_accuracy =  0.824\n",
      "j =  80\n",
      "batch_train_accuracy =  0.768\n",
      "j =  160\n",
      "batch_train_accuracy =  0.712\n",
      "j =  240\n",
      "batch_train_accuracy =  0.752\n",
      "j =  320\n",
      "batch_train_accuracy =  0.784\n",
      "lost =  0.701680501699\n",
      "train_cumulative_accuracy :  0.788680010438\n",
      "duree :  1173.30380201\n",
      "lost =  0.813739743829\n",
      "test_cumulative_accuracy :  0.764999979734\n",
      "epoch :  9\n",
      "j =  0\n",
      "batch_train_accuracy =  0.8\n",
      "j =  80\n",
      "batch_train_accuracy =  0.824\n",
      "j =  160\n",
      "batch_train_accuracy =  0.776\n",
      "j =  240\n",
      "batch_train_accuracy =  0.768\n",
      "j =  320\n",
      "batch_train_accuracy =  0.816\n",
      "lost =  0.617152020559\n",
      "train_cumulative_accuracy :  0.807800015211\n",
      "duree :  1302.17381692\n",
      "lost =  0.894144715667\n",
      "test_cumulative_accuracy :  0.757599980235\n",
      "epoch :  10\n",
      "j =  0\n",
      "batch_train_accuracy =  0.768\n",
      "j =  80\n",
      "batch_train_accuracy =  0.824\n",
      "j =  160\n",
      "batch_train_accuracy =  0.784\n",
      "j =  240\n",
      "batch_train_accuracy =  0.784\n",
      "j =  320\n",
      "batch_train_accuracy =  0.808\n",
      "lost =  0.564075852185\n",
      "train_cumulative_accuracy :  0.821660017222\n",
      "duree :  1430.50567102\n",
      "lost =  0.712645898461\n",
      "test_cumulative_accuracy :  0.790699980855\n",
      "epoch :  11\n",
      "j =  0\n",
      "batch_train_accuracy =  0.856\n",
      "j =  80\n",
      "batch_train_accuracy =  0.824\n",
      "j =  160\n",
      "batch_train_accuracy =  0.784\n",
      "j =  240\n",
      "batch_train_accuracy =  0.816\n",
      "j =  320\n",
      "batch_train_accuracy =  0.848\n",
      "lost =  0.518844979107\n",
      "train_cumulative_accuracy :  0.835280017257\n",
      "duree :  1558.86628294\n",
      "lost =  0.768800267279\n",
      "test_cumulative_accuracy :  0.791599982381\n",
      "epoch :  12\n",
      "j =  0\n",
      "batch_train_accuracy =  0.856\n",
      "j =  80\n",
      "batch_train_accuracy =  0.872\n",
      "j =  160\n",
      "batch_train_accuracy =  0.808\n",
      "j =  240\n",
      "batch_train_accuracy =  0.8\n",
      "j =  320\n",
      "batch_train_accuracy =  0.856\n",
      "lost =  0.448380465731\n",
      "train_cumulative_accuracy :  0.853640022427\n",
      "duree :  1687.19779086\n",
      "lost =  0.679016083181\n",
      "test_cumulative_accuracy :  0.801899982095\n",
      "epoch :  13\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.84\n",
      "j =  160\n",
      "batch_train_accuracy =  0.832\n",
      "j =  240\n",
      "batch_train_accuracy =  0.816\n",
      "j =  320\n",
      "batch_train_accuracy =  0.84\n",
      "lost =  0.435069689304\n",
      "train_cumulative_accuracy :  0.856880024523\n",
      "duree :  1815.505723\n",
      "lost =  0.659833139479\n",
      "test_cumulative_accuracy :  0.808899978995\n",
      "epoch :  14\n",
      "j =  0\n",
      "batch_train_accuracy =  0.904\n",
      "j =  80\n",
      "batch_train_accuracy =  0.832\n",
      "j =  160\n",
      "batch_train_accuracy =  0.88\n",
      "j =  240\n",
      "batch_train_accuracy =  0.808\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.384290834256\n",
      "train_cumulative_accuracy :  0.870660023987\n",
      "duree :  1945.74112391\n",
      "lost =  0.644638190866\n",
      "test_cumulative_accuracy :  0.819599980712\n",
      "epoch :  15\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.824\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.896\n",
      "lost =  0.368236101456\n",
      "train_cumulative_accuracy :  0.876400024593\n",
      "duree :  2074.13437796\n",
      "lost =  0.638781828284\n",
      "test_cumulative_accuracy :  0.821599978805\n",
      "epoch :  16\n",
      "j =  0\n",
      "batch_train_accuracy =  0.896\n",
      "j =  80\n",
      "batch_train_accuracy =  0.88\n",
      "j =  160\n",
      "batch_train_accuracy =  0.864\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.888\n",
      "lost =  0.346407792792\n",
      "train_cumulative_accuracy :  0.882860025764\n",
      "duree :  2203.16830587\n",
      "lost =  0.732756490707\n",
      "test_cumulative_accuracy :  0.80559997797\n",
      "epoch :  17\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.848\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.318808502387\n",
      "train_cumulative_accuracy :  0.889880027622\n",
      "duree :  2331.83448195\n",
      "lost =  0.593650710583\n",
      "test_cumulative_accuracy :  0.831899983287\n",
      "epoch :  18\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.84\n",
      "j =  320\n",
      "batch_train_accuracy =  0.912\n",
      "lost =  0.300186219811\n",
      "train_cumulative_accuracy :  0.897060027122\n",
      "duree :  2461.33531594\n",
      "lost =  0.636713566482\n",
      "test_cumulative_accuracy :  0.826799977422\n",
      "epoch :  19\n",
      "j =  0\n",
      "batch_train_accuracy =  0.888\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.896\n",
      "j =  240\n",
      "batch_train_accuracy =  0.88\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.262201867756\n",
      "train_cumulative_accuracy :  0.908780029863\n",
      "duree :  2589.87695384\n",
      "lost =  0.618416529894\n",
      "test_cumulative_accuracy :  0.834999983311\n",
      "epoch :  20\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.888\n",
      "j =  240\n",
      "batch_train_accuracy =  0.856\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.286344367247\n",
      "train_cumulative_accuracy :  0.902160027623\n",
      "duree :  2720.10329795\n",
      "lost =  0.688217607439\n",
      "test_cumulative_accuracy :  0.823799977899\n",
      "epoch :  21\n",
      "j =  0\n",
      "batch_train_accuracy =  0.92\n",
      "j =  80\n",
      "batch_train_accuracy =  0.888\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.25607782241\n",
      "train_cumulative_accuracy :  0.911400029212\n",
      "duree :  2850.00134897\n",
      "lost =  0.638250144422\n",
      "test_cumulative_accuracy :  0.836899982095\n",
      "epoch :  22\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.224375343127\n",
      "train_cumulative_accuracy :  0.921600031853\n",
      "duree :  2979.82186985\n",
      "lost =  0.701519638896\n",
      "test_cumulative_accuracy :  0.829599986076\n",
      "epoch :  23\n",
      "j =  0\n",
      "batch_train_accuracy =  0.912\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.22028143133\n",
      "train_cumulative_accuracy :  0.923400032222\n",
      "duree :  3112.62419295\n",
      "lost =  0.625763540566\n",
      "test_cumulative_accuracy :  0.838299987912\n",
      "epoch :  24\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.896\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.928\n",
      "lost =  0.20691447706\n",
      "train_cumulative_accuracy :  0.929080032259\n",
      "duree :  3242.5096848\n",
      "lost =  0.654143045396\n",
      "test_cumulative_accuracy :  0.837899984717\n",
      "epoch :  25\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.16948207756\n",
      "train_cumulative_accuracy :  0.940460032374\n",
      "duree :  3371.579005\n",
      "lost =  0.594875354022\n",
      "test_cumulative_accuracy :  0.848299988508\n",
      "epoch :  26\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.150282171108\n",
      "train_cumulative_accuracy :  0.945380035192\n",
      "duree :  3502.14337492\n",
      "lost =  0.588518608212\n",
      "test_cumulative_accuracy :  0.851899985671\n",
      "epoch :  27\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.154061688017\n",
      "train_cumulative_accuracy :  0.944300034195\n",
      "duree :  3631.22998381\n",
      "lost =  0.775563927591\n",
      "test_cumulative_accuracy :  0.824599978328\n",
      "epoch :  28\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.159345382992\n",
      "train_cumulative_accuracy :  0.943920034319\n",
      "duree :  3761.26581383\n",
      "lost =  0.791380013824\n",
      "test_cumulative_accuracy :  0.821399980783\n",
      "epoch :  29\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.928\n",
      "j =  240\n",
      "batch_train_accuracy =  0.896\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.19390733582\n",
      "train_cumulative_accuracy :  0.933320033252\n",
      "duree :  3890.37668896\n",
      "lost =  0.798826317787\n",
      "test_cumulative_accuracy :  0.822699980736\n",
      "epoch :  30\n",
      "j =  0\n",
      "batch_train_accuracy =  0.944\n",
      "j =  80\n",
      "batch_train_accuracy =  0.904\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.178489051657\n",
      "train_cumulative_accuracy :  0.939440034032\n",
      "duree :  4019.94382095\n",
      "lost =  0.832222325504\n",
      "test_cumulative_accuracy :  0.821299984455\n",
      "epoch :  31\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.156030636672\n",
      "train_cumulative_accuracy :  0.946480033696\n",
      "duree :  4149.44030499\n",
      "lost =  0.744253133535\n",
      "test_cumulative_accuracy :  0.83889999032\n",
      "epoch :  32\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.12038193075\n",
      "train_cumulative_accuracy :  0.956920035779\n",
      "duree :  4278.92424703\n",
      "lost =  0.676497378051\n",
      "test_cumulative_accuracy :  0.847099999189\n",
      "epoch :  33\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.139007766298\n",
      "train_cumulative_accuracy :  0.951300034821\n",
      "duree :  4408.35233498\n",
      "lost =  0.711013005674\n",
      "test_cumulative_accuracy :  0.842399991751\n",
      "epoch :  34\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.133208702067\n",
      "train_cumulative_accuracy :  0.953540033102\n",
      "duree :  4537.70976496\n",
      "lost =  0.703520452976\n",
      "test_cumulative_accuracy :  0.849399989843\n",
      "epoch :  35\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.107129302116\n",
      "train_cumulative_accuracy :  0.962320032418\n",
      "duree :  4666.71939993\n",
      "lost =  0.687151970863\n",
      "test_cumulative_accuracy :  0.846999988556\n",
      "epoch :  36\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.904\n",
      "lost =  0.0972202028194\n",
      "train_cumulative_accuracy :  0.964360033274\n",
      "duree :  4795.258255\n",
      "lost =  0.733231629431\n",
      "test_cumulative_accuracy :  0.840699990392\n",
      "epoch :  37\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.111804085081\n",
      "train_cumulative_accuracy :  0.96138003692\n",
      "duree :  4924.59059\n",
      "lost =  0.680883649588\n",
      "test_cumulative_accuracy :  0.843399989009\n",
      "epoch :  38\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.92\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.113131358682\n",
      "train_cumulative_accuracy :  0.96026003316\n",
      "duree :  5053.90832496\n",
      "lost =  0.712693780661\n",
      "test_cumulative_accuracy :  0.847899990678\n",
      "epoch :  39\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.111011958136\n",
      "train_cumulative_accuracy :  0.961600034833\n",
      "duree :  5183.15143204\n",
      "lost =  0.771111252904\n",
      "test_cumulative_accuracy :  0.841799992919\n",
      "epoch :  40\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.944\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.108961553448\n",
      "train_cumulative_accuracy :  0.961960031837\n",
      "duree :  5312.54663587\n",
      "lost =  0.827676113397\n",
      "test_cumulative_accuracy :  0.836899985671\n",
      "epoch :  41\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.928\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.0982382394059\n",
      "train_cumulative_accuracy :  0.964960033447\n",
      "duree :  5441.405828\n",
      "lost =  0.780231448412\n",
      "test_cumulative_accuracy :  0.842599986196\n",
      "epoch :  42\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.107920541691\n",
      "train_cumulative_accuracy :  0.962200032622\n",
      "duree :  5570.66408992\n",
      "lost =  1.02783731282\n",
      "test_cumulative_accuracy :  0.812999979258\n",
      "epoch :  43\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0946249940898\n",
      "train_cumulative_accuracy :  0.966560031772\n",
      "duree :  5700.37139487\n",
      "lost =  0.878556502759\n",
      "test_cumulative_accuracy :  0.833099981546\n",
      "epoch :  44\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0942781396653\n",
      "train_cumulative_accuracy :  0.967180030495\n",
      "duree :  5829.98862886\n",
      "lost =  0.691307966709\n",
      "test_cumulative_accuracy :  0.85219999373\n",
      "epoch :  45\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.108677643621\n",
      "train_cumulative_accuracy :  0.963720032126\n",
      "duree :  5959.48659682\n",
      "lost =  0.703091888428\n",
      "test_cumulative_accuracy :  0.855299990773\n",
      "epoch :  46\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0716600738617\n",
      "train_cumulative_accuracy :  0.974520024359\n",
      "duree :  6088.43241191\n",
      "lost =  1.02125295162\n",
      "test_cumulative_accuracy :  0.832299987078\n",
      "epoch :  47\n",
      "j =  0\n",
      "batch_train_accuracy =  0.936\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.106133500611\n",
      "train_cumulative_accuracy :  0.963660031706\n",
      "duree :  6217.60151386\n",
      "lost =  1.15253185451\n",
      "test_cumulative_accuracy :  0.808699985147\n",
      "epoch :  48\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.92\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0977374153142\n",
      "train_cumulative_accuracy :  0.967060032189\n",
      "duree :  6350.18429494\n",
      "lost =  0.863266049027\n",
      "test_cumulative_accuracy :  0.836399985552\n",
      "epoch :  49\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.0771459125669\n",
      "train_cumulative_accuracy :  0.972280030847\n",
      "duree :  6481.48195386\n",
      "lost =  0.76138905406\n",
      "test_cumulative_accuracy :  0.851899990439\n",
      "epoch :  50\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0535386167758\n",
      "train_cumulative_accuracy :  0.981300021559\n",
      "duree :  6610.1456039\n",
      "lost =  0.749211601913\n",
      "test_cumulative_accuracy :  0.849399989247\n",
      "epoch :  51\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0881988594442\n",
      "train_cumulative_accuracy :  0.969800026715\n",
      "duree :  6741.23908997\n",
      "lost =  0.769886567593\n",
      "test_cumulative_accuracy :  0.847899988294\n",
      "epoch :  52\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.928\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.110641372992\n",
      "train_cumulative_accuracy :  0.963020030856\n",
      "duree :  6869.64270282\n",
      "lost =  0.860944638848\n",
      "test_cumulative_accuracy :  0.840699991584\n",
      "epoch :  53\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0732063048688\n",
      "train_cumulative_accuracy :  0.97410002768\n",
      "duree :  6999.35558581\n",
      "lost =  0.844242502451\n",
      "test_cumulative_accuracy :  0.840299985409\n",
      "epoch :  54\n",
      "j =  0\n",
      "batch_train_accuracy =  0.96\n",
      "j =  80\n",
      "batch_train_accuracy =  0.936\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0690128113888\n",
      "train_cumulative_accuracy :  0.975720026195\n",
      "duree :  7128.27335\n",
      "lost =  0.729622374773\n",
      "test_cumulative_accuracy :  0.855\n",
      "epoch :  55\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.0619178260746\n",
      "train_cumulative_accuracy :  0.977420025915\n",
      "duree :  7258.41278601\n",
      "lost =  0.778477728069\n",
      "test_cumulative_accuracy :  0.852299990654\n",
      "epoch :  56\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.936\n",
      "lost =  0.083435176108\n",
      "train_cumulative_accuracy :  0.972120025754\n",
      "duree :  7389.17660284\n",
      "lost =  0.731658094078\n",
      "test_cumulative_accuracy :  0.860499995351\n",
      "epoch :  57\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0779381361231\n",
      "train_cumulative_accuracy :  0.973320024908\n",
      "duree :  7520.73787284\n",
      "lost =  0.973063869178\n",
      "test_cumulative_accuracy :  0.831299984455\n",
      "epoch :  58\n",
      "j =  0\n",
      "batch_train_accuracy =  0.968\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.0786863051952\n",
      "train_cumulative_accuracy :  0.973800020069\n",
      "duree :  7650.36335588\n",
      "lost =  0.807393913865\n",
      "test_cumulative_accuracy :  0.845999985337\n",
      "epoch :  59\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0768019909924\n",
      "train_cumulative_accuracy :  0.974740023166\n",
      "duree :  7781.05123997\n",
      "lost =  0.78525395453\n",
      "test_cumulative_accuracy :  0.847999988794\n",
      "epoch :  60\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0837584628473\n",
      "train_cumulative_accuracy :  0.971740026325\n",
      "duree :  7912.6563518\n",
      "lost =  0.708634150326\n",
      "test_cumulative_accuracy :  0.864599999189\n",
      "epoch :  61\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0901490697186\n",
      "train_cumulative_accuracy :  0.970320025235\n",
      "duree :  8044.3362999\n",
      "lost =  0.645073011369\n",
      "test_cumulative_accuracy :  0.871099997759\n",
      "epoch :  62\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0552862178849\n",
      "train_cumulative_accuracy :  0.981040015817\n",
      "duree :  8174.86050391\n",
      "lost =  0.811169879138\n",
      "test_cumulative_accuracy :  0.845699992776\n",
      "epoch :  63\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.0809222109817\n",
      "train_cumulative_accuracy :  0.973100029528\n",
      "duree :  8305.59400988\n",
      "lost =  0.700290244818\n",
      "test_cumulative_accuracy :  0.866199994683\n",
      "epoch :  64\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.0801853426854\n",
      "train_cumulative_accuracy :  0.974460024685\n",
      "duree :  8438.35109186\n",
      "lost =  0.733882491887\n",
      "test_cumulative_accuracy :  0.864799997807\n",
      "epoch :  65\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0848165502015\n",
      "train_cumulative_accuracy :  0.972940027565\n",
      "duree :  8569.74650788\n",
      "lost =  0.811843890846\n",
      "test_cumulative_accuracy :  0.857099995017\n",
      "epoch :  66\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.060329457194\n",
      "train_cumulative_accuracy :  0.979440022111\n",
      "duree :  8699.05605698\n",
      "lost =  0.804640081525\n",
      "test_cumulative_accuracy :  0.854999994636\n",
      "epoch :  67\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0610237471724\n",
      "train_cumulative_accuracy :  0.979140020609\n",
      "duree :  8829.35060382\n",
      "lost =  0.654576291293\n",
      "test_cumulative_accuracy :  0.873100001812\n",
      "epoch :  68\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0344033538571\n",
      "train_cumulative_accuracy :  0.988020014167\n",
      "duree :  8959.64513302\n",
      "lost =  0.833389624655\n",
      "test_cumulative_accuracy :  0.850399990082\n",
      "epoch :  69\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.952\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0744177872798\n",
      "train_cumulative_accuracy :  0.97514002353\n",
      "duree :  9089.38121796\n",
      "lost =  0.770512910783\n",
      "test_cumulative_accuracy :  0.861000003219\n",
      "epoch :  70\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0503615634827\n",
      "train_cumulative_accuracy :  0.982960017025\n",
      "duree :  9218.78325891\n",
      "lost =  0.716975382268\n",
      "test_cumulative_accuracy :  0.86349999249\n",
      "epoch :  71\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.0503715588123\n",
      "train_cumulative_accuracy :  0.982760018408\n",
      "duree :  9349.83938289\n",
      "lost =  0.75311445713\n",
      "test_cumulative_accuracy :  0.862599998713\n",
      "epoch :  72\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0510825876147\n",
      "train_cumulative_accuracy :  0.982240020037\n",
      "duree :  9481.5737288\n",
      "lost =  0.846427702308\n",
      "test_cumulative_accuracy :  0.851199991107\n",
      "epoch :  73\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.96\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0515050555841\n",
      "train_cumulative_accuracy :  0.982180019915\n",
      "duree :  9610.75552201\n",
      "lost =  0.886495161653\n",
      "test_cumulative_accuracy :  0.853499994278\n",
      "epoch :  74\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0711934426511\n",
      "train_cumulative_accuracy :  0.976800020188\n",
      "duree :  9739.8224349\n",
      "lost =  0.903372012973\n",
      "test_cumulative_accuracy :  0.850099995136\n",
      "epoch :  75\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.057083834918\n",
      "train_cumulative_accuracy :  0.981240024418\n",
      "duree :  9868.77365303\n",
      "lost =  0.934845535457\n",
      "test_cumulative_accuracy :  0.849099985957\n",
      "epoch :  76\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0652904922083\n",
      "train_cumulative_accuracy :  0.9792400226\n",
      "duree :  9997.81505299\n",
      "lost =  0.792314654291\n",
      "test_cumulative_accuracy :  0.862299987078\n",
      "epoch :  77\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0402690579325\n",
      "train_cumulative_accuracy :  0.986160016507\n",
      "duree :  10127.3926618\n",
      "lost =  1.09641199619\n",
      "test_cumulative_accuracy :  0.82469997704\n",
      "epoch :  78\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0455651896691\n",
      "train_cumulative_accuracy :  0.983580018282\n",
      "duree :  10256.5410099\n",
      "lost =  0.797716112137\n",
      "test_cumulative_accuracy :  0.856899997592\n",
      "epoch :  79\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0428255609726\n",
      "train_cumulative_accuracy :  0.985360014141\n",
      "duree :  10385.6233459\n",
      "lost =  0.936727877855\n",
      "test_cumulative_accuracy :  0.848499993682\n",
      "epoch :  80\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.944\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0865918869522\n",
      "train_cumulative_accuracy :  0.972500031292\n",
      "duree :  10515.9263098\n",
      "lost =  0.91633693248\n",
      "test_cumulative_accuracy :  0.854899993539\n",
      "epoch :  81\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0486030412183\n",
      "train_cumulative_accuracy :  0.983440022618\n",
      "duree :  10646.9938378\n",
      "lost =  0.784773827493\n",
      "test_cumulative_accuracy :  0.861999992132\n",
      "epoch :  82\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.952\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0517014862091\n",
      "train_cumulative_accuracy :  0.982820019722\n",
      "duree :  10782.668756\n",
      "lost =  0.946629029512\n",
      "test_cumulative_accuracy :  0.843199989796\n",
      "epoch :  83\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0463857199647\n",
      "train_cumulative_accuracy :  0.985480015129\n",
      "duree :  10911.1191449\n",
      "lost =  0.864448106885\n",
      "test_cumulative_accuracy :  0.850399991274\n",
      "epoch :  84\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.976\n",
      "lost =  0.0679697882166\n",
      "train_cumulative_accuracy :  0.97772002086\n",
      "duree :  11039.5399499\n",
      "lost =  1.17187765479\n",
      "test_cumulative_accuracy :  0.816199983358\n",
      "epoch :  85\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.912\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0810662969414\n",
      "train_cumulative_accuracy :  0.974920022637\n",
      "duree :  11168.3326309\n",
      "lost =  0.812104355097\n",
      "test_cumulative_accuracy :  0.85629998982\n",
      "epoch :  86\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.96\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.0767262845729\n",
      "train_cumulative_accuracy :  0.9755200243\n",
      "duree :  11297.164361\n",
      "lost =  1.03609127045\n",
      "test_cumulative_accuracy :  0.835699986815\n",
      "epoch :  87\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.05865383536\n",
      "train_cumulative_accuracy :  0.981800019741\n",
      "duree :  11425.995671\n",
      "lost =  0.834575532675\n",
      "test_cumulative_accuracy :  0.85909999907\n",
      "epoch :  88\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.992\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.035007249604\n",
      "train_cumulative_accuracy :  0.987540015727\n",
      "duree :  11555.018281\n",
      "lost =  0.885416336954\n",
      "test_cumulative_accuracy :  0.856999994516\n",
      "epoch :  89\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0353745803832\n",
      "train_cumulative_accuracy :  0.988060012311\n",
      "duree :  11685.456851\n",
      "lost =  0.922556059957\n",
      "test_cumulative_accuracy :  0.85219999373\n",
      "epoch :  90\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.96\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0369238575753\n",
      "train_cumulative_accuracy :  0.988080011457\n",
      "duree :  11814.4740989\n",
      "lost =  0.765916566551\n",
      "test_cumulative_accuracy :  0.862000000477\n",
      "epoch :  91\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.984\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.992\n",
      "lost =  0.0445420034397\n",
      "train_cumulative_accuracy :  0.9846000202\n",
      "duree :  11943.3054419\n",
      "lost =  0.782007926852\n",
      "test_cumulative_accuracy :  0.855299990177\n",
      "epoch :  92\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.0548135871829\n",
      "train_cumulative_accuracy :  0.981660018116\n",
      "duree :  12072.654748\n",
      "lost =  0.874804548025\n",
      "test_cumulative_accuracy :  0.849099995494\n",
      "epoch :  93\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0408967833782\n",
      "train_cumulative_accuracy :  0.985600016266\n",
      "duree :  12202.4783189\n",
      "lost =  0.89216933161\n",
      "test_cumulative_accuracy :  0.84859999299\n",
      "epoch :  94\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.968\n",
      "j =  160\n",
      "batch_train_accuracy =  1.0\n",
      "j =  240\n",
      "batch_train_accuracy =  1.0\n",
      "j =  320\n",
      "batch_train_accuracy =  0.944\n",
      "lost =  0.0430904414441\n",
      "train_cumulative_accuracy :  0.9854600133\n",
      "duree :  12332.005038\n",
      "lost =  1.21548756748\n",
      "test_cumulative_accuracy :  0.823499985933\n",
      "epoch :  95\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.976\n",
      "j =  240\n",
      "batch_train_accuracy =  0.968\n",
      "j =  320\n",
      "batch_train_accuracy =  0.952\n",
      "lost =  0.0567563509838\n",
      "train_cumulative_accuracy :  0.9814400208\n",
      "duree :  12462.3163118\n",
      "lost =  1.03753966779\n",
      "test_cumulative_accuracy :  0.834399981499\n",
      "epoch :  96\n",
      "j =  0\n",
      "batch_train_accuracy =  0.952\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.944\n",
      "j =  240\n",
      "batch_train_accuracy =  0.952\n",
      "j =  320\n",
      "batch_train_accuracy =  0.968\n",
      "lost =  0.0558443115964\n",
      "train_cumulative_accuracy :  0.981180020422\n",
      "duree :  12594.093133\n",
      "lost =  1.0360403654\n",
      "test_cumulative_accuracy :  0.836899985075\n",
      "epoch :  97\n",
      "j =  0\n",
      "batch_train_accuracy =  0.992\n",
      "j =  80\n",
      "batch_train_accuracy =  0.984\n",
      "j =  160\n",
      "batch_train_accuracy =  0.912\n",
      "j =  240\n",
      "batch_train_accuracy =  0.976\n",
      "j =  320\n",
      "batch_train_accuracy =  0.96\n",
      "lost =  0.0615688195074\n",
      "train_cumulative_accuracy :  0.982140015364\n",
      "duree :  12723.827353\n",
      "lost =  0.852878168821\n",
      "test_cumulative_accuracy :  0.860599994659\n",
      "epoch :  98\n",
      "j =  0\n",
      "batch_train_accuracy =  0.984\n",
      "j =  80\n",
      "batch_train_accuracy =  1.0\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.992\n",
      "j =  320\n",
      "batch_train_accuracy =  1.0\n",
      "lost =  0.0778969166378\n",
      "train_cumulative_accuracy :  0.97504002437\n",
      "duree :  12854.2498429\n",
      "lost =  1.01336735487\n",
      "test_cumulative_accuracy :  0.844899989367\n",
      "epoch :  99\n",
      "j =  0\n",
      "batch_train_accuracy =  0.976\n",
      "j =  80\n",
      "batch_train_accuracy =  0.976\n",
      "j =  160\n",
      "batch_train_accuracy =  0.968\n",
      "j =  240\n",
      "batch_train_accuracy =  0.984\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.0548616103255\n",
      "train_cumulative_accuracy :  0.981940017939\n",
      "duree :  12984.7783558\n",
      "lost =  0.837945970893\n",
      "test_cumulative_accuracy :  0.857099995613\n",
      "epoch :  100\n",
      "j =  0\n",
      "batch_train_accuracy =  1.0\n",
      "j =  80\n",
      "batch_train_accuracy =  0.992\n",
      "j =  160\n",
      "batch_train_accuracy =  0.936\n",
      "j =  240\n",
      "batch_train_accuracy =  0.936\n",
      "j =  320\n",
      "batch_train_accuracy =  0.984\n",
      "lost =  0.063117252549\n",
      "train_cumulative_accuracy :  0.979940021485\n",
      "duree :  13116.6353898\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bb24d26def3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0mbatch_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlbl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mc2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlbl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/chap3/gap/test_3/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    prob_1=tf.placeholder(tf.float32)\n",
    "    prob_2=tf.placeholder(tf.float32)\n",
    "    phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "\n",
    "    'wc1': tf.get_variable(name = \"w1\",shape = [3, 3, 3, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc2': tf.get_variable(name = \"w2\",shape = [3, 3, 48, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.get_variable(name = \"w3\",shape = [3, 3, 48, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc4': tf.get_variable(name = \"w4\",shape = [3, 3, 96, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    'wc5': tf.get_variable(name = \"w5\",shape = [3, 3, 96, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc6': tf.get_variable(name = \"w6\",shape = [3, 3, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc8': tf.Variable(tf.truncated_normal([1, 1, 128, 128], stddev=0.1), name = \"w8\"),\n",
    "    'wc7': tf.get_variable(name = \"w7\",shape = [1, 1, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc8': tf.get_variable(name = \"w8\",shape = [1, 1, 192, 10], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "}\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),   \n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[10]), name = \"b8\"),\n",
    "}\n",
    "\n",
    "'''\n",
    "'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b9\"),\n",
    "'''\n",
    "\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parametes = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parametes *= dim.value\n",
    "    print(variable_parametes)\n",
    "    total_parameters += variable_parametes\n",
    "print(\"total_parameters : \",total_parameters)\n",
    "    \n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "x_bn = batch_norm(x_image, 3, phase_train, convolutional = True)\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_bn, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_1_bn = batch_norm(hidden_1, 48, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.elu(hidden_1_bn)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_2_bn = batch_norm(hidden_2, 48, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.elu(hidden_2_bn)\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_1_do=tf.nn.dropout(pool_1, keep_prob=prob_2)\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1_do, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_3_bn = batch_norm(hidden_3, 96, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.elu(hidden_3_bn)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_4_bn = batch_norm(hidden_4, 96, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.elu(hidden_4_bn)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_2_do=tf.nn.dropout(pool_2, keep_prob=prob_2)\n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2_do, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_5_bn = batch_norm(hidden_5, 192, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.elu(hidden_5_bn)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_6_bn = batch_norm(hidden_6, 192, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.elu(hidden_6_bn)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "pool_3 = tf.nn.max_pool(hidden_6_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_3_do=tf.nn.dropout(pool_3, keep_prob=prob_1)\n",
    "print(pool_3.get_shape())\n",
    "\n",
    "hidden_7 = tf.nn.conv2d(pool_3_do, weights['wc7'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc7']\n",
    "#hidden_7_bn = batch_norm(hidden_7, 192, phase_train, convolutional = True)\n",
    "hidden_7_relu = tf.nn.elu(hidden_7)\n",
    "hidden_7_do=tf.nn.dropout(hidden_7_relu, keep_prob=prob_1)\n",
    "print(hidden_7_relu.get_shape())\n",
    "\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_do, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "gap = tf.nn.avg_pool(hidden_8_relu, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding=\"VALID\")\n",
    "print(gap.get_shape())\n",
    "\n",
    "out_y = tf.reshape(gap, (-1,10))\n",
    "print(out_y.get_shape())\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, {phase_train: True})\n",
    "    while(True):\n",
    "            gen_batch = create_batches(125,True)\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(400):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl, prob_1: 0.75, prob_2:0.5, phase_train: True})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl, prob_1: 1., prob_2:1., phase_train: False})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl, prob_1: 1., prob_2:1., phase_train: False})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%80 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], \n",
    "                                                               feed_dict={x: img, y: lbl, prob_1: 1., prob_2:1., phase_train: False})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 400 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 400 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/400\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/400\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            gen_batch2 = create_batches(100,False)\n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2, prob_1: 1., prob_2:1., phase_train: False})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2, prob_1: 1., prob_2:1., phase_train: False})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], \n",
    "                                                         feed_dict={x: img2, y: lbl2, prob_1: 1., prob_2:1., phase_train: False})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
