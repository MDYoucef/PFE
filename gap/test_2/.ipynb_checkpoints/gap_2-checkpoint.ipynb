{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import scipy.misc\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import cPickle\n",
    "import collections\n",
    "import Image, ImageDraw\n",
    "import PIL\n",
    "from PIL import ImageFont\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_norm(x, n_out, phase_train, convolutional = False, scope='bn'):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        if convolutional:\n",
    "            batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        \n",
    "        else:\n",
    "            batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "        \n",
    "        ema = tf.train.ExponentialMovingAverage(decay=0.999)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_concatenate():\n",
    "    \n",
    "    img = np.zeros([50000,3072])\n",
    "    lbl = np.zeros([50000])\n",
    "    for i in range(5):\n",
    "        with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/data_batch_'+str(i+1),'rb') as f:\n",
    "            data = cPickle.load(f)\n",
    "        for j in range(10000):\n",
    "            img[j+10000*i] = data['data'][j]\n",
    "            lbl[j+10000*i] = data['labels'][j]\n",
    "        \n",
    "        #print(lbl)\n",
    "        #print(\"//////////////////////////////////////////////\")\n",
    "        \n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('/home/skyolia/tensorflow_project/cifar-10/cifar-10-batches-py/test_batch','rb') as f:\n",
    "    data2 = cPickle.load(f)\n",
    "    test_labels = np.asarray(data2['labels'])\n",
    "    test_data = np.asarray(data2['data'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = cifar10_concatenate()\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_reshape(data):\n",
    "    \n",
    "    size = data.shape[0]\n",
    "    img = np.zeros([size,3072])\n",
    "    \n",
    "    for i in range(size):\n",
    "        imageToUse = data[i]\n",
    "        \n",
    "        image = imageToUse.reshape(3,32,32).transpose(1,2,0)\n",
    "        elmn = image.flatten()\n",
    "        \n",
    "        img[i] = elmn\n",
    "        \n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def normalisation(array):\n",
    "    \n",
    "    array = array.astype('float32')\n",
    "    array_nomalized = array / 255.0       \n",
    "    return array_nomalized\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar10_preparation():\n",
    "    \n",
    "    train_reshape = cifar10_reshape(train_data)\n",
    "    test_reshape = cifar10_reshape(test_data)\n",
    "    print(\"reshape done\")\n",
    "    \n",
    "    norm_train_data = normalisation(train_reshape)\n",
    "    norm_test_data = normalisation(test_reshape)\n",
    "    print(\"normalisation done\")\n",
    "    \n",
    "    #flip_train = flip_cifar10(norm_train_data)\n",
    "    #print(\"flip done\")\n",
    "    \n",
    "    #data_train_set = np.concatenate((norm_train_data, flip_train), axis=0)\n",
    "    #label_train_set = np.concatenate((train_labels, train_labels), axis = 0)\n",
    "    \n",
    "    return norm_train_data, norm_test_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape done\n",
      "normalisation done\n",
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "a,b = cifar10_preparation()\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_batches(batch_size, isTrain):\n",
    "    \n",
    "    while (True):\n",
    "        if isTrain:\n",
    "            for i in xrange(0, len(train_labels), batch_size):\n",
    "                yield(a[i:i+batch_size],train_labels[i:i+batch_size])\n",
    "        else:\n",
    "            for i in xrange(0, len(test_labels), batch_size):\n",
    "                yield(b[i:i+batch_size],test_labels[i:i+batch_size])     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "48\n",
      "1296\n",
      "(3, 3, 48, 48)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "48\n",
      "20736\n",
      "(3, 3, 48, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "48\n",
      "96\n",
      "41472\n",
      "(3, 3, 96, 96)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "96\n",
      "82944\n",
      "(3, 3, 96, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "96\n",
      "192\n",
      "165888\n",
      "(3, 3, 192, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "192\n",
      "192\n",
      "331776\n",
      "(3, 3, 192, 192)\n",
      "4\n",
      "3\n",
      "3\n",
      "192\n",
      "192\n",
      "331776\n",
      "(1, 1, 192, 192)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "192\n",
      "36864\n",
      "(1, 1, 192, 10)\n",
      "4\n",
      "1\n",
      "1\n",
      "192\n",
      "10\n",
      "1920\n",
      "(10,)\n",
      "1\n",
      "10\n",
      "10\n",
      "total_parameters :  1014682\n",
      "(?, 32, 32, 48)\n",
      "(?, 32, 32, 48)\n",
      "(?, 16, 16, 48)\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 96)\n",
      "(?, 8, 8, 96)\n",
      "(?, 8, 8, 192)\n",
      "(?, 8, 8, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 192)\n",
      "(?, 4, 4, 10)\n",
      "(?, 1, 1, 10)\n",
      "(?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-11-0f1b9db25b6f>:197 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-0f1b9db25b6f>:198 in <module>.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-11-0f1b9db25b6f>:205 in <module>.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "epoch :  0\n",
      "j =  0\n",
      "batch_train_accuracy =  0.152\n",
      "j =  80\n",
      "batch_train_accuracy =  0.272\n",
      "j =  160\n",
      "batch_train_accuracy =  0.368\n",
      "j =  240\n",
      "batch_train_accuracy =  0.464\n",
      "j =  320\n",
      "batch_train_accuracy =  0.4\n",
      "lost =  2.4934600237\n",
      "train_cumulative_accuracy :  0.362439999394\n",
      "duree :  113.175482988\n",
      "lost =  2.40482905388\n",
      "test_cumulative_accuracy :  0.361599986553\n",
      "epoch :  1\n",
      "j =  0\n",
      "batch_train_accuracy =  0.344\n",
      "j =  80\n",
      "batch_train_accuracy =  0.408\n",
      "j =  160\n",
      "batch_train_accuracy =  0.408\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.424\n",
      "lost =  2.31078398585\n",
      "train_cumulative_accuracy :  0.419899997897\n",
      "duree :  242.301836014\n",
      "lost =  1.73978654385\n",
      "test_cumulative_accuracy :  0.510299973488\n",
      "epoch :  2\n",
      "j =  0\n",
      "batch_train_accuracy =  0.496\n",
      "j =  80\n",
      "batch_train_accuracy =  0.464\n",
      "j =  160\n",
      "batch_train_accuracy =  0.464\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.488\n",
      "lost =  2.01849317342\n",
      "train_cumulative_accuracy :  0.476479997262\n",
      "duree :  368.435062885\n",
      "lost =  1.54558699131\n",
      "test_cumulative_accuracy :  0.553899966478\n",
      "epoch :  3\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.504\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.624\n",
      "j =  320\n",
      "batch_train_accuracy =  0.608\n",
      "lost =  1.74521849275\n",
      "train_cumulative_accuracy :  0.526159994528\n",
      "duree :  494.965642929\n",
      "lost =  1.42078233361\n",
      "test_cumulative_accuracy :  0.58609996438\n",
      "epoch :  4\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.552\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.64\n",
      "j =  320\n",
      "batch_train_accuracy =  0.624\n",
      "lost =  1.57289837658\n",
      "train_cumulative_accuracy :  0.555619996712\n",
      "duree :  620.970583916\n",
      "lost =  1.52118451357\n",
      "test_cumulative_accuracy :  0.563499968946\n",
      "epoch :  5\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.536\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  1.64859500408\n",
      "train_cumulative_accuracy :  0.54173999615\n",
      "duree :  747.370013952\n",
      "lost =  1.49302786827\n",
      "test_cumulative_accuracy :  0.57319996804\n",
      "epoch :  6\n",
      "j =  0\n",
      "batch_train_accuracy =  0.656\n",
      "j =  80\n",
      "batch_train_accuracy =  0.536\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.64\n",
      "lost =  1.62856840461\n",
      "train_cumulative_accuracy :  0.550559994802\n",
      "duree :  873.462124825\n",
      "lost =  1.69371642113\n",
      "test_cumulative_accuracy :  0.54919996649\n",
      "epoch :  7\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.712\n",
      "lost =  1.56923861712\n",
      "train_cumulative_accuracy :  0.569499993473\n",
      "duree :  999.330806017\n",
      "lost =  1.30733290732\n",
      "test_cumulative_accuracy :  0.606299968064\n",
      "epoch :  8\n",
      "j =  0\n",
      "batch_train_accuracy =  0.68\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.544\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  1.5902172251\n",
      "train_cumulative_accuracy :  0.567099997774\n",
      "duree :  1125.33807802\n",
      "lost =  1.33201594234\n",
      "test_cumulative_accuracy :  0.604599969089\n",
      "epoch :  9\n",
      "j =  0\n",
      "batch_train_accuracy =  0.68\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.496\n",
      "j =  240\n",
      "batch_train_accuracy =  0.456\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  1.80919467032\n",
      "train_cumulative_accuracy :  0.541059998497\n",
      "duree :  1251.23938894\n",
      "lost =  1.53784781814\n",
      "test_cumulative_accuracy :  0.579399967194\n",
      "epoch :  10\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.472\n",
      "j =  240\n",
      "batch_train_accuracy =  0.44\n",
      "j =  320\n",
      "batch_train_accuracy =  0.608\n",
      "lost =  1.90443156183\n",
      "train_cumulative_accuracy :  0.532419995517\n",
      "duree :  1377.22874784\n",
      "lost =  1.88505638957\n",
      "test_cumulative_accuracy :  0.518499976099\n",
      "epoch :  11\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.464\n",
      "j =  240\n",
      "batch_train_accuracy =  0.488\n",
      "j =  320\n",
      "batch_train_accuracy =  0.56\n",
      "lost =  1.75504856318\n",
      "train_cumulative_accuracy :  0.551899995208\n",
      "duree :  1503.39708304\n",
      "lost =  1.71460739255\n",
      "test_cumulative_accuracy :  0.544299974442\n",
      "epoch :  12\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.512\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.656\n",
      "lost =  1.64209489852\n",
      "train_cumulative_accuracy :  0.571219994724\n",
      "duree :  1629.43142605\n",
      "lost =  1.82699265361\n",
      "test_cumulative_accuracy :  0.533899972439\n",
      "epoch :  13\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.672\n",
      "lost =  1.75172879249\n",
      "train_cumulative_accuracy :  0.563219995275\n",
      "duree :  1755.43473601\n",
      "lost =  1.76866161346\n",
      "test_cumulative_accuracy :  0.539199970067\n",
      "epoch :  14\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.464\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.664\n",
      "lost =  1.75882806391\n",
      "train_cumulative_accuracy :  0.56449999325\n",
      "duree :  1881.18221688\n",
      "lost =  1.82513309479\n",
      "test_cumulative_accuracy :  0.556299969852\n",
      "epoch :  15\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.688\n",
      "j =  160\n",
      "batch_train_accuracy =  0.56\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.552\n",
      "lost =  1.77126282305\n",
      "train_cumulative_accuracy :  0.562039995119\n",
      "duree :  2007.10607886\n",
      "lost =  1.6059843111\n",
      "test_cumulative_accuracy :  0.565599969923\n",
      "epoch :  16\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.672\n",
      "lost =  1.748536053\n",
      "train_cumulative_accuracy :  0.578419993743\n",
      "duree :  2132.85604095\n",
      "lost =  1.80419933677\n",
      "test_cumulative_accuracy :  0.559799969494\n",
      "epoch :  17\n",
      "j =  0\n",
      "batch_train_accuracy =  0.6\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.472\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  1.90557839751\n",
      "train_cumulative_accuracy :  0.565599996895\n",
      "duree :  2258.90152192\n",
      "lost =  1.82482846975\n",
      "test_cumulative_accuracy :  0.56199996531\n",
      "epoch :  18\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.656\n",
      "lost =  1.82393963635\n",
      "train_cumulative_accuracy :  0.573919996917\n",
      "duree :  2384.90681696\n",
      "lost =  2.12096694946\n",
      "test_cumulative_accuracy :  0.533199969828\n",
      "epoch :  19\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  2.08179967254\n",
      "train_cumulative_accuracy :  0.55059999615\n",
      "duree :  2510.78451204\n",
      "lost =  2.06971797466\n",
      "test_cumulative_accuracy :  0.523399969637\n",
      "epoch :  20\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.552\n",
      "j =  240\n",
      "batch_train_accuracy =  0.464\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  1.95162614033\n",
      "train_cumulative_accuracy :  0.575119993761\n",
      "duree :  2636.73460984\n",
      "lost =  2.00358349442\n",
      "test_cumulative_accuracy :  0.557899966538\n",
      "epoch :  21\n",
      "j =  0\n",
      "batch_train_accuracy =  0.64\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.584\n",
      "j =  320\n",
      "batch_train_accuracy =  0.544\n",
      "lost =  2.06398115337\n",
      "train_cumulative_accuracy :  0.579539995342\n",
      "duree :  2762.58863688\n",
      "lost =  2.34691892266\n",
      "test_cumulative_accuracy :  0.541399969757\n",
      "epoch :  22\n",
      "j =  0\n",
      "batch_train_accuracy =  0.552\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.656\n",
      "lost =  1.95677544177\n",
      "train_cumulative_accuracy :  0.583039994985\n",
      "duree :  2888.54288483\n",
      "lost =  1.86135943413\n",
      "test_cumulative_accuracy :  0.58099996835\n",
      "epoch :  23\n",
      "j =  0\n",
      "batch_train_accuracy =  0.656\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.496\n",
      "j =  240\n",
      "batch_train_accuracy =  0.432\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.20050325781\n",
      "train_cumulative_accuracy :  0.552759994268\n",
      "duree :  3014.48933005\n",
      "lost =  2.81825182915\n",
      "test_cumulative_accuracy :  0.479199978709\n",
      "epoch :  24\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.48\n",
      "j =  320\n",
      "batch_train_accuracy =  0.552\n",
      "lost =  2.05472926646\n",
      "train_cumulative_accuracy :  0.569159993455\n",
      "duree :  3140.39113188\n",
      "lost =  2.23134149313\n",
      "test_cumulative_accuracy :  0.533999976814\n",
      "epoch :  25\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.26639784858\n",
      "train_cumulative_accuracy :  0.554699996263\n",
      "duree :  3266.34550691\n",
      "lost =  2.31371477842\n",
      "test_cumulative_accuracy :  0.530099969804\n",
      "epoch :  26\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.568\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.584\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.28012242287\n",
      "train_cumulative_accuracy :  0.556299996153\n",
      "duree :  3392.22345495\n",
      "lost =  2.37118797541\n",
      "test_cumulative_accuracy :  0.529199974239\n",
      "epoch :  27\n",
      "j =  0\n",
      "batch_train_accuracy =  0.544\n",
      "j =  80\n",
      "batch_train_accuracy =  0.608\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.472\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.1292459628\n",
      "train_cumulative_accuracy :  0.567799996138\n",
      "duree :  3518.18342495\n",
      "lost =  2.6560156405\n",
      "test_cumulative_accuracy :  0.52879997611\n",
      "epoch :  28\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.616\n",
      "j =  320\n",
      "batch_train_accuracy =  0.616\n",
      "lost =  2.19564940244\n",
      "train_cumulative_accuracy :  0.571339995712\n",
      "duree :  3644.03884697\n",
      "lost =  1.95646936655\n",
      "test_cumulative_accuracy :  0.592799964249\n",
      "epoch :  29\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.472\n",
      "j =  320\n",
      "batch_train_accuracy =  0.544\n",
      "lost =  2.27778343111\n",
      "train_cumulative_accuracy :  0.56941999644\n",
      "duree :  3769.93737602\n",
      "lost =  3.02228585482\n",
      "test_cumulative_accuracy :  0.522099972069\n",
      "epoch :  30\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.608\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.544\n",
      "j =  320\n",
      "batch_train_accuracy =  0.552\n",
      "lost =  2.48519820303\n",
      "train_cumulative_accuracy :  0.558539996967\n",
      "duree :  3895.99888682\n",
      "lost =  2.64708482265\n",
      "test_cumulative_accuracy :  0.543099969923\n",
      "epoch :  31\n",
      "j =  0\n",
      "batch_train_accuracy =  0.552\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.512\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.37980659276\n",
      "train_cumulative_accuracy :  0.559679995403\n",
      "duree :  4021.90976596\n",
      "lost =  2.89583460689\n",
      "test_cumulative_accuracy :  0.494799983799\n",
      "epoch :  32\n",
      "j =  0\n",
      "batch_train_accuracy =  0.496\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.64\n",
      "lost =  2.51014169991\n",
      "train_cumulative_accuracy :  0.560419996455\n",
      "duree :  4147.99994302\n",
      "lost =  2.59764540911\n",
      "test_cumulative_accuracy :  0.563299965858\n",
      "epoch :  33\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.648\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.648\n",
      "lost =  2.37529734045\n",
      "train_cumulative_accuracy :  0.572619995996\n",
      "duree :  4273.87060785\n",
      "lost =  2.68132459402\n",
      "test_cumulative_accuracy :  0.511099973619\n",
      "epoch :  34\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.616\n",
      "j =  240\n",
      "batch_train_accuracy =  0.496\n",
      "j =  320\n",
      "batch_train_accuracy =  0.56\n",
      "lost =  2.37211841911\n",
      "train_cumulative_accuracy :  0.565279994383\n",
      "duree :  4399.71304893\n",
      "lost =  3.07966486812\n",
      "test_cumulative_accuracy :  0.501299977899\n",
      "epoch :  35\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.48\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.52\n",
      "lost =  2.46315761596\n",
      "train_cumulative_accuracy :  0.55949999474\n",
      "duree :  4525.7627449\n",
      "lost =  2.85855370879\n",
      "test_cumulative_accuracy :  0.517299976349\n",
      "epoch :  36\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.608\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  2.21135202259\n",
      "train_cumulative_accuracy :  0.581139995977\n",
      "duree :  4651.71776986\n",
      "lost =  2.43881157517\n",
      "test_cumulative_accuracy :  0.551099971831\n",
      "epoch :  37\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.6\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.632\n",
      "j =  320\n",
      "batch_train_accuracy =  0.52\n",
      "lost =  2.32740041077\n",
      "train_cumulative_accuracy :  0.576859995648\n",
      "duree :  4777.97647905\n",
      "lost =  2.28935947657\n",
      "test_cumulative_accuracy :  0.566699973345\n",
      "epoch :  38\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.48\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.35961208493\n",
      "train_cumulative_accuracy :  0.574019997939\n",
      "duree :  4903.85348988\n",
      "lost =  3.13242752194\n",
      "test_cumulative_accuracy :  0.501899977028\n",
      "epoch :  39\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.48\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.41362111628\n",
      "train_cumulative_accuracy :  0.57399999395\n",
      "duree :  5029.88118696\n",
      "lost =  2.34587733388\n",
      "test_cumulative_accuracy :  0.581099967659\n",
      "epoch :  40\n",
      "j =  0\n",
      "batch_train_accuracy =  0.648\n",
      "j =  80\n",
      "batch_train_accuracy =  0.592\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.544\n",
      "j =  320\n",
      "batch_train_accuracy =  0.592\n",
      "lost =  2.59520201653\n",
      "train_cumulative_accuracy :  0.565999995247\n",
      "duree :  5155.76996088\n",
      "lost =  3.04464047909\n",
      "test_cumulative_accuracy :  0.514799972773\n",
      "epoch :  41\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.544\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.70124032587\n",
      "train_cumulative_accuracy :  0.546119993553\n",
      "duree :  5281.65241289\n",
      "lost =  3.23837265253\n",
      "test_cumulative_accuracy :  0.49909997493\n",
      "epoch :  42\n",
      "j =  0\n",
      "batch_train_accuracy =  0.528\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.616\n",
      "j =  240\n",
      "batch_train_accuracy =  0.488\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.56067711323\n",
      "train_cumulative_accuracy :  0.564039996713\n",
      "duree :  5407.77373195\n",
      "lost =  3.32759205341\n",
      "test_cumulative_accuracy :  0.482299979925\n",
      "epoch :  43\n",
      "j =  0\n",
      "batch_train_accuracy =  0.48\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.472\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  3.00763706058\n",
      "train_cumulative_accuracy :  0.525679995492\n",
      "duree :  5533.77064705\n",
      "lost =  3.10045713425\n",
      "test_cumulative_accuracy :  0.508999973238\n",
      "epoch :  44\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.608\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.584\n",
      "j =  320\n",
      "batch_train_accuracy =  0.592\n",
      "lost =  2.56720458061\n",
      "train_cumulative_accuracy :  0.564699993208\n",
      "duree :  5659.82138991\n",
      "lost =  2.48429168224\n",
      "test_cumulative_accuracy :  0.563899966478\n",
      "epoch :  45\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.648\n",
      "j =  160\n",
      "batch_train_accuracy =  0.512\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.568\n",
      "lost =  2.54380722106\n",
      "train_cumulative_accuracy :  0.567559997365\n",
      "duree :  5785.88343692\n",
      "lost =  2.57871478915\n",
      "test_cumulative_accuracy :  0.52649997443\n",
      "epoch :  46\n",
      "j =  0\n",
      "batch_train_accuracy =  0.536\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.56\n",
      "j =  240\n",
      "batch_train_accuracy =  0.672\n",
      "j =  320\n",
      "batch_train_accuracy =  0.52\n",
      "lost =  2.49188841552\n",
      "train_cumulative_accuracy :  0.573119995818\n",
      "duree :  5911.93656993\n",
      "lost =  3.8998235178\n",
      "test_cumulative_accuracy :  0.483799977005\n",
      "epoch :  47\n",
      "j =  0\n",
      "batch_train_accuracy =  0.528\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.568\n",
      "lost =  2.57971685052\n",
      "train_cumulative_accuracy :  0.573179994673\n",
      "duree :  6037.92677999\n",
      "lost =  2.82844593644\n",
      "test_cumulative_accuracy :  0.545099972785\n",
      "epoch :  48\n",
      "j =  0\n",
      "batch_train_accuracy =  0.648\n",
      "j =  80\n",
      "batch_train_accuracy =  0.704\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.456\n",
      "j =  320\n",
      "batch_train_accuracy =  0.536\n",
      "lost =  2.74845684826\n",
      "train_cumulative_accuracy :  0.555379997343\n",
      "duree :  6163.89202785\n",
      "lost =  2.58580975533\n",
      "test_cumulative_accuracy :  0.5724999699\n",
      "epoch :  49\n",
      "j =  0\n",
      "batch_train_accuracy =  0.632\n",
      "j =  80\n",
      "batch_train_accuracy =  0.576\n",
      "j =  160\n",
      "batch_train_accuracy =  0.496\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.536\n",
      "lost =  3.1563410911\n",
      "train_cumulative_accuracy :  0.527719995007\n",
      "duree :  6289.78279591\n",
      "lost =  2.2540299952\n",
      "test_cumulative_accuracy :  0.590399965048\n",
      "epoch :  50\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.608\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.672\n",
      "lost =  2.39535420924\n",
      "train_cumulative_accuracy :  0.579899997041\n",
      "duree :  6415.75611496\n",
      "lost =  3.22415774345\n",
      "test_cumulative_accuracy :  0.505699975789\n",
      "epoch :  51\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.536\n",
      "lost =  2.62016891956\n",
      "train_cumulative_accuracy :  0.554099997431\n",
      "duree :  6541.70453691\n",
      "lost =  2.49036252737\n",
      "test_cumulative_accuracy :  0.554899966717\n",
      "epoch :  52\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.608\n",
      "j =  240\n",
      "batch_train_accuracy =  0.552\n",
      "j =  320\n",
      "batch_train_accuracy =  0.624\n",
      "lost =  2.50804462254\n",
      "train_cumulative_accuracy :  0.586799995229\n",
      "duree :  6667.71390796\n",
      "lost =  2.35311965466\n",
      "test_cumulative_accuracy :  0.585099971294\n",
      "epoch :  53\n",
      "j =  0\n",
      "batch_train_accuracy =  0.648\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.584\n",
      "j =  240\n",
      "batch_train_accuracy =  0.592\n",
      "j =  320\n",
      "batch_train_accuracy =  0.688\n",
      "lost =  2.47018429637\n",
      "train_cumulative_accuracy :  0.590199996904\n",
      "duree :  6793.84494495\n",
      "lost =  2.66554137945\n",
      "test_cumulative_accuracy :  0.578699969053\n",
      "epoch :  54\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.608\n",
      "j =  240\n",
      "batch_train_accuracy =  0.616\n",
      "j =  320\n",
      "batch_train_accuracy =  0.616\n",
      "lost =  2.34832155019\n",
      "train_cumulative_accuracy :  0.596679995358\n",
      "duree :  6919.87491393\n",
      "lost =  3.00290693998\n",
      "test_cumulative_accuracy :  0.54849997133\n",
      "epoch :  55\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.528\n",
      "lost =  2.48352743268\n",
      "train_cumulative_accuracy :  0.589299995825\n",
      "duree :  7045.84334302\n",
      "lost =  3.2435909009\n",
      "test_cumulative_accuracy :  0.530399971902\n",
      "epoch :  56\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.688\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.632\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.54989290595\n",
      "train_cumulative_accuracy :  0.580379995331\n",
      "duree :  7171.98807192\n",
      "lost =  3.22292348742\n",
      "test_cumulative_accuracy :  0.541799968779\n",
      "epoch :  57\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.648\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.6\n",
      "j =  320\n",
      "batch_train_accuracy =  0.608\n",
      "lost =  2.67132421911\n",
      "train_cumulative_accuracy :  0.579599997625\n",
      "duree :  7297.92403197\n",
      "lost =  2.67580481291\n",
      "test_cumulative_accuracy :  0.560399971008\n",
      "epoch :  58\n",
      "j =  0\n",
      "batch_train_accuracy =  0.6\n",
      "j =  80\n",
      "batch_train_accuracy =  0.552\n",
      "j =  160\n",
      "batch_train_accuracy =  0.56\n",
      "j =  240\n",
      "batch_train_accuracy =  0.624\n",
      "j =  320\n",
      "batch_train_accuracy =  0.64\n",
      "lost =  2.7810063386\n",
      "train_cumulative_accuracy :  0.571259995997\n",
      "duree :  7423.81887984\n",
      "lost =  3.40799917459\n",
      "test_cumulative_accuracy :  0.535199971497\n",
      "epoch :  59\n",
      "j =  0\n",
      "batch_train_accuracy =  0.6\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.608\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.22524833828\n",
      "train_cumulative_accuracy :  0.603299996406\n",
      "duree :  7549.865345\n",
      "lost =  3.32836333513\n",
      "test_cumulative_accuracy :  0.494999978244\n",
      "epoch :  60\n",
      "j =  0\n",
      "batch_train_accuracy =  0.552\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.5212495479\n",
      "train_cumulative_accuracy :  0.57739999868\n",
      "duree :  7675.82262897\n",
      "lost =  3.16982434511\n",
      "test_cumulative_accuracy :  0.546899971962\n",
      "epoch :  61\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.552\n",
      "j =  240\n",
      "batch_train_accuracy =  0.592\n",
      "j =  320\n",
      "batch_train_accuracy =  0.664\n",
      "lost =  2.41120184869\n",
      "train_cumulative_accuracy :  0.591239995882\n",
      "duree :  7801.75964904\n",
      "lost =  3.07641692638\n",
      "test_cumulative_accuracy :  0.551499970853\n",
      "epoch :  62\n",
      "j =  0\n",
      "batch_train_accuracy =  0.648\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.424\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.544\n",
      "lost =  2.79007370859\n",
      "train_cumulative_accuracy :  0.54879999578\n",
      "duree :  7927.61095595\n",
      "lost =  3.06940219402\n",
      "test_cumulative_accuracy :  0.529199971557\n",
      "epoch :  63\n",
      "j =  0\n",
      "batch_train_accuracy =  0.552\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.496\n",
      "j =  320\n",
      "batch_train_accuracy =  0.712\n",
      "lost =  2.75799843013\n",
      "train_cumulative_accuracy :  0.572659996152\n",
      "duree :  8053.59792686\n",
      "lost =  3.33324079514\n",
      "test_cumulative_accuracy :  0.541599969268\n",
      "epoch :  64\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.648\n",
      "j =  160\n",
      "batch_train_accuracy =  0.616\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.488\n",
      "lost =  2.88747648925\n",
      "train_cumulative_accuracy :  0.558779997379\n",
      "duree :  8179.46395802\n",
      "lost =  2.90467174649\n",
      "test_cumulative_accuracy :  0.551099967659\n",
      "epoch :  65\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.56\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.456\n",
      "lost =  2.96743604779\n",
      "train_cumulative_accuracy :  0.541699996516\n",
      "duree :  8305.413908\n",
      "lost =  2.67954652429\n",
      "test_cumulative_accuracy :  0.550899971426\n",
      "epoch :  66\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.608\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.488\n",
      "j =  320\n",
      "batch_train_accuracy =  0.528\n",
      "lost =  2.816579175\n",
      "train_cumulative_accuracy :  0.54045999676\n",
      "duree :  8431.4761529\n",
      "lost =  3.80546968222\n",
      "test_cumulative_accuracy :  0.486999981701\n",
      "epoch :  67\n",
      "j =  0\n",
      "batch_train_accuracy =  0.52\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.552\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.536\n",
      "lost =  2.78484846681\n",
      "train_cumulative_accuracy :  0.545419994816\n",
      "duree :  8557.61254382\n",
      "lost =  2.91653729439\n",
      "test_cumulative_accuracy :  0.531999975741\n",
      "epoch :  68\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.552\n",
      "j =  320\n",
      "batch_train_accuracy =  0.48\n",
      "lost =  2.68368041903\n",
      "train_cumulative_accuracy :  0.5711799936\n",
      "duree :  8683.60362792\n",
      "lost =  3.11115535617\n",
      "test_cumulative_accuracy :  0.541399970055\n",
      "epoch :  69\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.552\n",
      "j =  320\n",
      "batch_train_accuracy =  0.712\n",
      "lost =  2.43302976638\n",
      "train_cumulative_accuracy :  0.583559994996\n",
      "duree :  8809.53652883\n",
      "lost =  3.04824083686\n",
      "test_cumulative_accuracy :  0.524899973571\n",
      "epoch :  70\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.544\n",
      "lost =  2.66441211253\n",
      "train_cumulative_accuracy :  0.562719995528\n",
      "duree :  8935.51072288\n",
      "lost =  3.8074899292\n",
      "test_cumulative_accuracy :  0.471899984181\n",
      "epoch :  71\n",
      "j =  0\n",
      "batch_train_accuracy =  0.536\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.86008757502\n",
      "train_cumulative_accuracy :  0.564839994833\n",
      "duree :  9061.36356688\n",
      "lost =  3.0539312315\n",
      "test_cumulative_accuracy :  0.537199971676\n",
      "epoch :  72\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.432\n",
      "lost =  3.25274805576\n",
      "train_cumulative_accuracy :  0.542759996355\n",
      "duree :  9187.09466004\n",
      "lost =  4.26795924902\n",
      "test_cumulative_accuracy :  0.487299980819\n",
      "epoch :  73\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.728\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.89871178031\n",
      "train_cumulative_accuracy :  0.572419994175\n",
      "duree :  9313.02807784\n",
      "lost =  3.3156769228\n",
      "test_cumulative_accuracy :  0.519399974644\n",
      "epoch :  74\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.648\n",
      "lost =  2.72325285822\n",
      "train_cumulative_accuracy :  0.575219995752\n",
      "duree :  9439.06965685\n",
      "lost =  3.43586082935\n",
      "test_cumulative_accuracy :  0.509699977338\n",
      "epoch :  75\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.48\n",
      "j =  320\n",
      "batch_train_accuracy =  0.416\n",
      "lost =  3.50990726709\n",
      "train_cumulative_accuracy :  0.513219995052\n",
      "duree :  9565.03516483\n",
      "lost =  3.30131488562\n",
      "test_cumulative_accuracy :  0.512599976361\n",
      "epoch :  76\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.632\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.656\n",
      "lost =  2.57858059645\n",
      "train_cumulative_accuracy :  0.575979995802\n",
      "duree :  9691.06637096\n",
      "lost =  2.44541182041\n",
      "test_cumulative_accuracy :  0.585099964738\n",
      "epoch :  77\n",
      "j =  0\n",
      "batch_train_accuracy =  0.664\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.624\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.66957671076\n",
      "train_cumulative_accuracy :  0.586579994857\n",
      "duree :  9817.08013105\n",
      "lost =  3.59232640266\n",
      "test_cumulative_accuracy :  0.514699973464\n",
      "epoch :  78\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.528\n",
      "j =  160\n",
      "batch_train_accuracy =  0.44\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.568\n",
      "lost =  3.23770198703\n",
      "train_cumulative_accuracy :  0.536199996546\n",
      "duree :  9943.04363704\n",
      "lost =  3.8382922864\n",
      "test_cumulative_accuracy :  0.503499977887\n",
      "epoch :  79\n",
      "j =  0\n",
      "batch_train_accuracy =  0.52\n",
      "j =  80\n",
      "batch_train_accuracy =  0.6\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.608\n",
      "lost =  2.8220511356\n",
      "train_cumulative_accuracy :  0.566919994131\n",
      "duree :  10069.0996699\n",
      "lost =  3.08941180944\n",
      "test_cumulative_accuracy :  0.540199972093\n",
      "epoch :  80\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.52\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.496\n",
      "lost =  2.70103573591\n",
      "train_cumulative_accuracy :  0.570119996294\n",
      "duree :  10195.143569\n",
      "lost =  3.34150434971\n",
      "test_cumulative_accuracy :  0.536099968255\n",
      "epoch :  81\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.552\n",
      "j =  240\n",
      "batch_train_accuracy =  0.616\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  2.66021387368\n",
      "train_cumulative_accuracy :  0.582219997272\n",
      "duree :  10321.1635809\n",
      "lost =  4.07154665232\n",
      "test_cumulative_accuracy :  0.488099979758\n",
      "epoch :  82\n",
      "j =  0\n",
      "batch_train_accuracy =  0.48\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.584\n",
      "j =  320\n",
      "batch_train_accuracy =  0.552\n",
      "lost =  2.46397553265\n",
      "train_cumulative_accuracy :  0.603719998598\n",
      "duree :  10447.0710909\n",
      "lost =  2.64209864259\n",
      "test_cumulative_accuracy :  0.588399969637\n",
      "epoch :  83\n",
      "j =  0\n",
      "batch_train_accuracy =  0.68\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.56\n",
      "j =  240\n",
      "batch_train_accuracy =  0.592\n",
      "j =  320\n",
      "batch_train_accuracy =  0.616\n",
      "lost =  2.41423193634\n",
      "train_cumulative_accuracy :  0.617359993607\n",
      "duree :  10572.9670849\n",
      "lost =  2.63566167712\n",
      "test_cumulative_accuracy :  0.576099966168\n",
      "epoch :  84\n",
      "j =  0\n",
      "batch_train_accuracy =  0.696\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.616\n",
      "lost =  2.53302247733\n",
      "train_cumulative_accuracy :  0.580119995996\n",
      "duree :  10698.978565\n",
      "lost =  3.18198332191\n",
      "test_cumulative_accuracy :  0.541599968672\n",
      "epoch :  85\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.608\n",
      "j =  320\n",
      "batch_train_accuracy =  0.552\n",
      "lost =  2.62721780449\n",
      "train_cumulative_accuracy :  0.587659995556\n",
      "duree :  10824.8746898\n",
      "lost =  3.19290996075\n",
      "test_cumulative_accuracy :  0.531899971664\n",
      "epoch :  86\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.512\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.56\n",
      "lost =  2.67772684515\n",
      "train_cumulative_accuracy :  0.578319993764\n",
      "duree :  10950.950918\n",
      "lost =  3.35126297474\n",
      "test_cumulative_accuracy :  0.5374999699\n",
      "epoch :  87\n",
      "j =  0\n",
      "batch_train_accuracy =  0.6\n",
      "j =  80\n",
      "batch_train_accuracy =  0.6\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.6\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.94518630296\n",
      "train_cumulative_accuracy :  0.574719993249\n",
      "duree :  11076.7638159\n",
      "lost =  3.63734985352\n",
      "test_cumulative_accuracy :  0.524899976254\n",
      "epoch :  88\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.48\n",
      "lost =  3.49541907936\n",
      "train_cumulative_accuracy :  0.531099995747\n",
      "duree :  11202.725564\n",
      "lost =  3.73764818192\n",
      "test_cumulative_accuracy :  0.51249997437\n",
      "epoch :  89\n",
      "j =  0\n",
      "batch_train_accuracy =  0.552\n",
      "j =  80\n",
      "batch_train_accuracy =  0.568\n",
      "j =  160\n",
      "batch_train_accuracy =  0.584\n",
      "j =  240\n",
      "batch_train_accuracy =  0.512\n",
      "j =  320\n",
      "batch_train_accuracy =  0.504\n",
      "lost =  3.10252556831\n",
      "train_cumulative_accuracy :  0.559999994412\n",
      "duree :  11328.809629\n",
      "lost =  3.32476589918\n",
      "test_cumulative_accuracy :  0.506599976718\n",
      "epoch :  90\n",
      "j =  0\n",
      "batch_train_accuracy =  0.576\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.608\n",
      "lost =  2.58479541063\n",
      "train_cumulative_accuracy :  0.573279998302\n",
      "duree :  11454.766444\n",
      "lost =  2.86235649586\n",
      "test_cumulative_accuracy :  0.538099969625\n",
      "epoch :  91\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.56\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.472\n",
      "j =  320\n",
      "batch_train_accuracy =  0.616\n",
      "lost =  2.96715936214\n",
      "train_cumulative_accuracy :  0.567039995641\n",
      "duree :  11580.789784\n",
      "lost =  3.22482596874\n",
      "test_cumulative_accuracy :  0.542099969089\n",
      "epoch :  92\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.48\n",
      "j =  320\n",
      "batch_train_accuracy =  0.44\n",
      "lost =  3.14954241037\n",
      "train_cumulative_accuracy :  0.55037999399\n",
      "duree :  11706.645216\n",
      "lost =  2.92875694275\n",
      "test_cumulative_accuracy :  0.54289997071\n",
      "epoch :  93\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.696\n",
      "j =  160\n",
      "batch_train_accuracy =  0.608\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.67437080264\n",
      "train_cumulative_accuracy :  0.586359997019\n",
      "duree :  11832.561162\n",
      "lost =  3.22534232855\n",
      "test_cumulative_accuracy :  0.541899965405\n",
      "epoch :  94\n",
      "j =  0\n",
      "batch_train_accuracy =  0.568\n",
      "j =  80\n",
      "batch_train_accuracy =  0.6\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.536\n",
      "lost =  3.23812797278\n",
      "train_cumulative_accuracy :  0.545359996632\n",
      "duree :  11958.379847\n",
      "lost =  3.01310453534\n",
      "test_cumulative_accuracy :  0.548399967551\n",
      "epoch :  95\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.576\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.56\n",
      "j =  320\n",
      "batch_train_accuracy =  0.456\n",
      "lost =  3.27834222555\n",
      "train_cumulative_accuracy :  0.528879993334\n",
      "duree :  12084.347086\n",
      "lost =  3.48509468079\n",
      "test_cumulative_accuracy :  0.508699975312\n",
      "epoch :  96\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.544\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.52\n",
      "lost =  3.00307820082\n",
      "train_cumulative_accuracy :  0.553219994977\n",
      "duree :  12210.1884689\n",
      "lost =  4.11636423588\n",
      "test_cumulative_accuracy :  0.488199980855\n",
      "epoch :  97\n",
      "j =  0\n",
      "batch_train_accuracy =  0.544\n",
      "j =  80\n",
      "batch_train_accuracy =  0.592\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.488\n",
      "j =  320\n",
      "batch_train_accuracy =  0.512\n",
      "lost =  3.29923942477\n",
      "train_cumulative_accuracy :  0.545999997184\n",
      "duree :  12336.11287\n",
      "lost =  4.43903989553\n",
      "test_cumulative_accuracy :  0.490599977672\n",
      "epoch :  98\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.592\n",
      "j =  320\n",
      "batch_train_accuracy =  0.528\n",
      "lost =  2.92134912699\n",
      "train_cumulative_accuracy :  0.559999995232\n",
      "duree :  12462.232825\n",
      "lost =  3.98314471245\n",
      "test_cumulative_accuracy :  0.494199978113\n",
      "epoch :  99\n",
      "j =  0\n",
      "batch_train_accuracy =  0.552\n",
      "j =  80\n",
      "batch_train_accuracy =  0.552\n",
      "j =  160\n",
      "batch_train_accuracy =  0.504\n",
      "j =  240\n",
      "batch_train_accuracy =  0.504\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  2.85648811519\n",
      "train_cumulative_accuracy :  0.56147999391\n",
      "duree :  12588.1274619\n",
      "lost =  3.17303344965\n",
      "test_cumulative_accuracy :  0.54919996798\n",
      "epoch :  100\n",
      "j =  0\n",
      "batch_train_accuracy =  0.64\n",
      "j =  80\n",
      "batch_train_accuracy =  0.72\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.608\n",
      "j =  320\n",
      "batch_train_accuracy =  0.632\n",
      "lost =  2.61480867058\n",
      "train_cumulative_accuracy :  0.611679994613\n",
      "duree :  12714.1586969\n",
      "lost =  4.37729479074\n",
      "test_cumulative_accuracy :  0.504499978125\n",
      "epoch :  101\n",
      "j =  0\n",
      "batch_train_accuracy =  0.56\n",
      "j =  80\n",
      "batch_train_accuracy =  0.648\n",
      "j =  160\n",
      "batch_train_accuracy =  0.592\n",
      "j =  240\n",
      "batch_train_accuracy =  0.544\n",
      "j =  320\n",
      "batch_train_accuracy =  0.528\n",
      "lost =  2.91935168922\n",
      "train_cumulative_accuracy :  0.585299996436\n",
      "duree :  12840.2043378\n",
      "lost =  3.665045681\n",
      "test_cumulative_accuracy :  0.522299973965\n",
      "epoch :  102\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.568\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.84181435764\n",
      "train_cumulative_accuracy :  0.585779998675\n",
      "duree :  12966.061362\n",
      "lost =  3.51186061144\n",
      "test_cumulative_accuracy :  0.541599972546\n",
      "epoch :  103\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.576\n",
      "j =  320\n",
      "batch_train_accuracy =  0.552\n",
      "lost =  3.02698325813\n",
      "train_cumulative_accuracy :  0.579819995239\n",
      "duree :  13092.0228579\n",
      "lost =  3.90676678896\n",
      "test_cumulative_accuracy :  0.526499970853\n",
      "epoch :  104\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.584\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.56\n",
      "lost =  3.16154334724\n",
      "train_cumulative_accuracy :  0.558459994271\n",
      "duree :  13217.931309\n",
      "lost =  4.12047711611\n",
      "test_cumulative_accuracy :  0.499299979806\n",
      "epoch :  105\n",
      "j =  0\n",
      "batch_train_accuracy =  0.528\n",
      "j =  80\n",
      "batch_train_accuracy =  0.64\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.79954232424\n",
      "train_cumulative_accuracy :  0.591159996688\n",
      "duree :  13343.9009879\n",
      "lost =  3.26700326681\n",
      "test_cumulative_accuracy :  0.548399969339\n",
      "epoch :  106\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.576\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.48\n",
      "j =  320\n",
      "batch_train_accuracy =  0.536\n",
      "lost =  3.42365055323\n",
      "train_cumulative_accuracy :  0.530399994254\n",
      "duree :  13470.0048869\n",
      "lost =  4.07807216406\n",
      "test_cumulative_accuracy :  0.488799980581\n",
      "epoch :  107\n",
      "j =  0\n",
      "batch_train_accuracy =  0.52\n",
      "j =  80\n",
      "batch_train_accuracy =  0.568\n",
      "j =  160\n",
      "batch_train_accuracy =  0.488\n",
      "j =  240\n",
      "batch_train_accuracy =  0.528\n",
      "j =  320\n",
      "batch_train_accuracy =  0.56\n",
      "lost =  4.05064181864\n",
      "train_cumulative_accuracy :  0.530079996064\n",
      "duree :  13596.1113119\n",
      "lost =  4.06020397425\n",
      "test_cumulative_accuracy :  0.526999972463\n",
      "epoch :  108\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.656\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.6\n",
      "j =  320\n",
      "batch_train_accuracy =  0.624\n",
      "lost =  3.03728506237\n",
      "train_cumulative_accuracy :  0.577699996457\n",
      "duree :  13722.0756929\n",
      "lost =  3.89583665609\n",
      "test_cumulative_accuracy :  0.517699975371\n",
      "epoch :  109\n",
      "j =  0\n",
      "batch_train_accuracy =  0.528\n",
      "j =  80\n",
      "batch_train_accuracy =  0.616\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.568\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  3.00581961542\n",
      "train_cumulative_accuracy :  0.561759993434\n",
      "duree :  13848.1351089\n",
      "lost =  3.78043767929\n",
      "test_cumulative_accuracy :  0.541999970675\n",
      "epoch :  110\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.536\n",
      "j =  240\n",
      "batch_train_accuracy =  0.536\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.92288672984\n",
      "train_cumulative_accuracy :  0.578159995079\n",
      "duree :  13974.148663\n",
      "lost =  3.76914791346\n",
      "test_cumulative_accuracy :  0.507899976373\n",
      "epoch :  111\n",
      "j =  0\n",
      "batch_train_accuracy =  0.584\n",
      "j =  80\n",
      "batch_train_accuracy =  0.664\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.52\n",
      "j =  320\n",
      "batch_train_accuracy =  0.44\n",
      "lost =  3.02387064725\n",
      "train_cumulative_accuracy :  0.556219995096\n",
      "duree :  14100.113297\n",
      "lost =  3.88009453058\n",
      "test_cumulative_accuracy :  0.500999975801\n",
      "epoch :  112\n",
      "j =  0\n",
      "batch_train_accuracy =  0.536\n",
      "j =  80\n",
      "batch_train_accuracy =  0.68\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.496\n",
      "j =  320\n",
      "batch_train_accuracy =  0.576\n",
      "lost =  2.88460385561\n",
      "train_cumulative_accuracy :  0.574999993891\n",
      "duree :  14226.160625\n",
      "lost =  3.02490183353\n",
      "test_cumulative_accuracy :  0.558599967062\n",
      "epoch :  113\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.672\n",
      "j =  160\n",
      "batch_train_accuracy =  0.576\n",
      "j =  240\n",
      "batch_train_accuracy =  0.648\n",
      "j =  320\n",
      "batch_train_accuracy =  0.584\n",
      "lost =  2.55654449433\n",
      "train_cumulative_accuracy :  0.619279997051\n",
      "duree :  14352.055959\n",
      "lost =  3.35021582365\n",
      "test_cumulative_accuracy :  0.539399971366\n",
      "epoch :  114\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.624\n",
      "j =  160\n",
      "batch_train_accuracy =  0.528\n",
      "j =  240\n",
      "batch_train_accuracy =  0.568\n",
      "j =  320\n",
      "batch_train_accuracy =  0.592\n",
      "lost =  2.81693097115\n",
      "train_cumulative_accuracy :  0.561159994379\n",
      "duree :  14478.1159389\n",
      "lost =  3.40441450357\n",
      "test_cumulative_accuracy :  0.522299974859\n",
      "epoch :  115\n",
      "j =  0\n",
      "batch_train_accuracy =  0.608\n",
      "j =  80\n",
      "batch_train_accuracy =  0.584\n",
      "j =  160\n",
      "batch_train_accuracy =  0.552\n",
      "j =  240\n",
      "batch_train_accuracy =  0.568\n",
      "j =  320\n",
      "batch_train_accuracy =  0.6\n",
      "lost =  2.86776173353\n",
      "train_cumulative_accuracy :  0.568099995106\n",
      "duree :  14604.2038898\n",
      "lost =  3.71437371969\n",
      "test_cumulative_accuracy :  0.528099970818\n",
      "epoch :  116\n",
      "j =  0\n",
      "batch_train_accuracy =  0.592\n",
      "j =  80\n",
      "batch_train_accuracy =  0.688\n",
      "j =  160\n",
      "batch_train_accuracy =  0.568\n",
      "j =  240\n",
      "batch_train_accuracy =  0.552\n",
      "j =  320\n",
      "batch_train_accuracy =  0.656\n",
      "lost =  2.78048441917\n",
      "train_cumulative_accuracy :  0.595419998094\n",
      "duree :  14730.3455451\n",
      "lost =  3.14079305649\n",
      "test_cumulative_accuracy :  0.56449996531\n",
      "epoch :  117\n",
      "j =  0\n",
      "batch_train_accuracy =  0.616\n",
      "j =  80\n",
      "batch_train_accuracy =  0.704\n",
      "j =  160\n",
      "batch_train_accuracy =  0.6\n",
      "j =  240\n",
      "batch_train_accuracy =  0.688\n",
      "j =  320\n",
      "batch_train_accuracy =  0.688\n",
      "lost =  2.10814174011\n",
      "train_cumulative_accuracy :  0.637059996724\n",
      "duree :  14857.607187\n",
      "lost =  2.76314173341\n",
      "test_cumulative_accuracy :  0.583599967062\n",
      "epoch :  118\n",
      "j =  0\n",
      "batch_train_accuracy =  0.624\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0f1b9db25b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0;31m#print(\"j = \",j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m                     \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3666\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3668\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "embedding_size = 1024\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "logs_path = \"/home/skyolia/tensorflow_project/cifar-10/CNN/chap3/gap/test_2/\"\n",
    "    \n",
    "    #mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=logs_path + 'data', one_hot=True)\n",
    "    \n",
    "    # Network Parameters\n",
    "n_input = 3072  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "strides=1\n",
    "k=2    \n",
    "    # tf Graph input\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input], name=\"x_input\")\n",
    "    y = tf.placeholder(tf.int64, shape=[None], name=\"y_input\")\n",
    "    prob_1=tf.placeholder(tf.float32)\n",
    "    #prob_2=tf.placeholder(tf.float32)\n",
    "    #prob_3=tf.placeholder(tf.float32)\n",
    "    phase_train = tf.placeholder(tf.bool)\n",
    "\n",
    "    \n",
    "    # Store layers weight & bias\n",
    "with tf.name_scope(\"weights\"):\n",
    "        \n",
    "    weights = {\n",
    "\n",
    "    'wc1': tf.get_variable(name = \"w1\",shape = [3, 3, 3, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc2': tf.get_variable(name = \"w2\",shape = [3, 3, 48, 48], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'wc3': tf.get_variable(name = \"w3\",shape = [3, 3, 48, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc4': tf.get_variable(name = \"w4\",shape = [3, 3, 96, 96], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    'wc5': tf.get_variable(name = \"w5\",shape = [3, 3, 96, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc6': tf.get_variable(name = \"w6\",shape = [3, 3, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc7': tf.get_variable(name = \"w7\",shape = [3, 3, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'wc7': tf.get_variable(name = \"w7\",shape = [1, 1, 192, 192], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    \n",
    "    'wc8': tf.get_variable(name = \"w8\",shape = [1, 1, 192, 10], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    #'wc10': tf.get_variable(name = \"w10\",shape = [1, 1, 192, 10], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"biases\"):\n",
    "    \n",
    "    biases = {\n",
    "    \n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[10]), name = \"b9\"),\n",
    "        \n",
    "        }\n",
    "\n",
    "''' \n",
    "\n",
    "'bc1': tf.Variable(tf.constant(0.1, shape=[48]), name='b1'),\n",
    "    'bc2': tf.Variable(tf.constant(0.1, shape=[48]), name = \"b2\"),\n",
    "    #'wc3': tf.Variable(tf.truncated_normal([3, 3, 32, 32], stddev=0.1), name = \"w3\"),\n",
    "    'bc3': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b3\"),\n",
    "    'bc4': tf.Variable(tf.constant(0.1, shape=[96]), name = \"b4\"),\n",
    "    #'wc6': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w6\"),\n",
    "    #'wc7': tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.1), name = \"w7\"),\n",
    "    'bc5': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b5\"),\n",
    "    'bc6': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b6\"),\n",
    "    'bc7': tf.Variable(tf.constant(0.1, shape=[192]), name = \"b7\"),\n",
    "    'bc8': tf.Variable(tf.constant(0.1, shape=[512]), name = \"b8\"),\n",
    "    'bc9': tf.Variable(tf.constant(0.1, shape=[256]), name = \"b9\"),\n",
    "'''\n",
    "\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parametes = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parametes *= dim.value\n",
    "    print(variable_parametes)\n",
    "    total_parameters += variable_parametes\n",
    "print(\"total_parameters : \",total_parameters)\n",
    "    \n",
    "x_image = tf.reshape(x,[-1,32,32,3])\n",
    "x_bn = batch_norm(x_image, 3, phase_train, convolutional = True)\n",
    "#x_image_do=tf.nn.dropout(x_image, keep_prob=prob_3)\n",
    "\n",
    "hidden_1 = tf.nn.conv2d(x_bn, weights['wc1'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_1_bn = batch_norm(hidden_1, 48, phase_train, convolutional = True)\n",
    "hidden_1_relu = tf.nn.elu(hidden_1_bn)\n",
    "print(hidden_1_relu.get_shape())\n",
    "\n",
    "hidden_2 = tf.nn.conv2d(hidden_1_relu, weights['wc2'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_2_bn = batch_norm(hidden_2, 48, phase_train, convolutional = True)\n",
    "hidden_2_relu = tf.nn.elu(hidden_2_bn)\n",
    "print(hidden_2_relu.get_shape())\n",
    "\n",
    "pool_1 = tf.nn.max_pool(hidden_2_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_1_do=tf.nn.dropout(pool_1, keep_prob=prob_1)\n",
    "print(pool_1.get_shape())\n",
    "\n",
    "hidden_3 = tf.nn.conv2d(pool_1_do, weights['wc3'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_3_bn = batch_norm(hidden_3, 96, phase_train, convolutional = True)\n",
    "hidden_3_relu = tf.nn.elu(hidden_3_bn)\n",
    "print(hidden_3_relu.get_shape())\n",
    "\n",
    "hidden_4 = tf.nn.conv2d(hidden_3_relu, weights['wc4'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_4_bn = batch_norm(hidden_4, 96, phase_train, convolutional = True)\n",
    "hidden_4_relu = tf.nn.elu(hidden_4_bn)\n",
    "print(hidden_4_relu.get_shape())\n",
    "\n",
    "pool_2 = tf.nn.max_pool(hidden_4_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_2_do=tf.nn.dropout(pool_2, keep_prob=prob_1)\n",
    "print(pool_2.get_shape())\n",
    "\n",
    "hidden_5 = tf.nn.conv2d(pool_2_do, weights['wc5'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_5_bn = batch_norm(hidden_5, 192, phase_train, convolutional = True)\n",
    "hidden_5_relu = tf.nn.elu(hidden_5_bn)\n",
    "print(hidden_5_relu.get_shape())\n",
    "\n",
    "hidden_6 = tf.nn.conv2d(hidden_5_relu, weights['wc6'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_6_bn = batch_norm(hidden_6, 192, phase_train, convolutional = True)\n",
    "hidden_6_relu = tf.nn.elu(hidden_6_bn)\n",
    "print(hidden_6_relu.get_shape())\n",
    "\n",
    "pool_3 = tf.nn.max_pool(hidden_6_relu, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='VALID')\n",
    "pool_3_do=tf.nn.dropout(pool_3, keep_prob=prob_1)\n",
    "print(pool_3.get_shape())\n",
    "\n",
    "'''\n",
    "hidden_7 = tf.nn.conv2d(pool_3_do, weights['wc7'], strides=[1, 1, 1, 1], padding='SAME')\n",
    "hidden_7_bn = batch_norm(hidden_7, 192, phase_train, convolutional = True)\n",
    "hidden_7_relu = tf.nn.elu(hidden_7_bn)\n",
    "#hidden_7_do=tf.nn.dropout(hidden_7_relu, keep_prob=prob_1)\n",
    "print(hidden_7_relu.get_shape())\n",
    "'''\n",
    "\n",
    "hidden_8 = tf.nn.conv2d(pool_3_do, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID')\n",
    "hidden_8_bn = batch_norm(hidden_8, 192, phase_train, convolutional = True)\n",
    "hidden_8_relu = tf.nn.elu(hidden_8_bn)\n",
    "#hidden_8_do=tf.nn.dropout(hidden_8_relu, keep_prob=prob_1)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.nn.conv2d(hidden_8_relu, weights['wc9'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc9']\n",
    "#hidden_9_bn = batch_norm(hidden_9, 10, phase_train, convolutional = True)\n",
    "hidden_9_relu = tf.nn.elu(hidden_9)\n",
    "#hidden_9_do=tf.nn.dropout(hidden_9_relu, keep_prob=prob_1)\n",
    "print(hidden_9_relu.get_shape())\n",
    "\n",
    "'''\n",
    "hidden_10 = tf.nn.conv2d(hidden_9_do, weights['wc10'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc9']\n",
    "hidden_10_bn = batch_norm(hidden_10, 10, phase_train, convolutional = True)\n",
    "hidden_10_relu = tf.nn.elu(hidden_10_bn)\n",
    "#hidden_10_do=tf.nn.dropout(hidden_10_relu, keep_prob=prob_1)\n",
    "print(hidden_10_relu.get_shape())\n",
    "'''\n",
    "\n",
    "gap = tf.nn.avg_pool(hidden_9_relu, ksize=[1, 4, 4, 1], strides=[1, 4, 4, 1], padding=\"VALID\")\n",
    "print(gap.get_shape())\n",
    "\n",
    "out_y = tf.reshape(gap,(-1,10))\n",
    "print(out_y.get_shape())\n",
    "\n",
    "\n",
    "'''\n",
    "hidden_8 = tf.nn.conv2d(hidden_7_relu, weights['wc8'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc8']\n",
    "hidden_8_relu = tf.nn.elu(hidden_8)\n",
    "print(hidden_8_relu.get_shape())\n",
    "\n",
    "hidden_9 = tf.nn.conv2d(hidden_8_relu, weights['wc9'], strides=[1, 1, 1, 1], padding='VALID') + biases['bc9']\n",
    "hidden_9_relu = tf.nn.elu(hidden_9)\n",
    "print(hidden_9_relu.get_shape())\n",
    "\n",
    "out_x = tf.nn.avg_pool(hidden_9_relu, ksize=[1, 8, 8, 1], strides=[1, 8, 8, 1], padding=\"VALID\")\n",
    "print(out_x.get_shape())\n",
    "out_y = tf.reshape(out_x,(-1,10))\n",
    "print(out_y.get_shape())\n",
    "'''\n",
    "\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(out_y, y))\n",
    "        \n",
    "with tf.name_scope('learning_rate'):\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    # Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(out_y, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "acc_training_summary = tf.summary.scalar(\"training_accuracy\", accuracy)\n",
    "acc_test_summary = tf.summary.scalar(\"test_accuracy\", accuracy)\n",
    "\n",
    "lost_training_summary = tf.scalar_summary(\"training_lost\", cost)\n",
    "lost_test_summary = tf.scalar_summary(\"test_lost\", cost)\n",
    "\n",
    "\n",
    "\n",
    "#summary_op = tf.merge_all_summaries()    \n",
    "\n",
    "\n",
    "writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())\n",
    "saver = tf.train.Saver(max_to_keep=300)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "test_cumulative_accuracy = 0.0\n",
    "train_cumulative_accuracy = 0.0\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, {phase_train: True})\n",
    "    while(True):\n",
    "            gen_batch = create_batches(125,True)\n",
    "            test_accuracy = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            c = 0.0\n",
    "            c2 = 0.0\n",
    "            print(\"epoch : \", epoch)\n",
    "            for j in range(400):\n",
    "                    #print(\"j = \",j)\n",
    "                    img, lbl = gen_batch.next()\n",
    "                    optimizer.run(feed_dict={x: img, y: lbl, prob_1: 0.75, phase_train: True})\n",
    "                    c += sess.run(cost, feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                    batch_train_accuracy = sess.run(accuracy, feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                    train_accuracy += batch_train_accuracy\n",
    "                    if (j%80 == 0):\n",
    "                        print(\"j = \",j)\n",
    "                        print(\"batch_train_accuracy = \",batch_train_accuracy)\n",
    "                        \n",
    "                    train_acc_summ, train_lost_summ = sess.run([acc_training_summary, lost_training_summary], \n",
    "                                                               feed_dict={x: img, y: lbl, prob_1: 1., phase_train: False})\n",
    "                    writer.add_summary(train_acc_summ,epoch * 400 + j)\n",
    "                    writer.add_summary(train_lost_summ,epoch * 400 + j)\n",
    "                        \n",
    "                #summary = sess.run(summary_op, feed_dict={x: img, y: lbl})\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(\"train accuracy = \",train_accuracy)\n",
    "            train_cost = c/400\n",
    "            print(\"lost = \", train_cost)\n",
    "            train_cumulative_accuracy = train_accuracy/400\n",
    "            \n",
    "            end = time.time()\n",
    "            duree = end-start\n",
    "            print(\"train_cumulative_accuracy : \", train_cumulative_accuracy)\n",
    "            print(\"duree : \", duree)\n",
    "            \n",
    "            gen_batch2 = create_batches(100,False)\n",
    "            for j in range(100):\n",
    "                img2, lbl2 = gen_batch2.next()\n",
    "                \n",
    "                batch_test_accuracy = sess.run(accuracy, feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "                c2 += sess.run(cost, feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "                    \n",
    "                test_accuracy += batch_test_accuracy\n",
    "                test_acc_summ, test_lost_summ = sess.run([acc_test_summary, lost_test_summary], \n",
    "                                                         feed_dict={x: img2, y: lbl2, prob_1: 1., phase_train: False})\n",
    "            \n",
    "                writer.add_summary(test_acc_summ,epoch * 100 + j)\n",
    "                writer.add_summary(test_lost_summ,epoch * 100 + j)\n",
    "            \n",
    "            test_cost = c2/100\n",
    "            print(\"lost = \", test_cost)\n",
    "            test_cumulative_accuracy = test_accuracy/100\n",
    "            print(\"test_cumulative_accuracy : \", test_cumulative_accuracy)\n",
    "            \n",
    "            file_name = \"./\"+str(epoch)+\"_model.ckpt\"\n",
    "            saver.save(sess, file_name)\n",
    "            \n",
    "            epoch += 1 \n",
    "    \n",
    "print(\"model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
